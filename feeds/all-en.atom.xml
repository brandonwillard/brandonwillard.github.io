<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Brandon T. Willard</title><link href="https://brandonwillard.github.io/" rel="alternate"></link><link href="https://brandonwillard.github.io/feeds/all-en.atom.xml" rel="self"></link><id>https://brandonwillard.github.io/</id><updated>2019-10-18T00:00:00-05:00</updated><entry><title>Symbolic PyMC Radon Example in PyMC4</title><link href="https://brandonwillard.github.io/symbolic-pymc-radon-example-in-pymc4.html" rel="alternate"></link><published>2019-09-08T00:00:00-05:00</published><updated>2019-10-18T00:00:00-05:00</updated><author><name>Brandon T. Willard</name></author><id>tag:brandonwillard.github.io,2019-09-08:/symbolic-pymc-radon-example-in-pymc4.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon T. Willard" /&gt;
  &lt;title&gt;Symbolic PyMC Radon Example in PyMC4&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;style type="text/css"&gt;
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  &lt;/style&gt;
  &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;Symbolic PyMC Radon Example in PyMC4&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon T. Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2019–09–08&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;section id="introduction" class="level1"&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/pymc-devs/symbolic-pymc"&gt;Symbolic PyMC&lt;/a&gt; is a library that provides tools for symbolic manipulation of Tensor library models in TensorFlow and Theano. Over time, we plan to add tools that are somewhat specialized toward Bayesian model manipulation and the mathematical identities relevant to model manipulation for MCMC.&lt;/p&gt;
&lt;p&gt;The main approach taken by Symbolic PyMC is relational/logic programming powered by a &lt;a href="http://minikanren.org/"&gt;miniKanren&lt;/a&gt; implementation in pure Python based on &lt;a href="https://github.com/pymc-devs/kanren"&gt;&lt;code&gt;kanren&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As an example of Symbolic PyMC’s usage, we will create a model “optimizer” that approximates the re-centering and re-scaling commonly demonstrated with the radon dataset. This example already exists for Theano in PyMC3 and can be found in the &lt;a href="https://github.com/pymc-devs/symbolic-pymc#automatic-re-centering-and-re-scaling"&gt;project README&lt;/a&gt;. Here, we will operate on TensorFlow graphs via PyMC4 and approximate the same optimization using a very different approach targeted toward the log-likelihood graph.&lt;/p&gt;
&lt;p&gt;To get started, we download the radon dataset and define the un-centered model in Listings &lt;a href="#orgb52aa39"&gt;1&lt;/a&gt;, &lt;a href="#org84a4bd7"&gt;2&lt;/a&gt;, and &lt;a href="#orgf0b697c"&gt;3&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="orgb52aa39"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgb52aa39-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; numpy &lt;span class="im"&gt;as&lt;/span&gt; np&lt;/a&gt;
&lt;a class="sourceLine" id="orgb52aa39-2" data-line-number="2"&gt;&lt;span class="im"&gt;import&lt;/span&gt; pandas &lt;span class="im"&gt;as&lt;/span&gt; pd&lt;/a&gt;
&lt;a class="sourceLine" id="orgb52aa39-3" data-line-number="3"&gt;&lt;span class="im"&gt;import&lt;/span&gt; tensorflow &lt;span class="im"&gt;as&lt;/span&gt; tf&lt;/a&gt;
&lt;a class="sourceLine" id="orgb52aa39-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb52aa39-5" data-line-number="5"&gt;&lt;span class="im"&gt;import&lt;/span&gt; pymc4 &lt;span class="im"&gt;as&lt;/span&gt; pm&lt;/a&gt;
&lt;a class="sourceLine" id="orgb52aa39-6" data-line-number="6"&gt;&lt;span class="im"&gt;import&lt;/span&gt; arviz &lt;span class="im"&gt;as&lt;/span&gt; az&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org84a4bd7"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org84a4bd7-1" data-line-number="1"&gt;data &lt;span class="op"&gt;=&lt;/span&gt; pd.read_csv(&lt;span class="st"&gt;&amp;#39;https://github.com/pymc-devs/pymc3/raw/master/pymc3/examples/data/radon.csv&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org84a4bd7-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org84a4bd7-3" data-line-number="3"&gt;county_names &lt;span class="op"&gt;=&lt;/span&gt; data.county.unique()&lt;/a&gt;
&lt;a class="sourceLine" id="org84a4bd7-4" data-line-number="4"&gt;county_idx &lt;span class="op"&gt;=&lt;/span&gt; data[&lt;span class="st"&gt;&amp;#39;county_code&amp;#39;&lt;/span&gt;].values.astype(np.int32)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgf0b697c"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgf0b697c-1" data-line-number="1"&gt;&lt;span class="at"&gt;@pm.model&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-2" data-line-number="2"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; hierarchical_model(data, county_idx):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-3" data-line-number="3"&gt;    &lt;span class="co"&gt;# Hyperpriors&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-4" data-line-number="4"&gt;    mu_a &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="cf"&gt;yield&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;mu_alpha&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;0.&lt;/span&gt;, sigma&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-5" data-line-number="5"&gt;    sigma_a &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="cf"&gt;yield&lt;/span&gt; pm.HalfCauchy(&lt;span class="st"&gt;&amp;#39;sigma_alpha&amp;#39;&lt;/span&gt;, beta&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-6" data-line-number="6"&gt;    mu_b &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="cf"&gt;yield&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;mu_beta&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;0.&lt;/span&gt;, sigma&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-7" data-line-number="7"&gt;    sigma_b &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="cf"&gt;yield&lt;/span&gt; pm.HalfCauchy(&lt;span class="st"&gt;&amp;#39;sigma_beta&amp;#39;&lt;/span&gt;, beta&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-9" data-line-number="9"&gt;    &lt;span class="co"&gt;# Intercept for each county, distributed around group mean mu_a&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-10" data-line-number="10"&gt;    a &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="cf"&gt;yield&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;alpha&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;mu_a, sigma&lt;span class="op"&gt;=&lt;/span&gt;sigma_a, plate&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="bu"&gt;len&lt;/span&gt;(data.county.unique()))&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-11" data-line-number="11"&gt;    &lt;span class="co"&gt;# Intercept for each county, distributed around group mean mu_a&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-12" data-line-number="12"&gt;    b &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="cf"&gt;yield&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;mu_b, sigma&lt;span class="op"&gt;=&lt;/span&gt;sigma_b, plate&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="bu"&gt;len&lt;/span&gt;(data.county.unique()))&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-14" data-line-number="14"&gt;    &lt;span class="co"&gt;# Model error&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-15" data-line-number="15"&gt;    eps &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="cf"&gt;yield&lt;/span&gt; pm.HalfCauchy(&lt;span class="st"&gt;&amp;#39;eps&amp;#39;&lt;/span&gt;, beta&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-17" data-line-number="17"&gt;    &lt;span class="co"&gt;# Expected value&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-18" data-line-number="18"&gt;    &lt;span class="co"&gt;#radon_est = a[county_idx] + b[county_idx] * data.floor.values&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-19" data-line-number="19"&gt;    radon_est &lt;span class="op"&gt;=&lt;/span&gt; tf.gather(a, county_idx) &lt;span class="op"&gt;+&lt;/span&gt; tf.gather(&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-20" data-line-number="20"&gt;        b, county_idx) &lt;span class="op"&gt;*&lt;/span&gt; data.floor.values&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-22" data-line-number="22"&gt;    &lt;span class="co"&gt;# Data likelihood&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-23" data-line-number="23"&gt;    y_like &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="cf"&gt;yield&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;y_like&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;radon_est, sigma&lt;span class="op"&gt;=&lt;/span&gt;eps, observed&lt;span class="op"&gt;=&lt;/span&gt;data.log_radon)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-24" data-line-number="24"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-25" data-line-number="25"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-26" data-line-number="26"&gt;init_num_chains &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;50&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf0b697c-27" data-line-number="27"&gt;model &lt;span class="op"&gt;=&lt;/span&gt; hierarchical_model(data, county_idx)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In Listing &lt;a href="#org76f5220"&gt;5&lt;/a&gt;, we estimates the model using the sample routine from the &lt;a href="https://github.com/pymc-devs/pymc4/blob/master/notebooks/radon_hierarchical.ipynb"&gt;PyMC4 Radon example Notebook&lt;/a&gt; in Listing &lt;a href="#org9df08c0"&gt;4&lt;/a&gt;. The same plots are reproduce here in Figures &lt;a href="#org2d6c05e"&gt;6&lt;/a&gt; and &lt;a href="#orgef38802"&gt;7&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="org9df08c0"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org9df08c0-1" data-line-number="1"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; sample(model, init_num_chains&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;50&lt;/span&gt;, num_samples&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;500&lt;/span&gt;, burn_in&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;500&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-2" data-line-number="2"&gt;    init_num_chains &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;50&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-3" data-line-number="3"&gt;    pm4_trace, _ &lt;span class="op"&gt;=&lt;/span&gt; pm.inference.sampling.sample(&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-4" data-line-number="4"&gt;        model, num_chains&lt;span class="op"&gt;=&lt;/span&gt;init_num_chains, num_samples&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;, burn_in&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;, step_size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1.&lt;/span&gt;, xla&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-5" data-line-number="5"&gt;    &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;range&lt;/span&gt;(&lt;span class="dv"&gt;3&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-6" data-line-number="6"&gt;        step_size_ &lt;span class="op"&gt;=&lt;/span&gt; []&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-7" data-line-number="7"&gt;        &lt;span class="cf"&gt;for&lt;/span&gt; _, x &lt;span class="kw"&gt;in&lt;/span&gt; pm4_trace.items():&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-8" data-line-number="8"&gt;            std &lt;span class="op"&gt;=&lt;/span&gt; tf.math.reduce_std(x, axis&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-9" data-line-number="9"&gt;            step_size_.append(&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-10" data-line-number="10"&gt;                std[tf.newaxis, ...] &lt;span class="op"&gt;*&lt;/span&gt; tf.ones([init_num_chains] &lt;span class="op"&gt;+&lt;/span&gt; std.shape, dtype&lt;span class="op"&gt;=&lt;/span&gt;std.dtype))&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-11" data-line-number="11"&gt;        pm4_trace, _ &lt;span class="op"&gt;=&lt;/span&gt; pm.inference.sampling.sample(&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-12" data-line-number="12"&gt;            model, num_chains&lt;span class="op"&gt;=&lt;/span&gt;init_num_chains, num_samples&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt; &lt;span class="op"&gt;+&lt;/span&gt; &lt;span class="dv"&gt;10&lt;/span&gt;&lt;span class="op"&gt;*&lt;/span&gt;i, burn_in&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt; &lt;span class="op"&gt;+&lt;/span&gt; &lt;span class="dv"&gt;10&lt;/span&gt;&lt;span class="op"&gt;*&lt;/span&gt;i,&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-13" data-line-number="13"&gt;            step_size&lt;span class="op"&gt;=&lt;/span&gt;step_size_, xla&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-14" data-line-number="14"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-15" data-line-number="15"&gt;    num_chains &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;5&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-16" data-line-number="16"&gt;    step_size_ &lt;span class="op"&gt;=&lt;/span&gt; []&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-17" data-line-number="17"&gt;    &lt;span class="cf"&gt;for&lt;/span&gt; _, x &lt;span class="kw"&gt;in&lt;/span&gt; pm4_trace.items():&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-18" data-line-number="18"&gt;        std &lt;span class="op"&gt;=&lt;/span&gt; tf.math.reduce_std(x, axis&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-19" data-line-number="19"&gt;        step_size_.append(&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-20" data-line-number="20"&gt;            std[tf.newaxis, ...] &lt;span class="op"&gt;*&lt;/span&gt; tf.ones([num_chains]&lt;span class="op"&gt;+&lt;/span&gt;std.shape, dtype&lt;span class="op"&gt;=&lt;/span&gt;std.dtype))&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-22" data-line-number="22"&gt;    pm4_trace, sample_stat &lt;span class="op"&gt;=&lt;/span&gt; pm.inference.sampling.sample(&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-23" data-line-number="23"&gt;        model, num_chains&lt;span class="op"&gt;=&lt;/span&gt;num_chains, num_samples&lt;span class="op"&gt;=&lt;/span&gt;num_samples, burn_in&lt;span class="op"&gt;=&lt;/span&gt;burn_in,&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-24" data-line-number="24"&gt;        step_size&lt;span class="op"&gt;=&lt;/span&gt;step_size_, xla&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-25" data-line-number="25"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-26" data-line-number="26"&gt;    az_trace &lt;span class="op"&gt;=&lt;/span&gt; pm.inference.utils.trace_to_arviz(pm4_trace, sample_stat)&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-27" data-line-number="27"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9df08c0-28" data-line-number="28"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; az_trace&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org76f5220"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org76f5220-1" data-line-number="1"&gt;az_trace &lt;span class="op"&gt;=&lt;/span&gt; sample(model)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org6569169"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org6569169-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; arviz &lt;span class="im"&gt;as&lt;/span&gt; az&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-2" data-line-number="2"&gt;&lt;span class="im"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class="im"&gt;as&lt;/span&gt; plt&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-4" data-line-number="4"&gt;&lt;span class="im"&gt;import&lt;/span&gt; seaborn &lt;span class="im"&gt;as&lt;/span&gt; sns&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-6" data-line-number="6"&gt;&lt;span class="im"&gt;from&lt;/span&gt; matplotlib &lt;span class="im"&gt;import&lt;/span&gt; rcParams&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-9" data-line-number="9"&gt;rcParams[&lt;span class="st"&gt;&amp;#39;figure.figsize&amp;#39;&lt;/span&gt;] &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="fl"&gt;11.7&lt;/span&gt;, &lt;span class="fl"&gt;8.27&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-11" data-line-number="11"&gt;&lt;span class="co"&gt;# plt.rc(&amp;#39;text&amp;#39;, usetex=True)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-12" data-line-number="12"&gt;sns.set_style(&lt;span class="st"&gt;&amp;quot;whitegrid&amp;quot;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org6569169-13" data-line-number="13"&gt;sns.set_context(&lt;span class="st"&gt;&amp;quot;paper&amp;quot;&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgdd90ae2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgdd90ae2-1" data-line-number="1"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; az.plot_energy(az_trace)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure id="fig:pymc4-radon-plot-energy"&gt;
&lt;img src="https://brandonwillard.github.io/figures/pymc4-radon-plot-energy.png" alt="" /&gt;
&lt;figcaption&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure id="fig:pymc4-radon-plot-trace"&gt;
&lt;img src="https://brandonwillard.github.io/figures/pymc4-radon-plot-trace.png" alt="" /&gt;
&lt;figcaption&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/section&gt;
&lt;section id="applying-an-optimization" class="level1"&gt;
&lt;h1&gt;Applying an Optimization&lt;/h1&gt;
&lt;p&gt;In order to apply our optimization, we need to do some work to obtain a graph of the log-likelihood function generated by the model in Listing &lt;a href="#orgf0b697c"&gt;3&lt;/a&gt;. With the graph in-hand, we can perform the re-centering and re-scaling transform–in log-space this time–and obtain a new log-likelihood graph from which better samples can be generated.&lt;/p&gt;
&lt;p&gt;This exercise introduces the TensorFlow function-graph elements that mirror Theano’s &lt;code&gt;tt.function&lt;/code&gt; and &lt;code&gt;FunctionGraph&lt;/code&gt;s: &lt;code&gt;tensorflow.python.framework.func_graph.FuncGraph&lt;/code&gt;. &lt;code&gt;FuncGraph&lt;/code&gt; is a subclass of the regular &lt;code&gt;Graph&lt;/code&gt; objects upon which implicitly &lt;code&gt;symbolic_pymc&lt;/code&gt; operates. Just as with Theano’s &lt;code&gt;FunctionGraph&lt;/code&gt;s, &lt;code&gt;FuncGraph&lt;/code&gt; simply specializes a graph by specifying inputs and outputs from elements (i.e. tensors) within a graph.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="log-likelihood-funcgraphs" class="level1"&gt;
&lt;h1&gt;Log-likelihood &lt;code&gt;FuncGraph&lt;/code&gt;s&lt;/h1&gt;
&lt;p&gt;In Listing &lt;a href="#orgc606190"&gt;8&lt;/a&gt;, we build the log-likelihood function for our model and a corresponding list of initial values for the parameters.&lt;/p&gt;
&lt;div class="sourceCode" id="orgc606190"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgc606190-1" data-line-number="1"&gt;state &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc606190-2" data-line-number="2"&gt;observed &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc606190-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc606190-4" data-line-number="4"&gt;logpfn, init &lt;span class="op"&gt;=&lt;/span&gt; pm.inference.sampling.build_logp_function(model,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc606190-5" data-line-number="5"&gt;                                                         state&lt;span class="op"&gt;=&lt;/span&gt;state,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc606190-6" data-line-number="6"&gt;                                                         observed&lt;span class="op"&gt;=&lt;/span&gt;observed)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From here we need &lt;code&gt;FuncGraph&lt;/code&gt;s for each input to &lt;code&gt;logpfn&lt;/code&gt;. Since &lt;code&gt;logpfn&lt;/code&gt; is a &lt;code&gt;tensorflow.python.eager.def_function.Function&lt;/code&gt; instance, every time it’s called with a specific tensor it may create a new function-object with it’s own &lt;code&gt;FuncGraph&lt;/code&gt;. In other words, it dynamically generates function objects based on the inputs it’s given.&lt;/p&gt;
&lt;p&gt;This specialization process can be performed manually using &lt;code&gt;logpfn.get_concrete_function(*args)&lt;/code&gt;, which necessarily produces a &lt;code&gt;tensorflow.python.eager.function.ConcreteFunction&lt;/code&gt; with the desired &lt;code&gt;FuncGraph&lt;/code&gt;. Listing &lt;a href="#org966cccf"&gt;9&lt;/a&gt; creates and extracts these two objects.&lt;/p&gt;
&lt;div class="sourceCode" id="org966cccf"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org966cccf-1" data-line-number="1"&gt;logpfn_cf &lt;span class="op"&gt;=&lt;/span&gt; logpfn.get_concrete_function(&lt;span class="op"&gt;*&lt;/span&gt;init.values())&lt;/a&gt;
&lt;a class="sourceLine" id="org966cccf-2" data-line-number="2"&gt;logpfn_fg &lt;span class="op"&gt;=&lt;/span&gt; logpfn_cf.graph&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The outputs are now available in graph form as &lt;code&gt;logpfn_fg.outputs&lt;/code&gt;. The inputs aren’t mapped in this particular function-graph output. I believe there’s a way to generate those as TF placeholders.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="the-log-space-transform" class="level1"&gt;
&lt;h1&gt;The Log-space Transform&lt;/h1&gt;
&lt;p&gt;Consider the following two equivalent hierarchical models,&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation}
  \begin{gathered}
    Y = X + \epsilon, \quad
    \epsilon \sim \operatorname{N}\left(0, 1\right)
    \\
    X \sim \operatorname{N}\left(\mu, \sigma^2\right)
  \end{gathered}
\label{eq:model-1}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation}
  \begin{gathered}
    Y = \mu + \sigma \cdot \tilde{X} + \epsilon, \quad
    \epsilon \sim \operatorname{N}\left(0, 1\right)
    \\
    \tilde{X} \sim \operatorname{N}\left(0, 1\right)
  \;.
  \end{gathered}
\label{eq:model-2}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Models &lt;span class="math inline"&gt;\(\eqref{eq:model-1}\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\eqref{eq:model-2}\)&lt;/span&gt; are represented in (log) measure space, respectively, as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{align}
    \log P(Y, X) &amp;amp;= \log P(Y\mid X) + \log P(X)
    \nonumber
    \\
    &amp;amp;= C - \frac{1}{2} \left(y - x\right)^2 - \frac{1}{2 \sigma^2} \left(x - \mu\right)^2
    \label{eq:log-model-1}
    \\
    &amp;amp;= \tilde{C} - \frac{1}{2} \left(y - \mu - \sigma \cdot \tilde{x}\right)^2 - \frac{1}{2} \tilde{x}^2
  \label{eq:log-model-2}
  \;.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Via term rewriting, Equation &lt;span class="math inline"&gt;\(\eqref{eq:log-model-2}\)&lt;/span&gt; is produced by first applying the replacement rule &lt;span class="math inline"&gt;\(x \to \mu + \sigma \cdot \tilde{x}\)&lt;/span&gt; to Equation &lt;span class="math inline"&gt;\(\eqref{eq:log-model-1}\)&lt;/span&gt;, which produces&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{align*}
C - \frac{1}{2} \left(y - (\mu + \sigma \cdot \tilde{x})\right)^2 - \frac{1}{2 \sigma^2} \left((\mu + \sigma \cdot \tilde{x}) - \mu\right)^2
\;.
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;After a few applications of some simple algebraic properties–as further replacement rules–one obtains the exact form of Equation &lt;span class="math inline"&gt;\(\eqref{eq:log-model-2}\)&lt;/span&gt;. Here, we’ll focus only on applying the initial replacement rule.&lt;/p&gt;
&lt;p&gt;In our case, the log-density returned by PyMC4–via the TensorFlow Probability library (TFP)– uses &lt;code&gt;tf.math.squared_difference&lt;/code&gt; to construct the “squared error” term in the exponential of a normal distribution. Listing &lt;a href="#orgc47d26d"&gt;10&lt;/a&gt; shows the graph produced by a normal distribution in TFP.&lt;/p&gt;
&lt;div class="sourceCode" id="orgc47d26d"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgc47d26d-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; tensorflow_probability &lt;span class="im"&gt;as&lt;/span&gt; tfp&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-3" data-line-number="3"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.eager.context &lt;span class="im"&gt;import&lt;/span&gt; graph_mode&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-4" data-line-number="4"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.framework.ops &lt;span class="im"&gt;import&lt;/span&gt; disable_tensor_equality&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-6" data-line-number="6"&gt;&lt;span class="im"&gt;from&lt;/span&gt; symbolic_pymc.tensorflow.printing &lt;span class="im"&gt;import&lt;/span&gt; tf_dprint&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-9" data-line-number="9"&gt;disable_tensor_equality()&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-11" data-line-number="11"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; graph_mode(), tf.Graph().as_default() &lt;span class="im"&gt;as&lt;/span&gt; test_graph:&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-12" data-line-number="12"&gt;    mu_tf &lt;span class="op"&gt;=&lt;/span&gt; tf.compat.v1.placeholder(tf.float32, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;mu&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-13" data-line-number="13"&gt;                                     shape&lt;span class="op"&gt;=&lt;/span&gt;tf.TensorShape([&lt;span class="va"&gt;None&lt;/span&gt;]))&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-14" data-line-number="14"&gt;    tau_tf &lt;span class="op"&gt;=&lt;/span&gt; tf.compat.v1.placeholder(tf.float32, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;tau&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-15" data-line-number="15"&gt;                                      shape&lt;span class="op"&gt;=&lt;/span&gt;tf.TensorShape([&lt;span class="va"&gt;None&lt;/span&gt;]))&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-17" data-line-number="17"&gt;    normal_tfp &lt;span class="op"&gt;=&lt;/span&gt; tfp.distributions.normal.Normal(mu_tf, tau_tf)&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-19" data-line-number="19"&gt;    value_tf &lt;span class="op"&gt;=&lt;/span&gt; tf.compat.v1.placeholder(tf.float32, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-20" data-line-number="20"&gt;                                        shape&lt;span class="op"&gt;=&lt;/span&gt;tf.TensorShape([&lt;span class="va"&gt;None&lt;/span&gt;]))&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-22" data-line-number="22"&gt;    normal_log_lik &lt;span class="op"&gt;=&lt;/span&gt; normal_tfp.log_prob(value_tf)&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-23" data-line-number="23"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc47d26d-24" data-line-number="24"&gt;    tf_dprint(normal_log_lik)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre id="org8ee5799" class="text"&gt;&lt;code&gt;Tensor(Sub):0,  shape=[None]    &amp;quot;Normal_1/log_prob/sub:0&amp;quot;
|  Op(Sub)  &amp;quot;Normal_1/log_prob/sub&amp;quot;
|  |  Tensor(Mul):0,    shape=[None]    &amp;quot;Normal_1/log_prob/mul:0&amp;quot;
|  |  |  Op(Mul)    &amp;quot;Normal_1/log_prob/mul&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;Normal_1/log_prob/mul/x:0&amp;quot;
|  |  |  |  Tensor(SquaredDifference):0,    shape=[None]    &amp;quot;Normal_1/log_prob/SquaredDifference:0&amp;quot;
|  |  |  |  |  Op(SquaredDifference)    &amp;quot;Normal_1/log_prob/SquaredDifference&amp;quot;
|  |  |  |  |  |  Tensor(RealDiv):0,    shape=[None]    &amp;quot;Normal_1/log_prob/truediv:0&amp;quot;
|  |  |  |  |  |  |  Op(RealDiv)    &amp;quot;Normal_1/log_prob/truediv&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;value:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  |  |  Tensor(RealDiv):0,    shape=[None]    &amp;quot;Normal_1/log_prob/truediv_1:0&amp;quot;
|  |  |  |  |  |  |  Op(RealDiv)    &amp;quot;Normal_1/log_prob/truediv_1&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;mu:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  Tensor(AddV2):0,  shape=[None]    &amp;quot;Normal_1/log_prob/add:0&amp;quot;
|  |  |  Op(AddV2)  &amp;quot;Normal_1/log_prob/add&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;Normal_1/log_prob/add/x:0&amp;quot;
|  |  |  |  Tensor(Log):0,  shape=[None]    &amp;quot;Normal_1/log_prob/Log:0&amp;quot;
|  |  |  |  |  Op(Log)  &amp;quot;Normal_1/log_prob/Log&amp;quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;tau:0&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Instead of looking for the entire log-likelihood graph for a distribution, we can focus on only the &lt;code&gt;SquaredDifference&lt;/code&gt; operators, since they contain all the relevant terms for our transformation.&lt;/p&gt;
&lt;p&gt;More specifically, if we can identify “chains” of such terms, i.e. &lt;code&gt;SquaredDifference(y, x)&lt;/code&gt; and &lt;code&gt;SquaredDifference(x, mu)&lt;/code&gt;, then we might be able to assume that the corresponding subgraph was formed from such a hierarchical normal model.&lt;/p&gt;
&lt;p&gt;Listing &lt;a href="#orgacfcea8"&gt;12&lt;/a&gt; shows the &lt;code&gt;SquaredDifference&lt;/code&gt; sub-graphs in the log-likelihood graph for our radon model. It demonstrates two instances of said &lt;code&gt;SquaredDifference&lt;/code&gt; “chains”: they involve tensors named &lt;code&gt;values_5&lt;/code&gt; and &lt;code&gt;values_1&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="orgacfcea8"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgacfcea8-1" data-line-number="1"&gt;square_diff_outs &lt;span class="op"&gt;=&lt;/span&gt; [o &lt;span class="cf"&gt;for&lt;/span&gt; o &lt;span class="kw"&gt;in&lt;/span&gt; logpfn_fg.get_operations()&lt;/a&gt;
&lt;a class="sourceLine" id="orgacfcea8-2" data-line-number="2"&gt;                    &lt;span class="cf"&gt;if&lt;/span&gt; o.&lt;span class="bu"&gt;type&lt;/span&gt; &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;SquaredDifference&amp;#39;&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgacfcea8-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgacfcea8-4" data-line-number="4"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; t &lt;span class="kw"&gt;in&lt;/span&gt; square_diff_outs:&lt;/a&gt;
&lt;a class="sourceLine" id="orgacfcea8-5" data-line-number="5"&gt;    tf_dprint(t)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre id="orga75d153" class="text"&gt;&lt;code&gt;Op(SquaredDifference)   &amp;quot;Normal_5/log_prob/SquaredDifference&amp;quot;
|  Tensor(RealDiv):0,   shape=[]    &amp;quot;Normal_5/log_prob/truediv:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;Normal_5/log_prob/truediv&amp;quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &amp;quot;values_5:0&amp;quot;
|  |  |  Tensor(Const):0,   shape=[]    &amp;quot;Normal/scale:0&amp;quot;
|  Tensor(RealDiv):0,   shape=[]    &amp;quot;Normal_5/log_prob/truediv_1:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;Normal_5/log_prob/truediv_1&amp;quot;
|  |  |  Tensor(Const):0,   shape=[]    &amp;quot;Normal/loc:0&amp;quot;
|  |  |  Tensor(Const):0,   shape=[]    &amp;quot;Normal/scale:0&amp;quot;
Op(SquaredDifference)   &amp;quot;Normal_1_1/log_prob/SquaredDifference&amp;quot;
|  Tensor(RealDiv):0,   shape=[]    &amp;quot;Normal_1_1/log_prob/truediv:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;Normal_1_1/log_prob/truediv&amp;quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &amp;quot;values_1:0&amp;quot;
|  |  |  Tensor(Const):0,   shape=[]    &amp;quot;Normal_1/scale:0&amp;quot;
|  Tensor(RealDiv):0,   shape=[]    &amp;quot;Normal_1_1/log_prob/truediv_1:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;Normal_1_1/log_prob/truediv_1&amp;quot;
|  |  |  Tensor(Const):0,   shape=[]    &amp;quot;Normal_1/loc:0&amp;quot;
|  |  |  Tensor(Const):0,   shape=[]    &amp;quot;Normal_1/scale:0&amp;quot;
Op(SquaredDifference)   &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/SquaredDifference&amp;quot;
|  Tensor(RealDiv):0,   shape=[85]  &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv&amp;quot;
|  |  |  Tensor(Transpose):0,   shape=[85]  &amp;quot;SampleNormal_2_1/log_prob/transpose:0&amp;quot;
|  |  |  |  Op(Transpose)   &amp;quot;SampleNormal_2_1/log_prob/transpose&amp;quot;
|  |  |  |  |  Tensor(Reshape):0,   shape=[85]  &amp;quot;SampleNormal_2_1/log_prob/Reshape:0&amp;quot;
|  |  |  |  |  |  Op(Reshape)   &amp;quot;SampleNormal_2_1/log_prob/Reshape&amp;quot;
|  |  |  |  |  |  |  Tensor(Placeholder):0, shape=[85]  &amp;quot;values_6:0&amp;quot;
|  |  |  |  |  |  |  Tensor(Const):0,   shape=[1]   &amp;quot;SampleNormal_2_1/log_prob/Reshape/shape:0&amp;quot;
|  |  |  |  |  Tensor(Const):0, shape=[1]   &amp;quot;SampleNormal_2_1/log_prob/transpose/perm:0&amp;quot;
|  |  |  Tensor(Exp):0, shape=[]    &amp;quot;exp_1/forward/Exp:0&amp;quot;
|  |  |  |  Op(Exp) &amp;quot;exp_1/forward/Exp&amp;quot;
|  |  |  |  |  Tensor(Placeholder):0,   shape=[]    &amp;quot;values_4:0&amp;quot;
|  Tensor(RealDiv):0,   shape=[]    &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv_1:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv_1&amp;quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &amp;quot;values_5:0&amp;quot;
|  |  |  Tensor(Exp):0, shape=[]    &amp;quot;exp_1/forward/Exp:0&amp;quot;
|  |  |  |  ...
Op(SquaredDifference)   &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/SquaredDifference&amp;quot;
|  Tensor(RealDiv):0,   shape=[85]  &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv&amp;quot;
|  |  |  Tensor(Transpose):0,   shape=[85]  &amp;quot;SampleNormal_3_1/log_prob/transpose:0&amp;quot;
|  |  |  |  Op(Transpose)   &amp;quot;SampleNormal_3_1/log_prob/transpose&amp;quot;
|  |  |  |  |  Tensor(Reshape):0,   shape=[85]  &amp;quot;SampleNormal_3_1/log_prob/Reshape:0&amp;quot;
|  |  |  |  |  |  Op(Reshape)   &amp;quot;SampleNormal_3_1/log_prob/Reshape&amp;quot;
|  |  |  |  |  |  |  Tensor(Placeholder):0, shape=[85]  &amp;quot;values_3:0&amp;quot;
|  |  |  |  |  |  |  Tensor(Const):0,   shape=[1]   &amp;quot;SampleNormal_3_1/log_prob/Reshape/shape:0&amp;quot;
|  |  |  |  |  Tensor(Const):0, shape=[1]   &amp;quot;SampleNormal_3_1/log_prob/transpose/perm:0&amp;quot;
|  |  |  Tensor(Exp):0, shape=[]    &amp;quot;exp_2_1/forward/Exp:0&amp;quot;
|  |  |  |  Op(Exp) &amp;quot;exp_2_1/forward/Exp&amp;quot;
|  |  |  |  |  Tensor(Placeholder):0,   shape=[]    &amp;quot;values_0:0&amp;quot;
|  Tensor(RealDiv):0,   shape=[]    &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv_1:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv_1&amp;quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &amp;quot;values_1:0&amp;quot;
|  |  |  Tensor(Exp):0, shape=[]    &amp;quot;exp_2_1/forward/Exp:0&amp;quot;
|  |  |  |  ...
Op(SquaredDifference)   &amp;quot;Normal_4_1/log_prob/SquaredDifference&amp;quot;
|  Tensor(RealDiv):0,   shape=[919] &amp;quot;Normal_4_1/log_prob/truediv:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;Normal_4_1/log_prob/truediv&amp;quot;
|  |  |  Tensor(Const):0,   shape=[919] &amp;quot;Normal_4_1/log_prob/value:0&amp;quot;
|  |  |  Tensor(Exp):0, shape=[]    &amp;quot;exp_3_1/forward/Exp:0&amp;quot;
|  |  |  |  Op(Exp) &amp;quot;exp_3_1/forward/Exp&amp;quot;
|  |  |  |  |  Tensor(Placeholder):0,   shape=[]    &amp;quot;values_2:0&amp;quot;
|  Tensor(RealDiv):0,   shape=[919] &amp;quot;Normal_4_1/log_prob/truediv_1:0&amp;quot;
|  |  Op(RealDiv)   &amp;quot;Normal_4_1/log_prob/truediv_1&amp;quot;
|  |  |  Tensor(AddV2):0,   shape=[919] &amp;quot;add:0&amp;quot;
|  |  |  |  Op(AddV2)   &amp;quot;add&amp;quot;
|  |  |  |  |  Tensor(GatherV2):0,  shape=[919] &amp;quot;GatherV2:0&amp;quot;
|  |  |  |  |  |  Op(GatherV2)  &amp;quot;GatherV2&amp;quot;
|  |  |  |  |  |  |  Tensor(Placeholder):0, shape=[85]  &amp;quot;values_6:0&amp;quot;
|  |  |  |  |  |  |  Tensor(Const):0,   shape=[919] &amp;quot;GatherV2/indices:0&amp;quot;
|  |  |  |  |  |  |  Tensor(Const):0,   shape=[]    &amp;quot;GatherV2/axis:0&amp;quot;
|  |  |  |  |  Tensor(Mul):0,   shape=[919] &amp;quot;mul:0&amp;quot;
|  |  |  |  |  |  Op(Mul)   &amp;quot;mul&amp;quot;
|  |  |  |  |  |  |  Tensor(GatherV2):0,    shape=[919] &amp;quot;GatherV2_1:0&amp;quot;
|  |  |  |  |  |  |  |  Op(GatherV2)    &amp;quot;GatherV2_1&amp;quot;
|  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,   shape=[85]  &amp;quot;values_3:0&amp;quot;
|  |  |  |  |  |  |  |  |  Tensor(Const):0, shape=[919] &amp;quot;GatherV2_1/indices:0&amp;quot;
|  |  |  |  |  |  |  |  |  Tensor(Const):0, shape=[]    &amp;quot;GatherV2_1/axis:0&amp;quot;
|  |  |  |  |  |  |  Tensor(Const):0,   shape=[919] &amp;quot;mul/y:0&amp;quot;
|  |  |  Tensor(Exp):0, shape=[]    &amp;quot;exp_3_1/forward/Exp:0&amp;quot;
|  |  |  |  ...

&lt;/code&gt;&lt;/pre&gt;
&lt;section id="graph-normalization" class="level2"&gt;
&lt;h2&gt;Graph Normalization&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;grappler&lt;/code&gt; library in TensorFlow provides a subset of graph pruning/optimization steps. Ideally, a library like &lt;code&gt;grappler&lt;/code&gt; would provide full-fledged graph normalization/canonicalization upon which we could base the subgraphs used in our relations.&lt;/p&gt;
&lt;div class="remark" data-markdown=""&gt;
&lt;p&gt;While &lt;code&gt;grappler&lt;/code&gt; does appear to provide some minimal algebraic normalizations, the extent to which these are performed and their breadth of relevant operator coverage isn’t clear; however, the normalizations that it does provide are worth using, so we’ll make use of them throughout.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In general, we don’t want our “patterns” to be “brittle”, e.g. rely on explicit–yet variable–term orderings in commutative operators (e.g. a pattern that exclusively targets &lt;code&gt;mt.add(x_lv, y_lv)&lt;/code&gt; and won’t match the equivalent &lt;code&gt;mt.add(y_lv, x_lv)&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Listing &lt;a href="#org0c58115"&gt;14&lt;/a&gt; provides a simple means of applying &lt;code&gt;grappler&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="org0c58115"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org0c58115-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.core.protobuf &lt;span class="im"&gt;import&lt;/span&gt; config_pb2&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-3" data-line-number="3"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.framework &lt;span class="im"&gt;import&lt;/span&gt; ops&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-4" data-line-number="4"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.framework &lt;span class="im"&gt;import&lt;/span&gt; importer&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-5" data-line-number="5"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.framework &lt;span class="im"&gt;import&lt;/span&gt; meta_graph&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-7" data-line-number="7"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.grappler &lt;span class="im"&gt;import&lt;/span&gt; cluster&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-8" data-line-number="8"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.grappler &lt;span class="im"&gt;import&lt;/span&gt; tf_optimizer&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-11" data-line-number="11"&gt;&lt;span class="cf"&gt;try&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-12" data-line-number="12"&gt;    gcluster &lt;span class="op"&gt;=&lt;/span&gt; cluster.Cluster()&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-13" data-line-number="13"&gt;&lt;span class="cf"&gt;except&lt;/span&gt; tf.errors.UnavailableError:&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-14" data-line-number="14"&gt;    &lt;span class="cf"&gt;pass&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-16" data-line-number="16"&gt;config &lt;span class="op"&gt;=&lt;/span&gt; config_pb2.ConfigProto()&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-17" data-line-number="17"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-19" data-line-number="19"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; normalize_tf_graph(graph_output, graph_inputs&lt;span class="op"&gt;=&lt;/span&gt;[]):&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-20" data-line-number="20"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Use grappler to normalize a graph.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-22" data-line-number="22"&gt;&lt;span class="co"&gt;    Arguments&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-23" data-line-number="23"&gt;&lt;span class="co"&gt;    =========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-24" data-line-number="24"&gt;&lt;span class="co"&gt;    graph_output: Tensor&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-25" data-line-number="25"&gt;&lt;span class="co"&gt;      A tensor we want to consider as &amp;quot;output&amp;quot; of a FuncGraph.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-26" data-line-number="26"&gt;&lt;span class="co"&gt;    graph_inputs: list of Tensor (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-27" data-line-number="27"&gt;&lt;span class="co"&gt;      Any tensors that correspond to inputs for the given output node.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-28" data-line-number="28"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-29" data-line-number="29"&gt;&lt;span class="co"&gt;    Returns&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-30" data-line-number="30"&gt;&lt;span class="co"&gt;    =======&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-31" data-line-number="31"&gt;&lt;span class="co"&gt;    The simplified graph.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-32" data-line-number="32"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-33" data-line-number="33"&gt;    train_op &lt;span class="op"&gt;=&lt;/span&gt; graph_output.graph.get_collection_ref(ops.GraphKeys.TRAIN_OP)&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-34" data-line-number="34"&gt;    train_op.clear()&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-35" data-line-number="35"&gt;    train_op.extend([graph_output] &lt;span class="op"&gt;+&lt;/span&gt; graph_inputs)&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-36" data-line-number="36"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-37" data-line-number="37"&gt;    &lt;span class="co"&gt;# if graph_inputs is not None:&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-38" data-line-number="38"&gt;    &lt;span class="co"&gt;#     # ops.GraphKeys.MODEL_VARIABLES?&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-39" data-line-number="39"&gt;    &lt;span class="co"&gt;#     train_vars = graph_output.graph.get_collection_ref(ops.GraphKeys.TRAINABLE_VARIABLES),&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-40" data-line-number="40"&gt;    &lt;span class="co"&gt;#     train_vars.clear()&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-41" data-line-number="41"&gt;    &lt;span class="co"&gt;#     train_vars.extend(graph_inputs)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-42" data-line-number="42"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-43" data-line-number="43"&gt;    metagraph &lt;span class="op"&gt;=&lt;/span&gt; meta_graph.create_meta_graph_def(graph&lt;span class="op"&gt;=&lt;/span&gt;graph_output.graph)&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-44" data-line-number="44"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-45" data-line-number="45"&gt;    optimized_graphdef &lt;span class="op"&gt;=&lt;/span&gt; tf_optimizer.OptimizeGraph(&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-46" data-line-number="46"&gt;        config, metagraph, verbose&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;, cluster&lt;span class="op"&gt;=&lt;/span&gt;gcluster)&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-47" data-line-number="47"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-48" data-line-number="48"&gt;    optimized_graph &lt;span class="op"&gt;=&lt;/span&gt; ops.Graph()&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-49" data-line-number="49"&gt;    &lt;span class="cf"&gt;with&lt;/span&gt; optimized_graph.as_default():&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-50" data-line-number="50"&gt;        importer.import_graph_def(optimized_graphdef, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&amp;quot;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-51" data-line-number="51"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-52" data-line-number="52"&gt;    opt_graph_output &lt;span class="op"&gt;=&lt;/span&gt; optimized_graph.get_tensor_by_name(graph_output.name)&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-53" data-line-number="53"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0c58115-54" data-line-number="54"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; opt_graph_output&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In Listing &lt;a href="#org0c58115"&gt;14&lt;/a&gt; we run &lt;code&gt;grappler&lt;/code&gt; on the log-likelihood graph for a normal random variable from Listing &lt;a href="#orgc47d26d"&gt;10&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="org66f178c"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org66f178c-1" data-line-number="1"&gt;normal_log_lik_opt &lt;span class="op"&gt;=&lt;/span&gt; normalize_tf_graph(normal_log_lik)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Listing &lt;a href="#org04c54ca"&gt;16&lt;/a&gt; compares the computed outputs for the original and normalized graphs–given identical inputs.&lt;/p&gt;
&lt;div class="sourceCode" id="org04c54ca"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org04c54ca-1" data-line-number="1"&gt;res_unopt &lt;span class="op"&gt;=&lt;/span&gt; normal_log_lik.&lt;span class="bu"&gt;eval&lt;/span&gt;({&lt;span class="st"&gt;&amp;#39;mu:0&amp;#39;&lt;/span&gt;: np.r_[&lt;span class="dv"&gt;3&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;tau:0&amp;#39;&lt;/span&gt;: np.r_[&lt;span class="dv"&gt;1&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;value:0&amp;#39;&lt;/span&gt;: np.r_[&lt;span class="dv"&gt;1&lt;/span&gt;]},&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-2" data-line-number="2"&gt;                                 session&lt;span class="op"&gt;=&lt;/span&gt;tf.compat.v1.Session(graph&lt;span class="op"&gt;=&lt;/span&gt;normal_log_lik.graph))&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-4" data-line-number="4"&gt;res_opt &lt;span class="op"&gt;=&lt;/span&gt; normal_log_lik_opt.&lt;span class="bu"&gt;eval&lt;/span&gt;({&lt;span class="st"&gt;&amp;#39;mu:0&amp;#39;&lt;/span&gt;: np.r_[&lt;span class="dv"&gt;3&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;tau:0&amp;#39;&lt;/span&gt;: np.r_[&lt;span class="dv"&gt;1&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;value:0&amp;#39;&lt;/span&gt;: np.r_[&lt;span class="dv"&gt;1&lt;/span&gt;]},&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-5" data-line-number="5"&gt;                                  session&lt;span class="op"&gt;=&lt;/span&gt;tf.compat.v1.Session(graph&lt;span class="op"&gt;=&lt;/span&gt;normal_log_lik_opt.graph))&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-7" data-line-number="7"&gt;&lt;span class="co"&gt;# They should be equal, naturally&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-8" data-line-number="8"&gt;&lt;span class="cf"&gt;assert&lt;/span&gt; np.array_equal(res_unopt, res_opt)&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org04c54ca-10" data-line-number="10"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; [res_unopt, res_opt]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orge8b12fa"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orge8b12fa-1" data-line-number="1"&gt;[array([&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;2.9189386&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;float32), array([&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;2.9189386&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;float32)]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orge1da777"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orge1da777-1" data-line-number="1"&gt;tf_dprint(normal_log_lik_opt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre id="org4ebdf85" class="text"&gt;&lt;code&gt;Tensor(Sub):0,  shape=[None]    &amp;quot;Normal_1/log_prob/sub:0&amp;quot;
|  Op(Sub)  &amp;quot;Normal_1/log_prob/sub&amp;quot;
|  |  Tensor(Mul):0,    shape=[None]    &amp;quot;Normal_1/log_prob/mul:0&amp;quot;
|  |  |  Op(Mul)    &amp;quot;Normal_1/log_prob/mul&amp;quot;
|  |  |  |  Tensor(SquaredDifference):0,    shape=[None]    &amp;quot;Normal_1/log_prob/SquaredDifference:0&amp;quot;
|  |  |  |  |  Op(SquaredDifference)    &amp;quot;Normal_1/log_prob/SquaredDifference&amp;quot;
|  |  |  |  |  |  Tensor(RealDiv):0,    shape=[None]    &amp;quot;Normal_1/log_prob/truediv:0&amp;quot;
|  |  |  |  |  |  |  Op(RealDiv)    &amp;quot;Normal_1/log_prob/truediv&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;value:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  |  |  Tensor(RealDiv):0,    shape=[None]    &amp;quot;Normal_1/log_prob/truediv_1:0&amp;quot;
|  |  |  |  |  |  |  Op(RealDiv)    &amp;quot;Normal_1/log_prob/truediv_1&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;mu:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;Normal_1/log_prob/mul/x:0&amp;quot;
|  |  Tensor(AddV2):0,  shape=[None]    &amp;quot;Normal_1/log_prob/add:0&amp;quot;
|  |  |  Op(AddV2)  &amp;quot;Normal_1/log_prob/add&amp;quot;
|  |  |  |  Tensor(Log):0,  shape=[None]    &amp;quot;Normal_1/log_prob/Log:0&amp;quot;
|  |  |  |  |  Op(Log)  &amp;quot;Normal_1/log_prob/Log&amp;quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;Normal_1/log_prob/add/x:0&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the output of Listing &lt;a href="#orge1da777"&gt;18&lt;/a&gt;, we can see that &lt;code&gt;grappler&lt;/code&gt; has performed some constant folding and has reordered the inputs in &lt;code&gt;&amp;quot;add_1_1&amp;quot;&lt;/code&gt;–among other things.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="minikanren-transform-relations" class="level2"&gt;
&lt;h2&gt;miniKanren Transform Relations&lt;/h2&gt;
&lt;p&gt;In Listing &lt;a href="#org0ad3a96"&gt;20&lt;/a&gt;, we create miniKanren functions that identify the aforementioned &lt;code&gt;SquaredDifference&lt;/code&gt; “chains” and perform the re-centered/scaled &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; substitution.&lt;/p&gt;
&lt;div class="sourceCode" id="org0ad3a96"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org0ad3a96-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; itertools &lt;span class="im"&gt;import&lt;/span&gt; chain&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; functools &lt;span class="im"&gt;import&lt;/span&gt; partial&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-4" data-line-number="4"&gt;&lt;span class="im"&gt;from&lt;/span&gt; unification &lt;span class="im"&gt;import&lt;/span&gt; var, reify, unify&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-6" data-line-number="6"&gt;&lt;span class="im"&gt;from&lt;/span&gt; kanren &lt;span class="im"&gt;import&lt;/span&gt; run, eq, lall, conde&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-7" data-line-number="7"&gt;&lt;span class="im"&gt;from&lt;/span&gt; kanren.goals &lt;span class="im"&gt;import&lt;/span&gt; not_equalo&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-8" data-line-number="8"&gt;&lt;span class="im"&gt;from&lt;/span&gt; kanren.core &lt;span class="im"&gt;import&lt;/span&gt; goaleval&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-10" data-line-number="10"&gt;&lt;span class="im"&gt;from&lt;/span&gt; symbolic_pymc.tensorflow.meta &lt;span class="im"&gt;import&lt;/span&gt; mt&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-11" data-line-number="11"&gt;&lt;span class="im"&gt;from&lt;/span&gt; symbolic_pymc.relations.graph &lt;span class="im"&gt;import&lt;/span&gt; graph_applyo, reduceo&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-12" data-line-number="12"&gt;&lt;span class="im"&gt;from&lt;/span&gt; symbolic_pymc.etuple &lt;span class="im"&gt;import&lt;/span&gt; ExpressionTuple, etuple&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-14" data-line-number="14"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-15" data-line-number="15"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; onceo(goal):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-16" data-line-number="16"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;A non-relational operator that yields only the first result from a relation.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-17" data-line-number="17"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; onceo_goal(s):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-18" data-line-number="18"&gt;        &lt;span class="kw"&gt;nonlocal&lt;/span&gt; goal&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-19" data-line-number="19"&gt;        g &lt;span class="op"&gt;=&lt;/span&gt; reify(goal, s)&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-20" data-line-number="20"&gt;        g_stream &lt;span class="op"&gt;=&lt;/span&gt; goaleval(g)(s)&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-21" data-line-number="21"&gt;        s &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;next&lt;/span&gt;(g_stream)&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-22" data-line-number="22"&gt;        &lt;span class="cf"&gt;yield&lt;/span&gt; s&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-23" data-line-number="23"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-24" data-line-number="24"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; onceo_goal&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-25" data-line-number="25"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-26" data-line-number="26"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-27" data-line-number="27"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; tf_graph_applyo(relation, a, b):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-28" data-line-number="28"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Construct a `graph_applyo` goal that evaluates a relation only at tensor nodes in a meta graph.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-29" data-line-number="29"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-30" data-line-number="30"&gt;&lt;span class="co"&gt;    Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-31" data-line-number="31"&gt;&lt;span class="co"&gt;    ----------&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-32" data-line-number="32"&gt;&lt;span class="co"&gt;    relation: function&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-33" data-line-number="33"&gt;&lt;span class="co"&gt;      A binary relation/goal constructor function&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-34" data-line-number="34"&gt;&lt;span class="co"&gt;    a: lvar, meta graph, or etuple&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-35" data-line-number="35"&gt;&lt;span class="co"&gt;      The left-hand side of the relation.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-36" data-line-number="36"&gt;&lt;span class="co"&gt;    b: lvar, meta graph, or etuple&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-37" data-line-number="37"&gt;&lt;span class="co"&gt;      The right-hand side of the relation&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-38" data-line-number="38"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-39" data-line-number="39"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-40" data-line-number="40"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; _expand_some_nodes(node):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-41" data-line-number="41"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(node, mt.Tensor) &lt;span class="kw"&gt;and&lt;/span&gt; node.op &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-42" data-line-number="42"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; etuple(node.operator, &lt;span class="op"&gt;*&lt;/span&gt;node.inputs, eval_obj&lt;span class="op"&gt;=&lt;/span&gt;node)&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-43" data-line-number="43"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-44" data-line-number="44"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-45" data-line-number="45"&gt;    gapplyo &lt;span class="op"&gt;=&lt;/span&gt; partial(graph_applyo, relation, preprocess_graph&lt;span class="op"&gt;=&lt;/span&gt;_expand_some_nodes)&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-46" data-line-number="46"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; gapplyo(a, b)&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-47" data-line-number="47"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-48" data-line-number="48"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-49" data-line-number="49"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; shift_squared_terms(in_obj, graph_inputs&lt;span class="op"&gt;=&lt;/span&gt;[]):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-50" data-line-number="50"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Re-center/scale SquaredDifference terms corresponding to hierarchical normals.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-51" data-line-number="51"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-52" data-line-number="52"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; shift_squared_subso(in_graph, out_subs):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-53" data-line-number="53"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Construct a goal that identifies the SquaredDifference terms we desire.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-54" data-line-number="54"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-55" data-line-number="55"&gt;        Y_lv, X_lv, mu_lv &lt;span class="op"&gt;=&lt;/span&gt; var(), var(), var()&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-56" data-line-number="56"&gt;        X_denom_lv &lt;span class="op"&gt;=&lt;/span&gt; var()&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-57" data-line-number="57"&gt;        X_form_lv &lt;span class="op"&gt;=&lt;/span&gt; mt.Placeholder(dtype&lt;span class="op"&gt;=&lt;/span&gt;var(), shape&lt;span class="op"&gt;=&lt;/span&gt;var(), name&lt;span class="op"&gt;=&lt;/span&gt;var())&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-58" data-line-number="58"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-59" data-line-number="59"&gt;        sqr_diff_Y_lv &lt;span class="op"&gt;=&lt;/span&gt; mt.SquaredDifference(Y_lv,&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-60" data-line-number="60"&gt;                                             mt.realdiv(X_lv, var(), name&lt;span class="op"&gt;=&lt;/span&gt;var()),&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-61" data-line-number="61"&gt;                                             name&lt;span class="op"&gt;=&lt;/span&gt;var())&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-62" data-line-number="62"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-63" data-line-number="63"&gt;        &lt;span class="kw"&gt;def&lt;/span&gt; Y_sqrdiffo(in_g, out_g):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-64" data-line-number="64"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; lall(eq(in_g, sqr_diff_Y_lv),&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-65" data-line-number="65"&gt;                        &lt;span class="co"&gt;# This just makes sure that we&amp;#39;re only considering X&amp;#39;s&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-66" data-line-number="66"&gt;                        &lt;span class="co"&gt;# that are Placeholders.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-67" data-line-number="67"&gt;                        eq(X_lv, X_form_lv))&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-68" data-line-number="68"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-69" data-line-number="69"&gt;        sqr_diff_X_lv &lt;span class="op"&gt;=&lt;/span&gt; mt.SquaredDifference(mt.mul(X_denom_lv, X_lv, name&lt;span class="op"&gt;=&lt;/span&gt;var()),&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-70" data-line-number="70"&gt;                                             &lt;span class="co"&gt;# mt.realdiv(X_lv, X_denom_lv, name=var()),&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-71" data-line-number="71"&gt;                                             mu_lv,&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-72" data-line-number="72"&gt;                                             name&lt;span class="op"&gt;=&lt;/span&gt;var())&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-73" data-line-number="73"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-74" data-line-number="74"&gt;        &lt;span class="kw"&gt;def&lt;/span&gt; X_sqrdiffo(in_g, out_g):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-75" data-line-number="75"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; eq(in_g, sqr_diff_X_lv)&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-76" data-line-number="76"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-77" data-line-number="77"&gt;        &lt;span class="co"&gt;# X_new_mt = mt.mul(X_denom_lv, mt.add(mu_lv, X_lv))&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-78" data-line-number="78"&gt;        X_new_mt &lt;span class="op"&gt;=&lt;/span&gt; mt.add(mu_lv, mt.mul(X_denom_lv, X_lv))&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-79" data-line-number="79"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-80" data-line-number="80"&gt;        res &lt;span class="op"&gt;=&lt;/span&gt; lall(&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-81" data-line-number="81"&gt;            &lt;span class="co"&gt;# The first (y - x/a)**2 (anywhere in the graph)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-82" data-line-number="82"&gt;            tf_graph_applyo(Y_sqrdiffo, in_graph, in_graph),&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-83" data-line-number="83"&gt;            &lt;span class="co"&gt;# The corresponding (x/b - z)**2 (also anywhere else in the graph)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-84" data-line-number="84"&gt;            tf_graph_applyo(X_sqrdiffo, in_graph, in_graph),&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-85" data-line-number="85"&gt;            &lt;span class="co"&gt;# Not sure if we need this, but we definitely don&amp;#39;t want X == Y&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-86" data-line-number="86"&gt;            (not_equalo, [Y_lv, X_lv], &lt;span class="va"&gt;True&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-87" data-line-number="87"&gt;            &lt;span class="co"&gt;# Set the &amp;quot;output&amp;quot;/second argument to the resulting substitution&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-88" data-line-number="88"&gt;            &lt;span class="co"&gt;# pair&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-89" data-line-number="89"&gt;            eq(out_subs, [X_lv, X_new_mt]))&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-90" data-line-number="90"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-91" data-line-number="91"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; res&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-92" data-line-number="92"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-93" data-line-number="93"&gt;    &lt;span class="co"&gt;# Normalize and convert to a meta graph&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-94" data-line-number="94"&gt;    in_obj &lt;span class="op"&gt;=&lt;/span&gt; mt(normalize_tf_graph(in_obj, graph_inputs&lt;span class="op"&gt;=&lt;/span&gt;graph_inputs))&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-95" data-line-number="95"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-96" data-line-number="96"&gt;    &lt;span class="co"&gt;# This run returns all the substitutions found in the graph&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-97" data-line-number="97"&gt;    subs_lv &lt;span class="op"&gt;=&lt;/span&gt; var()&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-98" data-line-number="98"&gt;    subs_res &lt;span class="op"&gt;=&lt;/span&gt; run(&lt;span class="dv"&gt;0&lt;/span&gt;, subs_lv, shift_squared_subso(in_obj, subs_lv))&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-99" data-line-number="99"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-100" data-line-number="100"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; subs_replaceo(in_g, out_g):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-101" data-line-number="101"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Create a goal that applies substitutions to a graph.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-102" data-line-number="102"&gt;        &lt;span class="kw"&gt;def&lt;/span&gt; _subs_replaceo(in_g, out_g):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-103" data-line-number="103"&gt;            x_g &lt;span class="op"&gt;=&lt;/span&gt; conde(&lt;span class="op"&gt;*&lt;/span&gt;[[eq(in_g, x), eq(out_g, y)]&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-104" data-line-number="104"&gt;                          &lt;span class="cf"&gt;for&lt;/span&gt; x, y &lt;span class="kw"&gt;in&lt;/span&gt; subs_res])&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-105" data-line-number="105"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; x_g&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-106" data-line-number="106"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-107" data-line-number="107"&gt;        g &lt;span class="op"&gt;=&lt;/span&gt; onceo(tf_graph_applyo(_subs_replaceo, in_g, out_g))&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-108" data-line-number="108"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; g&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-109" data-line-number="109"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-110" data-line-number="110"&gt;    &lt;span class="co"&gt;# Apply each substitution once&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-111" data-line-number="111"&gt;    out_graph_lv &lt;span class="op"&gt;=&lt;/span&gt; var()&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-112" data-line-number="112"&gt;    res &lt;span class="op"&gt;=&lt;/span&gt; run(&lt;span class="dv"&gt;1&lt;/span&gt;, out_graph_lv, reduceo(subs_replaceo, in_obj, out_graph_lv))&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-113" data-line-number="113"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-114" data-line-number="114"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; res:&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-115" data-line-number="115"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-116" data-line-number="116"&gt;        &lt;span class="kw"&gt;def&lt;/span&gt; reify_res(graph_res):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-117" data-line-number="117"&gt;            &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Reconstruct and/or reify meta object results.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-118" data-line-number="118"&gt;            from_etuple &lt;span class="op"&gt;=&lt;/span&gt; graph_res.eval_obj &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(graph_res, ExpressionTuple) &lt;span class="cf"&gt;else&lt;/span&gt; graph_res&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-119" data-line-number="119"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;hasattr&lt;/span&gt;(from_etuple, &lt;span class="st"&gt;&amp;#39;reify&amp;#39;&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-120" data-line-number="120"&gt;                &lt;span class="cf"&gt;return&lt;/span&gt; from_etuple.reify()&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-121" data-line-number="121"&gt;            &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-122" data-line-number="122"&gt;                &lt;span class="cf"&gt;return&lt;/span&gt; from_etuple&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-123" data-line-number="123"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-124" data-line-number="124"&gt;        res &lt;span class="op"&gt;=&lt;/span&gt; [reify_res(r) &lt;span class="cf"&gt;for&lt;/span&gt; r &lt;span class="kw"&gt;in&lt;/span&gt; res]&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-125" data-line-number="125"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-126" data-line-number="126"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;len&lt;/span&gt;(res) &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-127" data-line-number="127"&gt;        graph_res &lt;span class="op"&gt;=&lt;/span&gt; res[&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-128" data-line-number="128"&gt;        &lt;span class="co"&gt;# return graph_res, subs_res&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ad3a96-129" data-line-number="129"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; normalize_tf_graph(graph_res, graph_inputs&lt;span class="op"&gt;=&lt;/span&gt;graph_inputs), subs_res&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As a test, we will run our miniKanren relations on the log-likelihood graph for a normal-normal hierarchical model in Listing &lt;a href="#org29e93d9"&gt;21&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="org29e93d9"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org29e93d9-1" data-line-number="1"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; graph_mode(), tf.Graph().as_default() &lt;span class="im"&gt;as&lt;/span&gt; demo_graph:&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-2" data-line-number="2"&gt;    X_tfp &lt;span class="op"&gt;=&lt;/span&gt; tfp.distributions.normal.Normal(&lt;span class="fl"&gt;0.0&lt;/span&gt;, &lt;span class="fl"&gt;1.0&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-4" data-line-number="4"&gt;    x_tf &lt;span class="op"&gt;=&lt;/span&gt; tf.compat.v1.placeholder(tf.float32, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;value_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-5" data-line-number="5"&gt;                                    shape&lt;span class="op"&gt;=&lt;/span&gt;tf.TensorShape([&lt;span class="va"&gt;None&lt;/span&gt;]))&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-7" data-line-number="7"&gt;    tau_tf &lt;span class="op"&gt;=&lt;/span&gt; tf.compat.v1.placeholder(tf.float32, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;tau&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-8" data-line-number="8"&gt;                                      shape&lt;span class="op"&gt;=&lt;/span&gt;tf.TensorShape([&lt;span class="va"&gt;None&lt;/span&gt;]))&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-10" data-line-number="10"&gt;    Y_tfp &lt;span class="op"&gt;=&lt;/span&gt; tfp.distributions.normal.Normal(x_tf, tau_tf, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-12" data-line-number="12"&gt;    y_tf &lt;span class="op"&gt;=&lt;/span&gt; tf.compat.v1.placeholder(tf.float32, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;value_y&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-13" data-line-number="13"&gt;                                    shape&lt;span class="op"&gt;=&lt;/span&gt;tf.TensorShape([&lt;span class="va"&gt;None&lt;/span&gt;]))&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-14" data-line-number="14"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-15" data-line-number="15"&gt;    hier_norm_lik &lt;span class="op"&gt;=&lt;/span&gt; Y_tfp.log_prob(y_tf) &lt;span class="op"&gt;+&lt;/span&gt; X_tfp.log_prob(x_tf)&lt;/a&gt;
&lt;a class="sourceLine" id="org29e93d9-16" data-line-number="16"&gt;    hier_norm_lik &lt;span class="op"&gt;=&lt;/span&gt; normalize_tf_graph(hier_norm_lik)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Listing &lt;a href="#org59b1e29"&gt;22&lt;/a&gt; shows the form that a graph representing a hierarchical normal-normal model will generally take in TFP.&lt;/p&gt;
&lt;div class="sourceCode" id="org59b1e29"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org59b1e29-1" data-line-number="1"&gt;tf_dprint(hier_norm_lik)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre id="org707d199" class="text"&gt;&lt;code&gt;Tensor(AddV2):0,    shape=[None]    &amp;quot;add:0&amp;quot;
|  Op(AddV2)    &amp;quot;add&amp;quot;
|  |  Tensor(Sub):0,    shape=[None]    &amp;quot;X_1/log_prob/sub:0&amp;quot;
|  |  |  Op(Sub)    &amp;quot;X_1/log_prob/sub&amp;quot;
|  |  |  |  Tensor(Mul):0,  shape=[None]    &amp;quot;X_1/log_prob/mul:0&amp;quot;
|  |  |  |  |  Op(Mul)  &amp;quot;X_1/log_prob/mul&amp;quot;
|  |  |  |  |  |  Tensor(SquaredDifference):0,  shape=[None]    &amp;quot;X_1/log_prob/SquaredDifference:0&amp;quot;
|  |  |  |  |  |  |  Op(SquaredDifference)  &amp;quot;X_1/log_prob/SquaredDifference&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Mul):0,  shape=[None]    &amp;quot;X_1/log_prob/truediv:0&amp;quot;
|  |  |  |  |  |  |  |  |  Op(Mul)  &amp;quot;X_1/log_prob/truediv&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;ConstantFolding/X_1/log_prob/truediv_recip:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;value_x:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;X_1/log_prob/truediv_1:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;Y_1/log_prob/mul/x:0&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;Y_1/log_prob/add/x:0&amp;quot;
|  |  Tensor(Sub):0,    shape=[None]    &amp;quot;Y_1/log_prob/sub:0&amp;quot;
|  |  |  Op(Sub)    &amp;quot;Y_1/log_prob/sub&amp;quot;
|  |  |  |  Tensor(Mul):0,  shape=[None]    &amp;quot;Y_1/log_prob/mul:0&amp;quot;
|  |  |  |  |  Op(Mul)  &amp;quot;Y_1/log_prob/mul&amp;quot;
|  |  |  |  |  |  Tensor(SquaredDifference):0,  shape=[None]    &amp;quot;Y_1/log_prob/SquaredDifference:0&amp;quot;
|  |  |  |  |  |  |  Op(SquaredDifference)  &amp;quot;Y_1/log_prob/SquaredDifference&amp;quot;
|  |  |  |  |  |  |  |  Tensor(RealDiv):0,  shape=[None]    &amp;quot;Y_1/log_prob/truediv:0&amp;quot;
|  |  |  |  |  |  |  |  |  Op(RealDiv)  &amp;quot;Y_1/log_prob/truediv&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;value_y:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(RealDiv):0,  shape=[None]    &amp;quot;Y_1/log_prob/truediv_1:0&amp;quot;
|  |  |  |  |  |  |  |  |  Op(RealDiv)  &amp;quot;Y_1/log_prob/truediv_1&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;value_x:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;Y_1/log_prob/mul/x:0&amp;quot;
|  |  |  |  Tensor(AddV2):0,    shape=[None]    &amp;quot;Y_1/log_prob/add:0&amp;quot;
|  |  |  |  |  Op(AddV2)    &amp;quot;Y_1/log_prob/add&amp;quot;
|  |  |  |  |  |  Tensor(Log):0,    shape=[None]    &amp;quot;Y_1/log_prob/Log:0&amp;quot;
|  |  |  |  |  |  |  Op(Log)    &amp;quot;Y_1/log_prob/Log&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;Y_1/log_prob/add/x:0&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Listing &lt;a href="#orgf81b6e5"&gt;24&lt;/a&gt; runs our transformation and Listing &lt;a href="#orgae5d6c4"&gt;25&lt;/a&gt; prints the resulting graph.&lt;/p&gt;
&lt;div class="sourceCode" id="orgf81b6e5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgf81b6e5-1" data-line-number="1"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; graph_mode(), demo_graph.as_default():&lt;/a&gt;
&lt;a class="sourceLine" id="orgf81b6e5-2" data-line-number="2"&gt;    test_output_res, test_remaps &lt;span class="op"&gt;=&lt;/span&gt; shift_squared_terms(hier_norm_lik, graph_inputs&lt;span class="op"&gt;=&lt;/span&gt;[x_tf, y_tf])&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgae5d6c4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgae5d6c4-1" data-line-number="1"&gt;tf_dprint(test_output_res)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre id="orgbd059f9" class="text"&gt;&lt;code&gt;Tensor(AddV2):0,    shape=[None]    &amp;quot;add_2:0&amp;quot;
|  Op(AddV2)    &amp;quot;add_2&amp;quot;
|  |  Tensor(Sub):0,    shape=[None]    &amp;quot;X_1/log_prob/sub_1:0&amp;quot;
|  |  |  Op(Sub)    &amp;quot;X_1/log_prob/sub_1&amp;quot;
|  |  |  |  Tensor(Mul):0,  shape=[None]    &amp;quot;X_1/log_prob/mul_1:0&amp;quot;
|  |  |  |  |  Op(Mul)  &amp;quot;X_1/log_prob/mul_1&amp;quot;
|  |  |  |  |  |  Tensor(SquaredDifference):0,  shape=[None]    &amp;quot;X_1/log_prob/SquaredDifference_1:0&amp;quot;
|  |  |  |  |  |  |  Op(SquaredDifference)  &amp;quot;X_1/log_prob/SquaredDifference_1&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;X_1/log_prob/truediv_1:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Mul):0,  shape=[None]    &amp;quot;X_1/log_prob/truediv_2:0&amp;quot;
|  |  |  |  |  |  |  |  |  Op(Mul)  &amp;quot;X_1/log_prob/truediv_2&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Add):0,    shape=[None]    &amp;quot;Add_1:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  |  Op(Add)    &amp;quot;Add_1&amp;quot;
|  |  |  |  |  |  |  |  |  |  |  |  Tensor(Mul):0,  shape=[None]    &amp;quot;Mul:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  |  |  |  Op(Mul)  &amp;quot;Mul&amp;quot;
|  |  |  |  |  |  |  |  |  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;ConstantFolding/X_1/log_prob/truediv_recip:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;value_x:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;X_1/log_prob/truediv_1:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;ConstantFolding/X_1/log_prob/truediv_recip:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;Y_1/log_prob/mul/x:0&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;Y_1/log_prob/add/x:0&amp;quot;
|  |  Tensor(Sub):0,    shape=[None]    &amp;quot;Y_1/log_prob/sub_1:0&amp;quot;
|  |  |  Op(Sub)    &amp;quot;Y_1/log_prob/sub_1&amp;quot;
|  |  |  |  Tensor(Mul):0,  shape=[None]    &amp;quot;Y_1/log_prob/mul_1:0&amp;quot;
|  |  |  |  |  Op(Mul)  &amp;quot;Y_1/log_prob/mul_1&amp;quot;
|  |  |  |  |  |  Tensor(SquaredDifference):0,  shape=[None]    &amp;quot;Y_1/log_prob/SquaredDifference_1:0&amp;quot;
|  |  |  |  |  |  |  Op(SquaredDifference)  &amp;quot;Y_1/log_prob/SquaredDifference_1&amp;quot;
|  |  |  |  |  |  |  |  Tensor(RealDiv):0,  shape=[None]    &amp;quot;Y_1/log_prob/truediv:0&amp;quot;
|  |  |  |  |  |  |  |  |  Op(RealDiv)  &amp;quot;Y_1/log_prob/truediv&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;value_y:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(RealDiv):0,  shape=[None]    &amp;quot;Y_1/log_prob/truediv_1_1:0&amp;quot;
|  |  |  |  |  |  |  |  |  Op(RealDiv)  &amp;quot;Y_1/log_prob/truediv_1_1&amp;quot;
|  |  |  |  |  |  |  |  |  |  Tensor(Add):0,    shape=[None]    &amp;quot;Add_1:0&amp;quot;
|  |  |  |  |  |  |  |  |  |  |  ...
|  |  |  |  |  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;Y_1/log_prob/mul/x:0&amp;quot;
|  |  |  |  Tensor(AddV2):0,    shape=[None]    &amp;quot;Y_1/log_prob/add:0&amp;quot;
|  |  |  |  |  Op(AddV2)    &amp;quot;Y_1/log_prob/add&amp;quot;
|  |  |  |  |  |  Tensor(Log):0,    shape=[None]    &amp;quot;Y_1/log_prob/Log:0&amp;quot;
|  |  |  |  |  |  |  Op(Log)    &amp;quot;Y_1/log_prob/Log&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[None]    &amp;quot;tau:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;Y_1/log_prob/add/x:0&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From Listing &lt;a href="#orgae5d6c4"&gt;25&lt;/a&gt; we can see that &lt;code&gt;grappler&lt;/code&gt; is not applying enough algebraic simplifications to reduce the &lt;span class="math inline"&gt;\(\left(\mu + x - \mu \right)^2\)&lt;/span&gt; term.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="transforming-the-log-likelihood-graph" class="level1"&gt;
&lt;h1&gt;Transforming the Log-likelihood Graph&lt;/h1&gt;
&lt;p&gt;Now, we’re ready to apply the transform to the radon model log-likelihood graph.&lt;/p&gt;
&lt;div class="sourceCode" id="org537ce90"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org537ce90-1" data-line-number="1"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; graph_mode(), tf.Graph().as_default() &lt;span class="im"&gt;as&lt;/span&gt; trans_graph: &lt;span class="co"&gt;#logpfn_fg.as_default():&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org537ce90-2" data-line-number="2"&gt;    graph_inputs &lt;span class="op"&gt;=&lt;/span&gt; [logpfn_fg.get_operation_by_name(i.name).outputs[&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org537ce90-3" data-line-number="3"&gt;                    &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; logpfn_cf.structured_input_signature[&lt;span class="dv"&gt;0&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="org537ce90-4" data-line-number="4"&gt;    logpfn_trans_tf, logpfn_remaps &lt;span class="op"&gt;=&lt;/span&gt; shift_squared_terms(logpfn_fg.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;], graph_inputs&lt;span class="op"&gt;=&lt;/span&gt;graph_inputs)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Listing &lt;a href="#org73bcbee"&gt;28&lt;/a&gt; shows the replacements that were made throughout the graph. Two replacements were found and they appear to correspond to the un-centered normal distribution terms &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; in our model–as intended.&lt;/p&gt;
&lt;div class="sourceCode" id="org73bcbee"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org73bcbee-1" data-line-number="1"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; r &lt;span class="kw"&gt;in&lt;/span&gt; logpfn_remaps:&lt;/a&gt;
&lt;a class="sourceLine" id="org73bcbee-2" data-line-number="2"&gt;    [tf_dprint(i) &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; r]&lt;/a&gt;
&lt;a class="sourceLine" id="org73bcbee-3" data-line-number="3"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;------&amp;quot;&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre id="org8c33bb8" class="text"&gt;&lt;code&gt;Tensor(Placeholder):0,  shape=[]    &amp;quot;values_1:0&amp;quot;
Tensor(Add):0,  shape=[]    &amp;quot;Add_12:0&amp;quot;
|  Op(Add)  &amp;quot;Add&amp;quot;
|  |  Tensor(Const):0,  shape=[]    &amp;quot;add_1/x:0&amp;quot;
|  |  Tensor(Mul):0,    shape=[]    &amp;quot;Mul_4:0&amp;quot;
|  |  |  Op(Mul)    &amp;quot;Mul&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&amp;quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[]    &amp;quot;values_1:0&amp;quot;
------
Tensor(Placeholder):0,  shape=[]    &amp;quot;values_5:0&amp;quot;
Tensor(Add):0,  shape=[]    &amp;quot;Add_13:0&amp;quot;
|  Op(Add)  &amp;quot;Add&amp;quot;
|  |  Tensor(Const):0,  shape=[]    &amp;quot;add_1/x:0&amp;quot;
|  |  Tensor(Mul):0,    shape=[]    &amp;quot;Mul_5:0&amp;quot;
|  |  |  Op(Mul)    &amp;quot;Mul&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&amp;quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[]    &amp;quot;values_5:0&amp;quot;
------

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Likewise, Listing &lt;a href="#org0ce0bba"&gt;30&lt;/a&gt; shows all &lt;code&gt;Square&lt;/code&gt; and &lt;code&gt;SquaredDifference&lt;/code&gt; subgraphs that appear in the transformed log-likelihood.&lt;/p&gt;
&lt;div class="sourceCode" id="org0ce0bba"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org0ce0bba-1" data-line-number="1"&gt;square_diff_outs &lt;span class="op"&gt;=&lt;/span&gt; [o.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;] &lt;span class="cf"&gt;for&lt;/span&gt; o &lt;span class="kw"&gt;in&lt;/span&gt; logpfn_trans_tf.graph.get_operations()&lt;/a&gt;
&lt;a class="sourceLine" id="org0ce0bba-2" data-line-number="2"&gt;                    &lt;span class="cf"&gt;if&lt;/span&gt; o.&lt;span class="bu"&gt;type&lt;/span&gt; &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;SquaredDifference&amp;#39;&lt;/span&gt; &lt;span class="kw"&gt;or&lt;/span&gt; o.&lt;span class="bu"&gt;type&lt;/span&gt; &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;Square&amp;#39;&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org0ce0bba-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0ce0bba-4" data-line-number="4"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; t &lt;span class="kw"&gt;in&lt;/span&gt; square_diff_outs[:&lt;span class="dv"&gt;4&lt;/span&gt;]:&lt;/a&gt;
&lt;a class="sourceLine" id="org0ce0bba-5" data-line-number="5"&gt;    tf_dprint(t)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre id="org74e8720" class="text"&gt;&lt;code&gt;Tensor(SquaredDifference):0,    shape=[85]  &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/SquaredDifference_1:0&amp;quot;
|  Op(SquaredDifference)    &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/SquaredDifference_1&amp;quot;
|  |  Tensor(RealDiv):0,    shape=[85]  &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv:0&amp;quot;
|  |  |  Op(RealDiv)    &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv&amp;quot;
|  |  |  |  Tensor(Reshape):0,  shape=[85]  &amp;quot;SampleNormal_3_1/log_prob/Reshape:0&amp;quot;
|  |  |  |  |  Op(Reshape)  &amp;quot;SampleNormal_3_1/log_prob/Reshape&amp;quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[85]  &amp;quot;values_3:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[1]   &amp;quot;SampleNormal_2_1/log_prob/Reshape/shape:0&amp;quot;
|  |  |  |  Tensor(Exp):0,  shape=[]    &amp;quot;exp_2_1/forward/Exp:0&amp;quot;
|  |  |  |  |  Op(Exp)  &amp;quot;exp_2_1/forward/Exp&amp;quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[]    &amp;quot;values_0:0&amp;quot;
|  |  Tensor(RealDiv):0,    shape=[]    &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv_1_1:0&amp;quot;
|  |  |  Op(RealDiv)    &amp;quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv_1_1&amp;quot;
|  |  |  |  Tensor(Add):0,  shape=[]    &amp;quot;Add_12:0&amp;quot;
|  |  |  |  |  Op(Add)  &amp;quot;Add_12&amp;quot;
|  |  |  |  |  |  Tensor(Mul):0,    shape=[]    &amp;quot;Mul_4:0&amp;quot;
|  |  |  |  |  |  |  Op(Mul)    &amp;quot;Mul_4&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[]    &amp;quot;values_1:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;add_1/x:0&amp;quot;
|  |  |  |  Tensor(Exp):0,  shape=[]    &amp;quot;exp_2_1/forward/Exp:0&amp;quot;
|  |  |  |  |  ...
Tensor(SquaredDifference):0,    shape=[]    &amp;quot;Normal_1_1/log_prob/SquaredDifference_1:0&amp;quot;
|  Op(SquaredDifference)    &amp;quot;Normal_1_1/log_prob/SquaredDifference_1&amp;quot;
|  |  Tensor(Mul):0,    shape=[]    &amp;quot;Normal_1_1/log_prob/truediv_1:0&amp;quot;
|  |  |  Op(Mul)    &amp;quot;Normal_1_1/log_prob/truediv_1&amp;quot;
|  |  |  |  Tensor(Add):0,  shape=[]    &amp;quot;Add_12:0&amp;quot;
|  |  |  |  |  Op(Add)  &amp;quot;Add_12&amp;quot;
|  |  |  |  |  |  Tensor(Mul):0,    shape=[]    &amp;quot;Mul_4:0&amp;quot;
|  |  |  |  |  |  |  Op(Mul)    &amp;quot;Mul_4&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[]    &amp;quot;values_1:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;add_1/x:0&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&amp;quot;
|  |  Tensor(Const):0,  shape=[]    &amp;quot;add_1/x:0&amp;quot;
Tensor(SquaredDifference):0,    shape=[85]  &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/SquaredDifference_1:0&amp;quot;
|  Op(SquaredDifference)    &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/SquaredDifference_1&amp;quot;
|  |  Tensor(RealDiv):0,    shape=[85]  &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv:0&amp;quot;
|  |  |  Op(RealDiv)    &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv&amp;quot;
|  |  |  |  Tensor(Reshape):0,  shape=[85]  &amp;quot;SampleNormal_2_1/log_prob/Reshape:0&amp;quot;
|  |  |  |  |  Op(Reshape)  &amp;quot;SampleNormal_2_1/log_prob/Reshape&amp;quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[85]  &amp;quot;values_6:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[1]   &amp;quot;SampleNormal_2_1/log_prob/Reshape/shape:0&amp;quot;
|  |  |  |  Tensor(Exp):0,  shape=[]    &amp;quot;exp_1/forward/Exp:0&amp;quot;
|  |  |  |  |  Op(Exp)  &amp;quot;exp_1/forward/Exp&amp;quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[]    &amp;quot;values_4:0&amp;quot;
|  |  Tensor(RealDiv):0,    shape=[]    &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv_1_1:0&amp;quot;
|  |  |  Op(RealDiv)    &amp;quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv_1_1&amp;quot;
|  |  |  |  Tensor(Add):0,  shape=[]    &amp;quot;Add_13:0&amp;quot;
|  |  |  |  |  Op(Add)  &amp;quot;Add_13&amp;quot;
|  |  |  |  |  |  Tensor(Mul):0,    shape=[]    &amp;quot;Mul_5:0&amp;quot;
|  |  |  |  |  |  |  Op(Mul)    &amp;quot;Mul_5&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[]    &amp;quot;values_5:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;add_1/x:0&amp;quot;
|  |  |  |  Tensor(Exp):0,  shape=[]    &amp;quot;exp_1/forward/Exp:0&amp;quot;
|  |  |  |  |  ...
Tensor(SquaredDifference):0,    shape=[]    &amp;quot;Normal_5/log_prob/SquaredDifference_1:0&amp;quot;
|  Op(SquaredDifference)    &amp;quot;Normal_5/log_prob/SquaredDifference_1&amp;quot;
|  |  Tensor(Mul):0,    shape=[]    &amp;quot;Normal_5/log_prob/truediv_1:0&amp;quot;
|  |  |  Op(Mul)    &amp;quot;Normal_5/log_prob/truediv_1&amp;quot;
|  |  |  |  Tensor(Add):0,  shape=[]    &amp;quot;Add_13:0&amp;quot;
|  |  |  |  |  Op(Add)  &amp;quot;Add_13&amp;quot;
|  |  |  |  |  |  Tensor(Mul):0,    shape=[]    &amp;quot;Mul_5:0&amp;quot;
|  |  |  |  |  |  |  Op(Mul)    &amp;quot;Mul_5&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&amp;quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[]    &amp;quot;values_5:0&amp;quot;
|  |  |  |  |  |  Tensor(Const):0,  shape=[]    &amp;quot;add_1/x:0&amp;quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &amp;quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&amp;quot;
|  |  Tensor(Const):0,  shape=[]    &amp;quot;add_1/x:0&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;/section&gt;
&lt;section id="creating-a-new-log-likelihood-function" class="level1"&gt;
&lt;h1&gt;Creating a new Log-likelihood Function&lt;/h1&gt;
&lt;p&gt;Now that we have a transformed version of the original log-likelihood graph (i.e. &lt;code&gt;logpfn_trans_tf&lt;/code&gt;), we need to create a new &lt;code&gt;FuncGraph&lt;/code&gt; from it. Listing &lt;a href="#org8555c2e"&gt;32&lt;/a&gt; provides a simple function that creates a new &lt;code&gt;ConcreteFunction&lt;/code&gt; from an updated output node.&lt;/p&gt;
&lt;div class="sourceCode" id="org8555c2e"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org8555c2e-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.framework.func_graph &lt;span class="im"&gt;import&lt;/span&gt; FuncGraph&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.eager.function &lt;span class="im"&gt;import&lt;/span&gt; ConcreteFunction&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-3" data-line-number="3"&gt;&lt;span class="im"&gt;from&lt;/span&gt; tensorflow.python.eager.lift_to_graph &lt;span class="im"&gt;import&lt;/span&gt; lift_to_graph&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-6" data-line-number="6"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; new_tf_function(output, orig_cf):&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-7" data-line-number="7"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Create a new ConcreteFunction by replacing a single output in an existing FuncGraph.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-9" data-line-number="9"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-10" data-line-number="10"&gt;    orig_fg &lt;span class="op"&gt;=&lt;/span&gt; orig_cf.graph&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-11" data-line-number="11"&gt;    &lt;span class="co"&gt;# with trans_graph.as_default(): #orig_fg.as_default():&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-13" data-line-number="13"&gt;    logpfn_fg_new &lt;span class="op"&gt;=&lt;/span&gt; FuncGraph(&lt;span class="st"&gt;&amp;#39;logpfn_new&amp;#39;&lt;/span&gt;, orig_fg.collections, orig_fg.capture_by_value)&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-14" data-line-number="14"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-15" data-line-number="15"&gt;    old_to_new_ops &lt;span class="op"&gt;=&lt;/span&gt; lift_to_graph([output],&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-16" data-line-number="16"&gt;                                    logpfn_fg_new,&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-17" data-line-number="17"&gt;                                    add_sources&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-18" data-line-number="18"&gt;                                    handle_captures&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-19" data-line-number="19"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-20" data-line-number="20"&gt;    logpfn_fg_new.structured_input_signature &lt;span class="op"&gt;=&lt;/span&gt; orig_fg.structured_input_signature&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-22" data-line-number="22"&gt;    new_inputs &lt;span class="op"&gt;=&lt;/span&gt; [old_to_new_ops.get(output.graph.get_operation_by_name(i.name).outputs[&lt;span class="dv"&gt;0&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-23" data-line-number="23"&gt;                  &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; orig_cf.structured_input_signature[&lt;span class="dv"&gt;0&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-24" data-line-number="24"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-25" data-line-number="25"&gt;    logpfn_fg_new.inputs &lt;span class="op"&gt;=&lt;/span&gt; new_inputs&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-26" data-line-number="26"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-27" data-line-number="27"&gt;    &lt;span class="cf"&gt;assert&lt;/span&gt; &lt;span class="bu"&gt;all&lt;/span&gt;(i &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt; &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; logpfn_fg_new.inputs)&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-28" data-line-number="28"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-29" data-line-number="29"&gt;    logpfn_fg_new.outputs &lt;span class="op"&gt;=&lt;/span&gt; [old_to_new_ops[output]]&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-30" data-line-number="30"&gt;    logpfn_fg_new.structured_outputs &lt;span class="op"&gt;=&lt;/span&gt; logpfn_fg_new.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-31" data-line-number="31"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-32" data-line-number="32"&gt;    &lt;span class="cf"&gt;assert&lt;/span&gt; logpfn_fg_new.as_graph_element(logpfn_fg_new.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;]) &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-33" data-line-number="33"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-34" data-line-number="34"&gt;    logpfn_new_cf &lt;span class="op"&gt;=&lt;/span&gt; ConcreteFunction(logpfn_fg_new)&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-35" data-line-number="35"&gt;    logpfn_new_cf._arg_keywords &lt;span class="op"&gt;=&lt;/span&gt; orig_cf._arg_keywords&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-36" data-line-number="36"&gt;    logpfn_new_cf._num_positional_args &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;len&lt;/span&gt;(logpfn_fg_new.inputs)&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-37" data-line-number="37"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8555c2e-38" data-line-number="38"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; logpfn_new_cf&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org1bb5328"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org1bb5328-1" data-line-number="1"&gt;logpfn_new_cf &lt;span class="op"&gt;=&lt;/span&gt; new_tf_function(logpfn_trans_tf, logpfn_cf)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The new TF function, &lt;code&gt;logpfn_new_cf&lt;/code&gt;, in Listing &lt;a href="#org8555c2e"&gt;32&lt;/a&gt; is the function we are going to use for sampling from the new log-likelihood.&lt;/p&gt;
&lt;div class="sourceCode" id="org7bec3c9"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org7bec3c9-1" data-line-number="1"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; logpfn_cf(&lt;span class="op"&gt;*&lt;/span&gt;init.values()) &lt;span class="op"&gt;-&lt;/span&gt; logpfn_new_cf(&lt;span class="op"&gt;*&lt;/span&gt;init.values())&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgf0ac6d1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgf0ac6d1-1" data-line-number="1"&gt;tf.Tensor(&lt;span class="fl"&gt;0.0&lt;/span&gt;, shape&lt;span class="op"&gt;=&lt;/span&gt;(), dtype&lt;span class="op"&gt;=&lt;/span&gt;float32)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Listing &lt;a href="#org7bec3c9"&gt;34&lt;/a&gt; shows the difference between a transformed and non-transformed log-likelihood value given the same inputs.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="sampling-from-the-new-log-likelihood" class="level1"&gt;
&lt;h1&gt;Sampling from the new Log-likelihood&lt;/h1&gt;
&lt;p&gt;In Listing &lt;a href="#org4a79807"&gt;37&lt;/a&gt;, we reproduce the remaining steps of &lt;code&gt;pm.inference.sampling.sample&lt;/code&gt; and–unnaturally–force the PyMC4 machinery to draw samples from our new transformed log-likelihood function.&lt;/p&gt;
&lt;div class="sourceCode" id="orgf17c3d2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgf17c3d2-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; importlib &lt;span class="im"&gt;import&lt;/span&gt; &lt;span class="bu"&gt;reload&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-4" data-line-number="4"&gt;&lt;span class="co"&gt;# Let&amp;#39;s make sure we save the original function&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-5" data-line-number="5"&gt;&lt;span class="bu"&gt;reload&lt;/span&gt;(pm.inference.sampling)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-6" data-line-number="6"&gt;_build_logp_function &lt;span class="op"&gt;=&lt;/span&gt; pm.inference.sampling.build_logp_function&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-9" data-line-number="9"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; _new_build_logp_function(&lt;span class="op"&gt;*&lt;/span&gt;args, &lt;span class="op"&gt;**&lt;/span&gt;kwargs):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-10" data-line-number="10"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; logpfn_new_cf, init&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf17c3d2-12" data-line-number="12"&gt;pm.inference.sampling.build_logp_function &lt;span class="op"&gt;=&lt;/span&gt; _new_build_logp_function&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org4a79807"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org4a79807-1" data-line-number="1"&gt;az_trace &lt;span class="op"&gt;=&lt;/span&gt; sample(model)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;figure id="fig:transformed-model-plot-energy"&gt;
&lt;img src="https://brandonwillard.github.io/figures/transformed-model-plot-energy.png" alt="" /&gt;
&lt;figcaption&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure id="fig:transformed-model-plot-trace"&gt;
&lt;img src="https://brandonwillard.github.io/figures/transformed-model-plot-trace.png" alt="" /&gt;
&lt;figcaption&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/section&gt;
&lt;section id="discussion" class="level1"&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;The goals in the two separate &lt;code&gt;run&lt;/code&gt; calls we used in Listing &lt;a href="#org0ad3a96"&gt;20&lt;/a&gt; could have been combined into a single &lt;code&gt;run&lt;/code&gt;. This could’ve been accomplished using some “meta” steps (e.g. construct and evaluate a goal on-the-fly within a miniKanren) or special goals for reading from a miniKanren-generated &lt;code&gt;dict&lt;/code&gt;s or association lists. Goals of this nature are not uncommon (e.g. type inference and inhabitation exmaples), and serve to demonstrate the great breadth of activity possible within relational context of miniKanren.&lt;/p&gt;
&lt;p&gt;However, the point we want to make doesn’t require much sophistication. Instead, we wanted to demonstrate how a non-trivial “pattern” can be specified and matched using &lt;code&gt;symbolic-pymc&lt;/code&gt;, and how easily those results could be used to transform a graph.&lt;/p&gt;
&lt;p&gt;More specifically, our goal &lt;code&gt;shift_squared_subso&lt;/code&gt; in &lt;a href="#org0ad3a96"&gt;20&lt;/a&gt; demonstrates &lt;strong&gt;the way in which we were able to specify desired structure(s) within a graph&lt;/strong&gt;. We defined one pattern, &lt;code&gt;Y_sqrdiffo&lt;/code&gt;, to match anywhere in the graph then another pattern, &lt;code&gt;X_sqrdiffo&lt;/code&gt;, that relied on matched terms from &lt;code&gt;Y_sqrdiffo&lt;/code&gt; and could also be matched/found anywhere else in the same graph.&lt;/p&gt;
&lt;p&gt;Furthermore, our substitutions needed information from both “matched” subgraphs. Specifically, substitution pairs similar to &lt;code&gt;(x, z + x)&lt;/code&gt;. Within this framework, we could just as easily have included &lt;code&gt;y&lt;/code&gt;–or any terms from either successfully matched subgraph–in the substitution expressions.&lt;/p&gt;
&lt;p&gt;In sample-space, the search patterns and substitutions are much easier to specify exactly because they’re single-subgraph patterns that themselves are the subgraphs to be replaced (i.e. if we find a non-standard normal, replace it with a shifted/scaled standard normal). In log-space, we chose to find distinct subgraph “chains”, i.e. all &lt;code&gt;(y - x)**2&lt;/code&gt; and &lt;code&gt;(x - z)**2&lt;/code&gt; pairs (i.e. “connected” by an “unknown” term &lt;code&gt;x&lt;/code&gt;), since these are produced by the log-likelihood form of hierarchical normal distributions.&lt;/p&gt;
&lt;p&gt;As a result, we had a non-trivial structure/“pattern” to express–and execute. Using conventional graph search-and-replace functionality would’ve required much more orchestration and resulted considerably less flexible code with little-to-no reusability. In our case, the goals &lt;code&gt;onceo&lt;/code&gt; and &lt;code&gt;tf_graph_applyo&lt;/code&gt; are universal and the forms in &lt;code&gt;shift_squared_subso&lt;/code&gt; can be easily changed to account for more sophisticated (or entirely distinct) patterns and substitutions.&lt;/p&gt;
&lt;p&gt;Most related graph manipulation offerings make it easy to find a single subgraph that matches a pattern, but not potentially “co-dependent” and/or distinct subgraphs. In the end, the developer will often have to manually implement a “global” state and orchestrate multiple single-subgraph searches and their results.&lt;/p&gt;
&lt;p&gt;For single search-and-replace objectives, this amount of manual developer intervention/orchestration might be excusable; however, for objectives requiring the evaluation of multiple graph transformation, this approach is mostly unmaintainable and extremely difficult to compartmentalize.&lt;/p&gt;
&lt;p&gt;This demonstration barely even scratches the surface of what’s possible using miniKanren and relational programming for graph manipulation and symbolic statistical model optimization. As the &lt;code&gt;symbolic-pymc&lt;/code&gt; project advances, we’ll cover examples in which miniKanren’s more distinct offerings are demonstrated.&lt;/p&gt;
&lt;/section&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content><category term="pymc4"></category><category term="tensorflow"></category><category term="symbolic computation"></category><category term="python"></category><category term="symbolic-pymc"></category></entry><entry><title>Random Variables in Theano</title><link href="https://brandonwillard.github.io/random-variables-in-theano.html" rel="alternate"></link><published>2018-12-28T00:00:00-06:00</published><updated>2019-02-04T00:00:00-06:00</updated><author><name>Brandon T. Willard</name></author><id>tag:brandonwillard.github.io,2018-12-28:/random-variables-in-theano.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon T. Willard" /&gt;
  &lt;title&gt;Random Variables in Theano&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;style type="text/css"&gt;
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  &lt;/style&gt;
  &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;Random Variables in Theano&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon T. Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2018–12–28&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;div class="abstract"&gt;
&lt;p&gt;Continuing from &lt;a href="#24875a2c31fa7f94ce562adddedc0bf8"&gt;Willard, Brandon T. (2018)&lt;/a&gt;, we’ll attempt to improve upon &lt;code&gt;RandomFunction&lt;/code&gt; and make a case for a similar &lt;code&gt;Op&lt;/code&gt; in PyMC3.&lt;/p&gt;
&lt;/div&gt;
&lt;section id="introduction" class="level1"&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;We’ll call the new &lt;code&gt;Op&lt;/code&gt; developed here &lt;code&gt;RandomVariable&lt;/code&gt;, since random variables are the abstraction we’re primarily targeting. &lt;code&gt;RandomVariable&lt;/code&gt; will provide the functionality of &lt;code&gt;Distribution&lt;/code&gt;, &lt;code&gt;FreeRV&lt;/code&gt; and &lt;code&gt;ObservedRV&lt;/code&gt;, and, by working at the &lt;code&gt;Op&lt;/code&gt; level, it will be much more capable of leveraging existing Theano functionality.&lt;/p&gt;
&lt;p&gt;Specifically, by using the &lt;code&gt;Op&lt;/code&gt; interface, we’re able to do the following:&lt;/p&gt;
&lt;ol type="1"&gt;
&lt;li&gt;&lt;p&gt;Remove the need for an explicitly specified shape parameter.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;For example, definitions like&lt;/p&gt;
&lt;div class="sourceCode" id="org9f36fc6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org9f36fc6-1" data-line-number="1"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model():&lt;/a&gt;
&lt;a class="sourceLine" id="org9f36fc6-2" data-line-number="2"&gt;    X_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;X_rv&amp;#39;&lt;/span&gt;, mu_X, sd&lt;span class="op"&gt;=&lt;/span&gt;sd_X, shape&lt;span class="op"&gt;=&lt;/span&gt;(&lt;span class="dv"&gt;1&lt;/span&gt;,))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;reduce to&lt;/p&gt;
&lt;div class="sourceCode" id="orgf62e7a4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgf62e7a4-1" data-line-number="1"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model():&lt;/a&gt;
&lt;a class="sourceLine" id="orgf62e7a4-2" data-line-number="2"&gt;    X_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;X_rv&amp;#39;&lt;/span&gt;, mu_X, sd&lt;span class="op"&gt;=&lt;/span&gt;sd_X)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;Random variable nodes created by an &lt;code&gt;Op&lt;/code&gt; automatically implement &lt;code&gt;Distribution.default&lt;/code&gt;/&lt;code&gt;Distribution.get_test_val&lt;/code&gt; functionality and remove the reliance on initial values during random variable instantiation. &lt;code&gt;Op&lt;/code&gt; automatically uses &lt;code&gt;Op.perform&lt;/code&gt;, which will draw a sample as a test value &lt;strong&gt;and&lt;/strong&gt; propagate it throughout the graph to down-stream tensor variables.&lt;/li&gt;
&lt;li&gt;Log-densities can be generated as secondary outputs of &lt;code&gt;Op.make_node&lt;/code&gt;, which removes the need for &lt;code&gt;Distribution.logp*&lt;/code&gt; methods.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;pymc.distribution.draw_values&lt;/code&gt; and related methods are no longer necessary; their functionality is already covered within Theano’s existing graph machinery–in the same way as &lt;code&gt;pymc.distribution.Distribution.default/get_test_val&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The main points of entry in our &lt;code&gt;Op&lt;/code&gt;, are &lt;code&gt;Op.make_node&lt;/code&gt; and &lt;code&gt;Op.perform&lt;/code&gt;. &lt;code&gt;Op.make_node&lt;/code&gt; is used during symbolic graph creation and provides immediate access to the &lt;code&gt;Op&lt;/code&gt;’s symbolic inputs–serving a purpose similar to &lt;code&gt;Distribution.__init__&lt;/code&gt;. &lt;code&gt;Op.make_node&lt;/code&gt; is where shape inference tasks (e.g. &lt;a href="https://github.com/pymc-devs/pymc3/pull/1125"&gt;PyMC3 PR 1125&lt;/a&gt;) are more suitably addressed; however, &lt;code&gt;Op&lt;/code&gt; provides additional means of shape inference and management (e.g. &lt;code&gt;Op.infer_shape&lt;/code&gt;) occurring at different phases of graph compilation that aren’t readily accessible outside of the &lt;code&gt;Op&lt;/code&gt; framework.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="a-new-random-variable-op" class="level1"&gt;
&lt;h1&gt;A &lt;strong&gt;new&lt;/strong&gt; Random Variable &lt;code&gt;Op&lt;/code&gt;&lt;/h1&gt;
&lt;div class="sourceCode" id="org9c584cc"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org9c584cc-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; sys&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-2" data-line-number="2"&gt;&lt;span class="im"&gt;import&lt;/span&gt; os&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-4" data-line-number="4"&gt;&lt;span class="im"&gt;from&lt;/span&gt; pprint &lt;span class="im"&gt;import&lt;/span&gt; pprint&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-6" data-line-number="6"&gt;&lt;span class="im"&gt;import&lt;/span&gt; numpy &lt;span class="im"&gt;as&lt;/span&gt; np&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-8" data-line-number="8"&gt;os.environ[&lt;span class="st"&gt;&amp;#39;MKL_THREADING_LAYER&amp;#39;&lt;/span&gt;] &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;GNU&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-10" data-line-number="10"&gt;&lt;span class="im"&gt;import&lt;/span&gt; theano&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-11" data-line-number="11"&gt;&lt;span class="im"&gt;import&lt;/span&gt; theano.tensor &lt;span class="im"&gt;as&lt;/span&gt; tt&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-13" data-line-number="13"&gt;theano.config.mode &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;FAST_COMPILE&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-14" data-line-number="14"&gt;theano.config.exception_verbosity &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;high&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-15" data-line-number="15"&gt;&lt;span class="co"&gt;# &lt;/span&gt;&lt;span class="al"&gt;NOTE&lt;/span&gt;&lt;span class="co"&gt;: pymc3 requires test values&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-16" data-line-number="16"&gt;theano.config.compute_test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;warn&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-17" data-line-number="17"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c584cc-18" data-line-number="18"&gt;&lt;span class="im"&gt;import&lt;/span&gt; pymc3 &lt;span class="im"&gt;as&lt;/span&gt; pm&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Most of the work involved in generalizing &lt;code&gt;RandomFunction&lt;/code&gt; has to do with symbolic shape handling and inference. We need to bridge the gaps between symbolic array/tensor broadcasting parameters and the way Numpy random variable functions allow distribution parameters to be specified.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;Scalar normal random variates have a support and parameters with dimension zero. In Listing &lt;a href="#org352d751"&gt;4&lt;/a&gt; we create a scalar normal random variate in Numpy and inspect its shape. The length of the shape corresponds to the dimension of the distribution’s support (i.e. zero).&lt;/p&gt;
&lt;div class="sourceCode" id="org352d751"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org352d751-1" data-line-number="1"&gt;np.shape(np.random.normal(loc&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;0&lt;/span&gt;, scale&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org96612e2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org96612e2-1" data-line-number="1"&gt;()&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Numpy also allows one to specify &lt;strong&gt;independent&lt;/strong&gt; normal variates using one function call with each variate’s parameters spanning dimensions higher than the variate’s. In Listing &lt;a href="#orgbabaa48"&gt;6&lt;/a&gt; we specify three independent scalar normal variates, each with a different mean and scale parameter. This time, the result’s shape reflects &lt;strong&gt;the number of independent random variates&lt;/strong&gt;, and not the dimension of the underlying distribution’s support.&lt;/p&gt;
&lt;div class="sourceCode" id="orgbabaa48"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgbabaa48-1" data-line-number="1"&gt;np.shape(np.random.normal(loc&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;], scale&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;], size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgef69d1e"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgef69d1e-1" data-line-number="1"&gt;(&lt;span class="dv"&gt;3&lt;/span&gt;,)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Distribution parameters can also be broadcasted, as in &lt;a href="#org6643ee7"&gt;8&lt;/a&gt;. Now, each independent variate has the same scale value.&lt;/p&gt;
&lt;div class="sourceCode" id="org6643ee7"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org6643ee7-1" data-line-number="1"&gt;np.shape(np.random.normal(loc&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;], scale&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;size&lt;/code&gt; parameter effectively replicates variates, in-line with the–potentially broadcasted–distribution parameters.&lt;/p&gt;
&lt;p&gt;When bridging these Numpy functions and Theano, we have to adapt the underlying parameter/shape logic of functions like &lt;code&gt;np.random.normal&lt;/code&gt; to a scenario involving symbolic parameters and their symbolic shapes.&lt;/p&gt;
&lt;p&gt;For instance, in Theano a &lt;strong&gt;symbolic&lt;/strong&gt; scalar’s shape is represented in nearly the same way.&lt;/p&gt;
&lt;div class="sourceCode" id="orga6116d4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orga6116d4-1" data-line-number="1"&gt;test_scalar &lt;span class="op"&gt;=&lt;/span&gt; tt.scalar()&lt;/a&gt;
&lt;a class="sourceLine" id="orga6116d4-2" data-line-number="2"&gt;test_scalar.shape.&lt;span class="bu"&gt;eval&lt;/span&gt;({test_scalar: &lt;span class="dv"&gt;1&lt;/span&gt;})&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgb9018eb"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgb9018eb-1" data-line-number="1"&gt;[]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This means that our proposed Theano adaptation of &lt;code&gt;np.random.normal&lt;/code&gt;, let’s call it &lt;code&gt;tt_normal&lt;/code&gt;, should return the same result as Numpy in the case of scalars.&lt;/p&gt;
&lt;p&gt;What about &lt;code&gt;tt_normal(loc=tt.vector(), scale=tt.vector(), size=None)&lt;/code&gt;? Since the inputs are purely symbolic, the resulting symbolic object’s shape should be, too, but we should also know that the symbolic shape should have dimension equal to one. Just as in Listing &lt;a href="#orgbabaa48"&gt;6&lt;/a&gt;, each corresponding element in the vector arguments of &lt;code&gt;tt_normal&lt;/code&gt; is an independent variate; in the symbolic case, we might not know exactly how many of them there are, yet, but we know that there’s a vector’s worth of them.&lt;/p&gt;
&lt;p&gt;How exactly do we get that information from Theano, though? The type produced by &lt;code&gt;tt.vector&lt;/code&gt; has an &lt;code&gt;ndim&lt;/code&gt; parameter that provides this. Furthermore, there is some (intermittent) functionality that allows one to iterate over shapes. Listing &lt;a href="#org0d70518"&gt;11&lt;/a&gt; demonstrates this.&lt;/p&gt;
&lt;div class="sourceCode" id="org0d70518"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org0d70518-1" data-line-number="1"&gt;test_matrix &lt;span class="op"&gt;=&lt;/span&gt; tt.matrix()&lt;/a&gt;
&lt;a class="sourceLine" id="org0d70518-2" data-line-number="2"&gt;shape_parts &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(test_matrix.shape)&lt;/a&gt;
&lt;a class="sourceLine" id="org0d70518-3" data-line-number="3"&gt;shape_parts&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgd865db6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgd865db6-1" data-line-number="1"&gt;(Subtensor{int64}.&lt;span class="dv"&gt;0&lt;/span&gt;, Subtensor{int64}.&lt;span class="dv"&gt;0&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When the matrix in Listing &lt;a href="#org0d70518"&gt;11&lt;/a&gt; is “materialized” (i.e. given a value), its corresponding shape object–and its components–will take their respective values.&lt;/p&gt;
&lt;div class="sourceCode" id="org4d51e03"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org4d51e03-1" data-line-number="1"&gt;&lt;span class="bu"&gt;tuple&lt;/span&gt;(p.&lt;span class="bu"&gt;eval&lt;/span&gt;({test_matrix: np.diag([&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;])}) &lt;span class="cf"&gt;for&lt;/span&gt; p &lt;span class="kw"&gt;in&lt;/span&gt; shape_parts)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgc53dece"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgc53dece-1" data-line-number="1"&gt;(array(&lt;span class="dv"&gt;2&lt;/span&gt;), array(&lt;span class="dv"&gt;2&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If we knew that the support of this distribution was a scalar/vector/matrix, then these &lt;code&gt;ndim&lt;/code&gt;-related results–obtained from the symbolic parameters–would tell us that we have multiple, independent variates and we could reliably extract the symbolic variables corresponding to those actual dimension sizes.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;To determine the shape parts (i.e. support, number of independent and replicated variates) of the symbolic random variables, we mimic the corresponding Numpy logic and use the Theano &lt;code&gt;ndim&lt;/code&gt; shape information described above. The following function generalizes that work for many simple distributions.&lt;/p&gt;
&lt;div class="sourceCode" id="org03297c0"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org03297c0-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; collections.abc &lt;span class="im"&gt;import&lt;/span&gt; Iterable, ByteString&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; warnings &lt;span class="im"&gt;import&lt;/span&gt; warn&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-3" data-line-number="3"&gt;&lt;span class="im"&gt;from&lt;/span&gt; copy &lt;span class="im"&gt;import&lt;/span&gt; copy&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-5" data-line-number="5"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano.tensor.raw_random &lt;span class="im"&gt;import&lt;/span&gt; (RandomFunction, RandomStateType,&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-6" data-line-number="6"&gt;                                      _infer_ndim_bcast)&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-9" data-line-number="9"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; param_supp_shape_fn(ndim_supp, ndims_params, dist_params,&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-10" data-line-number="10"&gt;                        rep_param_idx&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;0&lt;/span&gt;, param_shapes&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-11" data-line-number="11"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;A function for deriving a random variable&amp;#39;s support shape/dimensions&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-12" data-line-number="12"&gt;&lt;span class="co"&gt;    from one of its parameters.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-14" data-line-number="14"&gt;&lt;span class="co"&gt;    XXX: It&amp;#39;s not always possible to determine a random variable&amp;#39;s support&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-15" data-line-number="15"&gt;&lt;span class="co"&gt;    shape from its parameters, so this function has fundamentally limited&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-16" data-line-number="16"&gt;&lt;span class="co"&gt;    applicability.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-17" data-line-number="17"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-18" data-line-number="18"&gt;&lt;span class="co"&gt;    XXX: This function is not expected to handle `ndim_supp = 0` (i.e.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-19" data-line-number="19"&gt;&lt;span class="co"&gt;    scalars), since that is already definitively handled in the `Op` that&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-20" data-line-number="20"&gt;&lt;span class="co"&gt;    calls this.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-22" data-line-number="22"&gt;&lt;span class="co"&gt;    &lt;/span&gt;&lt;span class="al"&gt;TODO&lt;/span&gt;&lt;span class="co"&gt;: Consider using `theano.compile.ops.shape_i` alongside `ShapeFeature`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-23" data-line-number="23"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-24" data-line-number="24"&gt;&lt;span class="co"&gt;    Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-25" data-line-number="25"&gt;&lt;span class="co"&gt;    ==========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-26" data-line-number="26"&gt;&lt;span class="co"&gt;    ndim_supp: int&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-27" data-line-number="27"&gt;&lt;span class="co"&gt;        Total number of dimensions in the support (assumedly &amp;gt; 0).&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-28" data-line-number="28"&gt;&lt;span class="co"&gt;    ndims_params: list of int&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-29" data-line-number="29"&gt;&lt;span class="co"&gt;        Number of dimensions for each distribution parameter.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-30" data-line-number="30"&gt;&lt;span class="co"&gt;    dist_params: list of `theano.gof.graph.Variable`&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-31" data-line-number="31"&gt;&lt;span class="co"&gt;        The distribution parameters.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-32" data-line-number="32"&gt;&lt;span class="co"&gt;    param_shapes: list of `theano.compile.ops.Shape` (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-33" data-line-number="33"&gt;&lt;span class="co"&gt;        Symbolic shapes for each distribution parameter.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-34" data-line-number="34"&gt;&lt;span class="co"&gt;        Providing this value prevents us from reproducing the requisite&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-35" data-line-number="35"&gt;&lt;span class="co"&gt;        `theano.compile.ops.Shape` object (e.g. when it&amp;#39;s already available to&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-36" data-line-number="36"&gt;&lt;span class="co"&gt;        the caller).&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-37" data-line-number="37"&gt;&lt;span class="co"&gt;    rep_param_idx: int (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-38" data-line-number="38"&gt;&lt;span class="co"&gt;        The index of the distribution parameter to use as a reference&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-39" data-line-number="39"&gt;&lt;span class="co"&gt;        In other words, a parameter in `dist_param` with a shape corresponding&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-40" data-line-number="40"&gt;&lt;span class="co"&gt;        to the support&amp;#39;s shape.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-41" data-line-number="41"&gt;&lt;span class="co"&gt;        The default is the first parameter (i.e. the value 0).&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-42" data-line-number="42"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-43" data-line-number="43"&gt;&lt;span class="co"&gt;    Results&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-44" data-line-number="44"&gt;&lt;span class="co"&gt;    =======&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-45" data-line-number="45"&gt;&lt;span class="co"&gt;    out: a tuple representing the support shape for a distribution with the&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-46" data-line-number="46"&gt;&lt;span class="co"&gt;    given `dist_params`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-47" data-line-number="47"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-48" data-line-number="48"&gt;    &lt;span class="co"&gt;# XXX: Gotta be careful slicing Theano variables, the `Subtensor` Op isn&amp;#39;t&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-49" data-line-number="49"&gt;    &lt;span class="co"&gt;# handled by `tensor.get_scalar_constant_value`!&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-50" data-line-number="50"&gt;    &lt;span class="co"&gt;# E.g.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-51" data-line-number="51"&gt;    &lt;span class="co"&gt;#     test_val = tt.as_tensor_variable([[1], [4]])&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-52" data-line-number="52"&gt;    &lt;span class="co"&gt;#     tt.get_scalar_constant_value(test_val.shape[-1]) # works&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-53" data-line-number="53"&gt;    &lt;span class="co"&gt;#     tt.get_scalar_constant_value(test_val.shape[0]) # doesn&amp;#39;t&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-54" data-line-number="54"&gt;    &lt;span class="co"&gt;#     tt.get_scalar_constant_value(test_val.shape[:-1]) # doesn&amp;#39;t&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-55" data-line-number="55"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; param_shapes &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-56" data-line-number="56"&gt;        &lt;span class="co"&gt;# return param_shapes[0][-self.ndim_supp:]&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-57" data-line-number="57"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; (param_shapes[rep_param_idx][&lt;span class="op"&gt;-&lt;/span&gt;ndim_supp],)&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-58" data-line-number="58"&gt;    &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-59" data-line-number="59"&gt;        &lt;span class="co"&gt;# return dist_params[rep_param_idx].shape[-ndim_supp]&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-60" data-line-number="60"&gt;        ref_shape &lt;span class="op"&gt;=&lt;/span&gt; tt.shape(dist_params[rep_param_idx])&lt;/a&gt;
&lt;a class="sourceLine" id="org03297c0-61" data-line-number="61"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; (ref_shape[&lt;span class="op"&gt;-&lt;/span&gt;ndim_supp],)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, we put everything together in a new random variable &lt;code&gt;Op&lt;/code&gt; called &lt;code&gt;RandomVariable&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="orgb7517e4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgb7517e4-1" data-line-number="1"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; RandomVariable(tt.gof.Op):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-2" data-line-number="2"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;This is essentially `RandomFunction`, except that it removes the `outtype`&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-3" data-line-number="3"&gt;&lt;span class="co"&gt;    dependency and handles shape dimension information more directly.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-4" data-line-number="4"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-5" data-line-number="5"&gt;    __props__ &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="st"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;dtype&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;ndim_supp&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;inplace&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;ndims_params&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-7" data-line-number="7"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;, name, dtype, ndim_supp, ndims_params, rng_fn,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-8" data-line-number="8"&gt;                 &lt;span class="op"&gt;*&lt;/span&gt;args,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-9" data-line-number="9"&gt;                 supp_shape_fn&lt;span class="op"&gt;=&lt;/span&gt;param_supp_shape_fn,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-10" data-line-number="10"&gt;                 inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-11" data-line-number="11"&gt;                 &lt;span class="op"&gt;**&lt;/span&gt;kwargs):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-12" data-line-number="12"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Create a random variable `Op`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-14" data-line-number="14"&gt;&lt;span class="co"&gt;        Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-15" data-line-number="15"&gt;&lt;span class="co"&gt;        ==========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-16" data-line-number="16"&gt;&lt;span class="co"&gt;        name: str&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-17" data-line-number="17"&gt;&lt;span class="co"&gt;            The `Op`&amp;#39;s display name.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-18" data-line-number="18"&gt;&lt;span class="co"&gt;        dtype: Theano dtype&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-19" data-line-number="19"&gt;&lt;span class="co"&gt;            The underlying dtype.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-20" data-line-number="20"&gt;&lt;span class="co"&gt;        ndim_supp: int&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-21" data-line-number="21"&gt;&lt;span class="co"&gt;            Dimension of the support.  This value is used to infer the exact&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-22" data-line-number="22"&gt;&lt;span class="co"&gt;            shape of the support and independent terms from ``dist_params``.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-23" data-line-number="23"&gt;&lt;span class="co"&gt;        ndims_params: tuple (int)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-24" data-line-number="24"&gt;&lt;span class="co"&gt;            Number of dimensions of each parameter in ``dist_params``.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-25" data-line-number="25"&gt;&lt;span class="co"&gt;        rng_fn: function or str&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-26" data-line-number="26"&gt;&lt;span class="co"&gt;            The non-symbolic random variate sampling function.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-27" data-line-number="27"&gt;&lt;span class="co"&gt;            Can be the string name of a method provided by&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-28" data-line-number="28"&gt;&lt;span class="co"&gt;            `numpy.random.RandomState`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-29" data-line-number="29"&gt;&lt;span class="co"&gt;        supp_shape_fn: callable (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-30" data-line-number="30"&gt;&lt;span class="co"&gt;            Function used to determine the exact shape of the distribution&amp;#39;s&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-31" data-line-number="31"&gt;&lt;span class="co"&gt;            support.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-32" data-line-number="32"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-33" data-line-number="33"&gt;&lt;span class="co"&gt;            It must take arguments ndim_supp, ndims_params, dist_params&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-34" data-line-number="34"&gt;&lt;span class="co"&gt;            (i.e. an collection of the distribution parameters) and an&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-35" data-line-number="35"&gt;&lt;span class="co"&gt;            optional param_shapes (i.e. tuples containing the size of each&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-36" data-line-number="36"&gt;&lt;span class="co"&gt;            dimension for each distribution parameter).&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-37" data-line-number="37"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-38" data-line-number="38"&gt;&lt;span class="co"&gt;            Defaults to `param_supp_shape_fn`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-39" data-line-number="39"&gt;&lt;span class="co"&gt;        inplace: boolean&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-40" data-line-number="40"&gt;&lt;span class="co"&gt;            Determine whether or not the underlying rng state is updated in-place or&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-41" data-line-number="41"&gt;&lt;span class="co"&gt;            not (i.e. copied).&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-42" data-line-number="42"&gt;&lt;span class="co"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-43" data-line-number="43"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="op"&gt;*&lt;/span&gt;args, &lt;span class="op"&gt;**&lt;/span&gt;kwargs)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-44" data-line-number="44"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-45" data-line-number="45"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.name &lt;span class="op"&gt;=&lt;/span&gt; name&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-46" data-line-number="46"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.ndim_supp &lt;span class="op"&gt;=&lt;/span&gt; ndim_supp&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-47" data-line-number="47"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.dtype &lt;span class="op"&gt;=&lt;/span&gt; dtype&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-48" data-line-number="48"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.supp_shape_fn &lt;span class="op"&gt;=&lt;/span&gt; supp_shape_fn&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-49" data-line-number="49"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.inplace &lt;span class="op"&gt;=&lt;/span&gt; inplace&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-50" data-line-number="50"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-51" data-line-number="51"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(ndims_params, Iterable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-52" data-line-number="52"&gt;            &lt;span class="cf"&gt;raise&lt;/span&gt; &lt;span class="pp"&gt;ValueError&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;Parameter ndims_params must be iterable.&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-53" data-line-number="53"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-54" data-line-number="54"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.ndims_params &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(ndims_params)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-55" data-line-number="55"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-56" data-line-number="56"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.default_output &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-57" data-line-number="57"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-58" data-line-number="58"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(rng_fn, (&lt;span class="bu"&gt;str&lt;/span&gt;, ByteString)):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-59" data-line-number="59"&gt;            &lt;span class="va"&gt;self&lt;/span&gt;.rng_fn &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(np.random.RandomState, rng_fn)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-60" data-line-number="60"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-61" data-line-number="61"&gt;            &lt;span class="va"&gt;self&lt;/span&gt;.rng_fn &lt;span class="op"&gt;=&lt;/span&gt; rng_fn&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-62" data-line-number="62"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-63" data-line-number="63"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__str__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-64" data-line-number="64"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;_rv&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;.name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-65" data-line-number="65"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-66" data-line-number="66"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; _infer_shape(&lt;span class="va"&gt;self&lt;/span&gt;, size, dist_params, param_shapes&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-67" data-line-number="67"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Compute shapes and broadcasts properties.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-68" data-line-number="68"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-69" data-line-number="69"&gt;&lt;span class="co"&gt;        Inspired by `tt.add.get_output_info`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-70" data-line-number="70"&gt;&lt;span class="co"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-71" data-line-number="71"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-72" data-line-number="72"&gt;        size_len &lt;span class="op"&gt;=&lt;/span&gt; tt.get_vector_length(size)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-73" data-line-number="73"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-74" data-line-number="74"&gt;        dummy_params &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(p &lt;span class="cf"&gt;if&lt;/span&gt; n &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="cf"&gt;else&lt;/span&gt; tt.ones(&lt;span class="bu"&gt;tuple&lt;/span&gt;(p.shape)[:&lt;span class="op"&gt;-&lt;/span&gt;n])&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-75" data-line-number="75"&gt;                             &lt;span class="cf"&gt;for&lt;/span&gt; p, n &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;zip&lt;/span&gt;(dist_params, &lt;span class="va"&gt;self&lt;/span&gt;.ndims_params))&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-76" data-line-number="76"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-77" data-line-number="77"&gt;        _, out_bcasts, bcastd_inputs &lt;span class="op"&gt;=&lt;/span&gt; tt.add.get_output_info(&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-78" data-line-number="78"&gt;            tt.DimShuffle, &lt;span class="op"&gt;*&lt;/span&gt;dummy_params)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-79" data-line-number="79"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-80" data-line-number="80"&gt;        &lt;span class="co"&gt;# _, out_bcasts, bcastd_inputs = tt.add.get_output_info(tt.DimShuffle, *dist_params)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-81" data-line-number="81"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-82" data-line-number="82"&gt;        bcast_ind, &lt;span class="op"&gt;=&lt;/span&gt; out_bcasts&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-83" data-line-number="83"&gt;        ndim_ind &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;len&lt;/span&gt;(bcast_ind)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-84" data-line-number="84"&gt;        shape_ind &lt;span class="op"&gt;=&lt;/span&gt; bcastd_inputs[&lt;span class="dv"&gt;0&lt;/span&gt;].shape&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-85" data-line-number="85"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-86" data-line-number="86"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.ndim_supp &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-87" data-line-number="87"&gt;            shape_supp &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;()&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-88" data-line-number="88"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-89" data-line-number="89"&gt;            &lt;span class="co"&gt;# In the scalar case, `size` corresponds to the entire result&amp;#39;s&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-90" data-line-number="90"&gt;            &lt;span class="co"&gt;# shape. This implies the following:&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-91" data-line-number="91"&gt;            &lt;span class="co"&gt;#     shape_ind[-ndim_ind] == size[:ndim_ind]&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-92" data-line-number="92"&gt;            &lt;span class="co"&gt;# &lt;/span&gt;&lt;span class="al"&gt;TODO&lt;/span&gt;&lt;span class="co"&gt;: How do we add this constraint/check symbolically?&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-93" data-line-number="93"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-94" data-line-number="94"&gt;            ndim_reps &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;max&lt;/span&gt;(size_len &lt;span class="op"&gt;-&lt;/span&gt; ndim_ind, &lt;span class="dv"&gt;0&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-95" data-line-number="95"&gt;            shape_reps &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(size)[ndim_ind:]&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-96" data-line-number="96"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-97" data-line-number="97"&gt;            shape_supp &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.supp_shape_fn(&lt;span class="va"&gt;self&lt;/span&gt;.ndim_supp,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-98" data-line-number="98"&gt;                                            &lt;span class="va"&gt;self&lt;/span&gt;.ndims_params,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-99" data-line-number="99"&gt;                                            dist_params,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-100" data-line-number="100"&gt;                                            param_shapes&lt;span class="op"&gt;=&lt;/span&gt;param_shapes)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-101" data-line-number="101"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-102" data-line-number="102"&gt;            ndim_reps &lt;span class="op"&gt;=&lt;/span&gt; size_len&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-103" data-line-number="103"&gt;            shape_reps &lt;span class="op"&gt;=&lt;/span&gt; size&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-104" data-line-number="104"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-105" data-line-number="105"&gt;        ndim_shape &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.ndim_supp &lt;span class="op"&gt;+&lt;/span&gt; ndim_ind &lt;span class="op"&gt;+&lt;/span&gt; ndim_reps&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-106" data-line-number="106"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-107" data-line-number="107"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; ndim_shape &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-108" data-line-number="108"&gt;            shape &lt;span class="op"&gt;=&lt;/span&gt; tt.constant([], dtype&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;int64&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-109" data-line-number="109"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-110" data-line-number="110"&gt;            shape &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(shape_reps) &lt;span class="op"&gt;+&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(shape_ind) &lt;span class="op"&gt;+&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(shape_supp)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-111" data-line-number="111"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-112" data-line-number="112"&gt;        &lt;span class="co"&gt;# if shape is None:&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-113" data-line-number="113"&gt;        &lt;span class="co"&gt;#     raise tt.ShapeError()&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-114" data-line-number="114"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-115" data-line-number="115"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; shape&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-116" data-line-number="116"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-117" data-line-number="117"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; compute_bcast(&lt;span class="va"&gt;self&lt;/span&gt;, dist_params, size):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-118" data-line-number="118"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Compute the broadcast array for this distribution&amp;#39;s `TensorType`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-119" data-line-number="119"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-120" data-line-number="120"&gt;&lt;span class="co"&gt;        Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-121" data-line-number="121"&gt;&lt;span class="co"&gt;        ==========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-122" data-line-number="122"&gt;&lt;span class="co"&gt;        dist_params: list&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-123" data-line-number="123"&gt;&lt;span class="co"&gt;            Distribution parameters.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-124" data-line-number="124"&gt;&lt;span class="co"&gt;        size: int or Iterable (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-125" data-line-number="125"&gt;&lt;span class="co"&gt;            Numpy-like size of the output (i.e. replications).&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-126" data-line-number="126"&gt;&lt;span class="co"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-127" data-line-number="127"&gt;        shape &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;._infer_shape(size, dist_params)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-128" data-line-number="128"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-129" data-line-number="129"&gt;        &lt;span class="co"&gt;# Let&amp;#39;s try to do a better job than `_infer_ndim_bcast` when&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-130" data-line-number="130"&gt;        &lt;span class="co"&gt;# dimension sizes are symbolic.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-131" data-line-number="131"&gt;        bcast &lt;span class="op"&gt;=&lt;/span&gt; []&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-132" data-line-number="132"&gt;        &lt;span class="cf"&gt;for&lt;/span&gt; s &lt;span class="kw"&gt;in&lt;/span&gt; shape:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-133" data-line-number="133"&gt;            &lt;span class="cf"&gt;try&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-134" data-line-number="134"&gt;                &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(s.owner.op, tt.Subtensor) &lt;span class="kw"&gt;and&lt;/span&gt; &lt;span class="op"&gt;\&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-135" data-line-number="135"&gt;                   s.owner.inputs[&lt;span class="dv"&gt;0&lt;/span&gt;].owner &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-136" data-line-number="136"&gt;                    &lt;span class="co"&gt;# Handle a special case in which&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-137" data-line-number="137"&gt;                    &lt;span class="co"&gt;# `tensor.get_scalar_constant_value` doesn&amp;#39;t really work.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-138" data-line-number="138"&gt;                    s_x, s_idx &lt;span class="op"&gt;=&lt;/span&gt; s.owner.inputs&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-139" data-line-number="139"&gt;                    s_idx &lt;span class="op"&gt;=&lt;/span&gt; tt.get_scalar_constant_value(s_idx)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-140" data-line-number="140"&gt;                    &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(s_x.owner.op, tt.Shape):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-141" data-line-number="141"&gt;                        x_obj, &lt;span class="op"&gt;=&lt;/span&gt; s_x.owner.inputs&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-142" data-line-number="142"&gt;                        s_val &lt;span class="op"&gt;=&lt;/span&gt; x_obj.&lt;span class="bu"&gt;type&lt;/span&gt;.broadcastable[s_idx]&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-143" data-line-number="143"&gt;                    &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-144" data-line-number="144"&gt;                        &lt;span class="co"&gt;# &lt;/span&gt;&lt;span class="al"&gt;TODO&lt;/span&gt;&lt;span class="co"&gt;: Could go for an existing broadcastable here, too, no?&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-145" data-line-number="145"&gt;                        s_val &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;False&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-146" data-line-number="146"&gt;                &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-147" data-line-number="147"&gt;                    s_val &lt;span class="op"&gt;=&lt;/span&gt; tt.get_scalar_constant_value(s)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-148" data-line-number="148"&gt;            &lt;span class="cf"&gt;except&lt;/span&gt; tt.NotScalarConstantError:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-149" data-line-number="149"&gt;                s_val &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;False&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-150" data-line-number="150"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-151" data-line-number="151"&gt;            bcast &lt;span class="op"&gt;+=&lt;/span&gt; [s_val &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-152" data-line-number="152"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; bcast&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-153" data-line-number="153"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-154" data-line-number="154"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; infer_shape(&lt;span class="va"&gt;self&lt;/span&gt;, node, input_shapes):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-155" data-line-number="155"&gt;        size &lt;span class="op"&gt;=&lt;/span&gt; node.inputs[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-156" data-line-number="156"&gt;        dist_params &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(node.inputs[:&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-157" data-line-number="157"&gt;        shape &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;._infer_shape(size, dist_params,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-158" data-line-number="158"&gt;                                  param_shapes&lt;span class="op"&gt;=&lt;/span&gt;input_shapes[:&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-159" data-line-number="159"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-160" data-line-number="160"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; [&lt;span class="va"&gt;None&lt;/span&gt;, [s &lt;span class="cf"&gt;for&lt;/span&gt; s &lt;span class="kw"&gt;in&lt;/span&gt; shape]]&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-161" data-line-number="161"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-162" data-line-number="162"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, &lt;span class="op"&gt;*&lt;/span&gt;dist_params, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-163" data-line-number="163"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Create a random variable node.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-164" data-line-number="164"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-165" data-line-number="165"&gt;&lt;span class="co"&gt;        XXX: Unnamed/non-keyword arguments are considered distribution&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-166" data-line-number="166"&gt;&lt;span class="co"&gt;        parameters!  If you want to set `size`, `rng`, and/or `name`, use their&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-167" data-line-number="167"&gt;&lt;span class="co"&gt;        keywords.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-168" data-line-number="168"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-169" data-line-number="169"&gt;&lt;span class="co"&gt;        Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-170" data-line-number="170"&gt;&lt;span class="co"&gt;        ==========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-171" data-line-number="171"&gt;&lt;span class="co"&gt;        dist_params: list&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-172" data-line-number="172"&gt;&lt;span class="co"&gt;            Distribution parameters.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-173" data-line-number="173"&gt;&lt;span class="co"&gt;        size: int or Iterable (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-174" data-line-number="174"&gt;&lt;span class="co"&gt;            Numpy-like size of the output (i.e. replications).&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-175" data-line-number="175"&gt;&lt;span class="co"&gt;        rng: RandomState (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-176" data-line-number="176"&gt;&lt;span class="co"&gt;            Existing Theano `RandomState` object to be used.  Creates a&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-177" data-line-number="177"&gt;&lt;span class="co"&gt;            new one, if `None`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-178" data-line-number="178"&gt;&lt;span class="co"&gt;        name: str (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-179" data-line-number="179"&gt;&lt;span class="co"&gt;            Label for the resulting node.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-180" data-line-number="180"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-181" data-line-number="181"&gt;&lt;span class="co"&gt;        Results&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-182" data-line-number="182"&gt;&lt;span class="co"&gt;        =======&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-183" data-line-number="183"&gt;&lt;span class="co"&gt;        out: `Apply`&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-184" data-line-number="184"&gt;&lt;span class="co"&gt;            A node with inputs `dist_args + (size, in_rng, name)` and outputs&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-185" data-line-number="185"&gt;&lt;span class="co"&gt;            `(out_rng, sample_tensorvar)`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-186" data-line-number="186"&gt;&lt;span class="co"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-187" data-line-number="187"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; size &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-188" data-line-number="188"&gt;            size &lt;span class="op"&gt;=&lt;/span&gt; tt.constant([], dtype&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;int64&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-189" data-line-number="189"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(size, &lt;span class="bu"&gt;int&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-190" data-line-number="190"&gt;            size &lt;span class="op"&gt;=&lt;/span&gt; tt.as_tensor_variable([size], ndim&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-191" data-line-number="191"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(size, Iterable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-192" data-line-number="192"&gt;            &lt;span class="cf"&gt;raise&lt;/span&gt; &lt;span class="pp"&gt;ValueError&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;Parameter size must be None, int, or an iterable with ints.&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-193" data-line-number="193"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-194" data-line-number="194"&gt;            size &lt;span class="op"&gt;=&lt;/span&gt; tt.as_tensor_variable(size, ndim&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-195" data-line-number="195"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-196" data-line-number="196"&gt;        &lt;span class="cf"&gt;assert&lt;/span&gt; size.dtype &lt;span class="kw"&gt;in&lt;/span&gt; tt.int_dtypes&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-197" data-line-number="197"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-198" data-line-number="198"&gt;        dist_params &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(tt.as_tensor_variable(p)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-199" data-line-number="199"&gt;                            &lt;span class="cf"&gt;for&lt;/span&gt; p &lt;span class="kw"&gt;in&lt;/span&gt; dist_params)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-200" data-line-number="200"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-201" data-line-number="201"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; rng &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-202" data-line-number="202"&gt;            rng &lt;span class="op"&gt;=&lt;/span&gt; theano.shared(np.random.RandomState())&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-203" data-line-number="203"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(rng.&lt;span class="bu"&gt;type&lt;/span&gt;, RandomStateType):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-204" data-line-number="204"&gt;            warn(&lt;span class="st"&gt;&amp;#39;The type of rng should be an instance of RandomStateType&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-205" data-line-number="205"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-206" data-line-number="206"&gt;        bcast &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.compute_bcast(dist_params, size)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-207" data-line-number="207"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-208" data-line-number="208"&gt;        &lt;span class="co"&gt;# dtype = tt.scal.upcast(self.dtype, *[p.dtype for p in dist_params])&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-209" data-line-number="209"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-210" data-line-number="210"&gt;        outtype &lt;span class="op"&gt;=&lt;/span&gt; tt.TensorType(dtype&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;self&lt;/span&gt;.dtype, broadcastable&lt;span class="op"&gt;=&lt;/span&gt;bcast)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-211" data-line-number="211"&gt;        out_var &lt;span class="op"&gt;=&lt;/span&gt; outtype(name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-212" data-line-number="212"&gt;        inputs &lt;span class="op"&gt;=&lt;/span&gt; dist_params &lt;span class="op"&gt;+&lt;/span&gt; (size, rng)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-213" data-line-number="213"&gt;        outputs &lt;span class="op"&gt;=&lt;/span&gt; (rng.&lt;span class="bu"&gt;type&lt;/span&gt;(), out_var)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-214" data-line-number="214"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-215" data-line-number="215"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; theano.gof.Apply(&lt;span class="va"&gt;self&lt;/span&gt;, inputs, outputs)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-216" data-line-number="216"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-217" data-line-number="217"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; perform(&lt;span class="va"&gt;self&lt;/span&gt;, node, inputs, outputs):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-218" data-line-number="218"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Draw samples using Numpy/SciPy.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-219" data-line-number="219"&gt;        rng_out, smpl_out &lt;span class="op"&gt;=&lt;/span&gt; outputs&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-220" data-line-number="220"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-221" data-line-number="221"&gt;        &lt;span class="co"&gt;# Draw from `rng` if `self.inplace` is `True`, and from a copy of `rng`&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-222" data-line-number="222"&gt;        &lt;span class="co"&gt;# otherwise.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-223" data-line-number="223"&gt;        args &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;list&lt;/span&gt;(inputs)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-224" data-line-number="224"&gt;        rng &lt;span class="op"&gt;=&lt;/span&gt; args.pop()&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-225" data-line-number="225"&gt;        size &lt;span class="op"&gt;=&lt;/span&gt; args.pop()&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-226" data-line-number="226"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-227" data-line-number="227"&gt;        &lt;span class="cf"&gt;assert&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(rng, np.random.RandomState), (&lt;span class="bu"&gt;type&lt;/span&gt;(rng), rng)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-228" data-line-number="228"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-229" data-line-number="229"&gt;        rng_out[&lt;span class="dv"&gt;0&lt;/span&gt;] &lt;span class="op"&gt;=&lt;/span&gt; rng&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-230" data-line-number="230"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-231" data-line-number="231"&gt;        &lt;span class="co"&gt;# The symbolic output variable corresponding to value produced here.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-232" data-line-number="232"&gt;        out_var &lt;span class="op"&gt;=&lt;/span&gt; node.outputs[&lt;span class="dv"&gt;1&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-233" data-line-number="233"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-234" data-line-number="234"&gt;        &lt;span class="co"&gt;# If `size == []`, that means no size is enforced, and NumPy is&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-235" data-line-number="235"&gt;        &lt;span class="co"&gt;# trusted to draw the appropriate number of samples, NumPy uses&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-236" data-line-number="236"&gt;        &lt;span class="co"&gt;# `size=None` to represent that.  Otherwise, NumPy expects a tuple.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-237" data-line-number="237"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; np.size(size) &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-238" data-line-number="238"&gt;            size &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-239" data-line-number="239"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-240" data-line-number="240"&gt;            size &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(size)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-241" data-line-number="241"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-242" data-line-number="242"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.inplace:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-243" data-line-number="243"&gt;            rng &lt;span class="op"&gt;=&lt;/span&gt; copy(rng)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-244" data-line-number="244"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-245" data-line-number="245"&gt;        smpl_val &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.rng_fn(rng, &lt;span class="op"&gt;*&lt;/span&gt;(args &lt;span class="op"&gt;+&lt;/span&gt; [size]))&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-246" data-line-number="246"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-247" data-line-number="247"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; (&lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(smpl_val, np.ndarray) &lt;span class="kw"&gt;or&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-248" data-line-number="248"&gt;            &lt;span class="bu"&gt;str&lt;/span&gt;(smpl_val.dtype) &lt;span class="op"&gt;!=&lt;/span&gt; out_var.&lt;span class="bu"&gt;type&lt;/span&gt;.dtype):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-249" data-line-number="249"&gt;            smpl_val &lt;span class="op"&gt;=&lt;/span&gt; theano._asarray(smpl_val, dtype&lt;span class="op"&gt;=&lt;/span&gt;out_var.&lt;span class="bu"&gt;type&lt;/span&gt;.dtype)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-250" data-line-number="250"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-251" data-line-number="251"&gt;        &lt;span class="co"&gt;# When `size` is `None`, NumPy has a tendency to unexpectedly&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-252" data-line-number="252"&gt;        &lt;span class="co"&gt;# return a scalar instead of a higher-dimension array containing&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-253" data-line-number="253"&gt;        &lt;span class="co"&gt;# only one element. This value should be reshaped&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-254" data-line-number="254"&gt;        &lt;span class="co"&gt;# &lt;/span&gt;&lt;span class="al"&gt;TODO&lt;/span&gt;&lt;span class="co"&gt;: Really?  Why shouldn&amp;#39;t the output correctly correspond to&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-255" data-line-number="255"&gt;        &lt;span class="co"&gt;# the returned NumPy value?  Sounds more like a mis-specification of&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-256" data-line-number="256"&gt;        &lt;span class="co"&gt;# the symbolic output variable.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-257" data-line-number="257"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; size &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt; &lt;span class="kw"&gt;and&lt;/span&gt; smpl_val.ndim &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="kw"&gt;and&lt;/span&gt; out_var.ndim &lt;span class="op"&gt;&amp;gt;&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-258" data-line-number="258"&gt;            smpl_val &lt;span class="op"&gt;=&lt;/span&gt; smpl_val.reshape([&lt;span class="dv"&gt;1&lt;/span&gt;] &lt;span class="op"&gt;*&lt;/span&gt; out_var.ndim)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-259" data-line-number="259"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-260" data-line-number="260"&gt;        smpl_out[&lt;span class="dv"&gt;0&lt;/span&gt;] &lt;span class="op"&gt;=&lt;/span&gt; smpl_val&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-261" data-line-number="261"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-262" data-line-number="262"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; grad(&lt;span class="va"&gt;self&lt;/span&gt;, inputs, outputs):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-263" data-line-number="263"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; [theano.gradient.grad_undefined(&lt;span class="va"&gt;self&lt;/span&gt;, k, inp,&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-264" data-line-number="264"&gt;                                               &lt;span class="st"&gt;&amp;#39;No gradient defined through raw random numbers op&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-265" data-line-number="265"&gt;                &lt;span class="cf"&gt;for&lt;/span&gt; k, inp &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;enumerate&lt;/span&gt;(inputs)]&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-266" data-line-number="266"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-267" data-line-number="267"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; R_op(&lt;span class="va"&gt;self&lt;/span&gt;, inputs, eval_points):&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7517e4-268" data-line-number="268"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; [&lt;span class="va"&gt;None&lt;/span&gt; &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; eval_points]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section id="using-randomvariable" class="level1"&gt;
&lt;h1&gt;Using &lt;code&gt;RandomVariable&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;In Listing &lt;a href="#orgf494cec"&gt;17&lt;/a&gt; we create some &lt;code&gt;RandomVariable&lt;/code&gt; &lt;code&gt;Op&lt;/code&gt;s.&lt;/p&gt;
&lt;div class="sourceCode" id="orgf494cec"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgf494cec-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; scipy&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; functools &lt;span class="im"&gt;import&lt;/span&gt; partial&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-5" data-line-number="5"&gt;&lt;span class="co"&gt;# Continuous Numpy-generated variates&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-6" data-line-number="6"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; UniformRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-7" data-line-number="7"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-8" data-line-number="8"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;uniform&amp;#39;&lt;/span&gt;, theano.config.floatX, &lt;span class="dv"&gt;0&lt;/span&gt;, [&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;uniform&amp;#39;&lt;/span&gt;, inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-10" data-line-number="10"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, lower, upper, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-11" data-line-number="11"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(lower, upper, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-13" data-line-number="13"&gt;UniformRV &lt;span class="op"&gt;=&lt;/span&gt; UniformRVType()&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-14" data-line-number="14"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-16" data-line-number="16"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; NormalRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-17" data-line-number="17"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-18" data-line-number="18"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;normal&amp;#39;&lt;/span&gt;, theano.config.floatX, &lt;span class="dv"&gt;0&lt;/span&gt;, [&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;normal&amp;#39;&lt;/span&gt;, inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-19" data-line-number="19"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-20" data-line-number="20"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, mu, sigma, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-21" data-line-number="21"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(mu, sigma, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-22" data-line-number="22"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-23" data-line-number="23"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-24" data-line-number="24"&gt;NormalRV &lt;span class="op"&gt;=&lt;/span&gt; NormalRVType()&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-25" data-line-number="25"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-26" data-line-number="26"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-27" data-line-number="27"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; GammaRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-28" data-line-number="28"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-29" data-line-number="29"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;gamma&amp;#39;&lt;/span&gt;, theano.config.floatX, &lt;span class="dv"&gt;0&lt;/span&gt;, [&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;gamma&amp;#39;&lt;/span&gt;, inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-30" data-line-number="30"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-31" data-line-number="31"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, shape, scale, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-32" data-line-number="32"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(shape, scale, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-33" data-line-number="33"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-34" data-line-number="34"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-35" data-line-number="35"&gt;GammaRV &lt;span class="op"&gt;=&lt;/span&gt; GammaRVType()&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-36" data-line-number="36"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-37" data-line-number="37"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-38" data-line-number="38"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; ExponentialRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-39" data-line-number="39"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-40" data-line-number="40"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;exponential&amp;#39;&lt;/span&gt;, theano.config.floatX, &lt;span class="dv"&gt;0&lt;/span&gt;, [&lt;span class="dv"&gt;0&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;exponential&amp;#39;&lt;/span&gt;, inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-41" data-line-number="41"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-42" data-line-number="42"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, scale, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-43" data-line-number="43"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(scale, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-44" data-line-number="44"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-45" data-line-number="45"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-46" data-line-number="46"&gt;ExponentialRV &lt;span class="op"&gt;=&lt;/span&gt; ExponentialRVType()&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-47" data-line-number="47"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-48" data-line-number="48"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-49" data-line-number="49"&gt;&lt;span class="co"&gt;# One with multivariate support&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-50" data-line-number="50"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; MvNormalRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-51" data-line-number="51"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-52" data-line-number="52"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;multivariate_normal&amp;#39;&lt;/span&gt;, theano.config.floatX, &lt;span class="dv"&gt;1&lt;/span&gt;, [&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;multivariate_normal&amp;#39;&lt;/span&gt;, inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-53" data-line-number="53"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-54" data-line-number="54"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, mean, cov, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-55" data-line-number="55"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(mean, cov, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-56" data-line-number="56"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-57" data-line-number="57"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-58" data-line-number="58"&gt;MvNormalRV &lt;span class="op"&gt;=&lt;/span&gt; MvNormalRVType()&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-59" data-line-number="59"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-60" data-line-number="60"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-61" data-line-number="61"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; DirichletRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-62" data-line-number="62"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-63" data-line-number="63"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;dirichlet&amp;#39;&lt;/span&gt;, theano.config.floatX, &lt;span class="dv"&gt;1&lt;/span&gt;, [&lt;span class="dv"&gt;1&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;dirichlet&amp;#39;&lt;/span&gt;, inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-64" data-line-number="64"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-65" data-line-number="65"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, alpha, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-66" data-line-number="66"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(alpha, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-67" data-line-number="67"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-68" data-line-number="68"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-69" data-line-number="69"&gt;DirichletRV &lt;span class="op"&gt;=&lt;/span&gt; DirichletRVType()&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-70" data-line-number="70"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-71" data-line-number="71"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-72" data-line-number="72"&gt;&lt;span class="co"&gt;# A discrete Numpy-generated variate&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-73" data-line-number="73"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; PoissonRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-74" data-line-number="74"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-75" data-line-number="75"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;poisson&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;int64&amp;#39;&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;, [&lt;span class="dv"&gt;0&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;poisson&amp;#39;&lt;/span&gt;, inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-76" data-line-number="76"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-77" data-line-number="77"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, rate, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-78" data-line-number="78"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(rate, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-79" data-line-number="79"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-80" data-line-number="80"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-81" data-line-number="81"&gt;PoissonRV &lt;span class="op"&gt;=&lt;/span&gt; PoissonRVType()&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-82" data-line-number="82"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-83" data-line-number="83"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-84" data-line-number="84"&gt;&lt;span class="co"&gt;# A SciPy-generated variate&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-85" data-line-number="85"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; CauchyRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-86" data-line-number="86"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-87" data-line-number="87"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;cauchy&amp;#39;&lt;/span&gt;, theano.config.floatX, &lt;span class="dv"&gt;0&lt;/span&gt;, [&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-88" data-line-number="88"&gt;                         &lt;span class="kw"&gt;lambda&lt;/span&gt; rng, &lt;span class="op"&gt;*&lt;/span&gt;args: scipy.stats.cauchy.rvs(&lt;span class="op"&gt;*&lt;/span&gt;args, random_state&lt;span class="op"&gt;=&lt;/span&gt;rng),&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-89" data-line-number="89"&gt;                         inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-90" data-line-number="90"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-91" data-line-number="91"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, loc, scale, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-92" data-line-number="92"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(loc, scale, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-93" data-line-number="93"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-94" data-line-number="94"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-95" data-line-number="95"&gt;CauchyRV &lt;span class="op"&gt;=&lt;/span&gt; CauchyRVType()&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-96" data-line-number="96"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-97" data-line-number="97"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-98" data-line-number="98"&gt;&lt;span class="co"&gt;# Support shape is determined by the first dimension in the *second* parameter (i.e.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-99" data-line-number="99"&gt;&lt;span class="co"&gt;# the probabilities vector)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-100" data-line-number="100"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; MultinomialRVType(RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-101" data-line-number="101"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-102" data-line-number="102"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;multinomial&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;int64&amp;#39;&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;, [&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;], &lt;span class="st"&gt;&amp;#39;multinomial&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-103" data-line-number="103"&gt;                         supp_shape_fn&lt;span class="op"&gt;=&lt;/span&gt;partial(param_supp_shape_fn, rep_param_idx&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-104" data-line-number="104"&gt;                         inplace&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-105" data-line-number="105"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-106" data-line-number="106"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, n, pvals, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, rng&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-107" data-line-number="107"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().make_node(n, pvals, size&lt;span class="op"&gt;=&lt;/span&gt;size, rng&lt;span class="op"&gt;=&lt;/span&gt;rng, name&lt;span class="op"&gt;=&lt;/span&gt;name)&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-108" data-line-number="108"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-109" data-line-number="109"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgf494cec-110" data-line-number="110"&gt;MultinomialRV &lt;span class="op"&gt;=&lt;/span&gt; MultinomialRVType()&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;In Listing &lt;a href="#orged59f09"&gt;18&lt;/a&gt; we draw samples from instances of &lt;code&gt;RandomVariable&lt;/code&gt;s.&lt;/p&gt;
&lt;div class="sourceCode" id="orged59f09"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orged59f09-1" data-line-number="1"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;UniformRV(0., 30., size=[10]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-2" data-line-number="2"&gt;    UniformRV(&lt;span class="fl"&gt;0.&lt;/span&gt;, &lt;span class="fl"&gt;30.&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;10&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-3" data-line-number="3"&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-5" data-line-number="5"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;NormalRV([0., 100.], 30, size=[4, 2]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-6" data-line-number="6"&gt;    NormalRV([&lt;span class="fl"&gt;0.&lt;/span&gt;, &lt;span class="fl"&gt;100.&lt;/span&gt;], &lt;span class="dv"&gt;30&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()))&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-8" data-line-number="8"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;GammaRV([2., 1.], 2., size=[4, 2]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-9" data-line-number="9"&gt;    GammaRV([&lt;span class="fl"&gt;2.&lt;/span&gt;, &lt;span class="fl"&gt;1.&lt;/span&gt;], &lt;span class="fl"&gt;2.&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()))&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-11" data-line-number="11"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;ExponentialRV([2., 50.], size=[4, 2]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-12" data-line-number="12"&gt;    ExponentialRV([&lt;span class="fl"&gt;2.&lt;/span&gt;, &lt;span class="fl"&gt;50.&lt;/span&gt;], size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()))&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-14" data-line-number="14"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;MvNormalRV([0, 1e2, 2e3], np.diag([1, 1, 1]), size=[3, 2, 3]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-15" data-line-number="15"&gt;    MvNormalRV([&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="fl"&gt;1e2&lt;/span&gt;, &lt;span class="fl"&gt;2e3&lt;/span&gt;], np.diag([&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;]), size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()))&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-17" data-line-number="17"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;DirichletRV([0.1, 10, 0.5], size=[3, 2, 3]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-18" data-line-number="18"&gt;    DirichletRV([&lt;span class="fl"&gt;0.1&lt;/span&gt;, &lt;span class="dv"&gt;10&lt;/span&gt;, &lt;span class="fl"&gt;0.5&lt;/span&gt;], size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()))&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-19" data-line-number="19"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-20" data-line-number="20"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;PoissonRV([2., 1.], size=[4, 2]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-21" data-line-number="21"&gt;    PoissonRV([&lt;span class="fl"&gt;2.&lt;/span&gt;, &lt;span class="fl"&gt;15.&lt;/span&gt;], size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()))&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-22" data-line-number="22"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-23" data-line-number="23"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;CauchyRV([1., 100.], 30, size=[4, 2]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-24" data-line-number="24"&gt;    CauchyRV([&lt;span class="fl"&gt;1.&lt;/span&gt;, &lt;span class="fl"&gt;100.&lt;/span&gt;], &lt;span class="dv"&gt;30&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()))&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-25" data-line-number="25"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-26" data-line-number="26"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;MultinomialRV(20, [1/6.]*6, size=[6, 2]):&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orged59f09-27" data-line-number="27"&gt;    MultinomialRV(&lt;span class="dv"&gt;20&lt;/span&gt;, [&lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="op"&gt;/&lt;/span&gt; &lt;span class="fl"&gt;6.&lt;/span&gt;] &lt;span class="op"&gt;*&lt;/span&gt; &lt;span class="dv"&gt;6&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]).&lt;span class="bu"&gt;eval&lt;/span&gt;()))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orga89dd83"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orga89dd83-1" data-line-number="1"&gt;UniformRV(&lt;span class="fl"&gt;0.&lt;/span&gt;, &lt;span class="fl"&gt;30.&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;10&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-2" data-line-number="2"&gt;[ &lt;span class="fl"&gt;5.83131933&lt;/span&gt; &lt;span class="fl"&gt;28.56231204&lt;/span&gt; &lt;span class="fl"&gt;20.73018065&lt;/span&gt; &lt;span class="fl"&gt;17.21042461&lt;/span&gt; &lt;span class="fl"&gt;25.53140341&lt;/span&gt; &lt;span class="fl"&gt;23.76268637&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-3" data-line-number="3"&gt; &lt;span class="fl"&gt;28.27629994&lt;/span&gt;  &lt;span class="fl"&gt;7.10457399&lt;/span&gt; &lt;span class="fl"&gt;19.88378878&lt;/span&gt; &lt;span class="fl"&gt;26.62382369&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-5" data-line-number="5"&gt;NormalRV([&lt;span class="fl"&gt;0.&lt;/span&gt;, &lt;span class="fl"&gt;100.&lt;/span&gt;], &lt;span class="dv"&gt;30&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-6" data-line-number="6"&gt;[[  &lt;span class="fl"&gt;0.73277898&lt;/span&gt;  &lt;span class="fl"&gt;98.26041204&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-7" data-line-number="7"&gt; [&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;25.9810085&lt;/span&gt;   &lt;span class="fl"&gt;79.13385495&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-8" data-line-number="8"&gt; [&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;23.17013683&lt;/span&gt; &lt;span class="fl"&gt;130.86966242&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-9" data-line-number="9"&gt; [&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;52.83756722&lt;/span&gt;  &lt;span class="fl"&gt;95.21829178&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-11" data-line-number="11"&gt;GammaRV([&lt;span class="fl"&gt;2.&lt;/span&gt;, &lt;span class="fl"&gt;1.&lt;/span&gt;], &lt;span class="fl"&gt;2.&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-12" data-line-number="12"&gt;[[&lt;span class="fl"&gt;5.09679154&lt;/span&gt; &lt;span class="fl"&gt;0.6149213&lt;/span&gt; ]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-13" data-line-number="13"&gt; [&lt;span class="fl"&gt;2.64231927&lt;/span&gt; &lt;span class="fl"&gt;0.7277265&lt;/span&gt; ]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-14" data-line-number="14"&gt; [&lt;span class="fl"&gt;5.98877316&lt;/span&gt; &lt;span class="fl"&gt;0.41751667&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-15" data-line-number="15"&gt; [&lt;span class="fl"&gt;3.77525439&lt;/span&gt; &lt;span class="fl"&gt;1.11561567&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-17" data-line-number="17"&gt;ExponentialRV([&lt;span class="fl"&gt;2.&lt;/span&gt;, &lt;span class="fl"&gt;50.&lt;/span&gt;], size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-18" data-line-number="18"&gt;[[ &lt;span class="fl"&gt;2.29684191&lt;/span&gt;  &lt;span class="fl"&gt;7.12084933&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-19" data-line-number="19"&gt; [ &lt;span class="fl"&gt;0.39386731&lt;/span&gt; &lt;span class="fl"&gt;38.79158981&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-20" data-line-number="20"&gt; [ &lt;span class="fl"&gt;1.11400165&lt;/span&gt;  &lt;span class="fl"&gt;4.31175303&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-21" data-line-number="21"&gt; [ &lt;span class="fl"&gt;1.50499115&lt;/span&gt;  &lt;span class="fl"&gt;9.65667649&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-22" data-line-number="22"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-23" data-line-number="23"&gt;MvNormalRV([&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="fl"&gt;1e2&lt;/span&gt;, &lt;span class="fl"&gt;2e3&lt;/span&gt;], np.diag([&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;]), size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-24" data-line-number="24"&gt;[[[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;6.67447019e-01&lt;/span&gt;  &lt;span class="fl"&gt;9.88636435e+01&lt;/span&gt;  &lt;span class="fl"&gt;1.99973471e+03&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-25" data-line-number="25"&gt;  [ &lt;span class="fl"&gt;6.06351715e-01&lt;/span&gt;  &lt;span class="fl"&gt;9.96429347e+01&lt;/span&gt;  &lt;span class="fl"&gt;1.99915978e+03&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-26" data-line-number="26"&gt;  [ &lt;span class="fl"&gt;1.12246741e+00&lt;/span&gt;  &lt;span class="fl"&gt;9.96807860e+01&lt;/span&gt;  &lt;span class="fl"&gt;2.00201859e+03&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-27" data-line-number="27"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-28" data-line-number="28"&gt; [[ &lt;span class="fl"&gt;3.61931404e-02&lt;/span&gt;  &lt;span class="fl"&gt;9.89907880e+01&lt;/span&gt;  &lt;span class="fl"&gt;2.00036910e+03&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-29" data-line-number="29"&gt;  [&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;1.61077330e+00&lt;/span&gt;  &lt;span class="fl"&gt;1.01905479e+02&lt;/span&gt;  &lt;span class="fl"&gt;2.00134565e+03&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-30" data-line-number="30"&gt;  [ &lt;span class="fl"&gt;9.45854243e-01&lt;/span&gt;  &lt;span class="fl"&gt;1.00877071e+02&lt;/span&gt;  &lt;span class="fl"&gt;1.99914438e+03&lt;/span&gt;]]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-31" data-line-number="31"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-32" data-line-number="32"&gt;DirichletRV([&lt;span class="fl"&gt;0.1&lt;/span&gt;, &lt;span class="dv"&gt;10&lt;/span&gt;, &lt;span class="fl"&gt;0.5&lt;/span&gt;], size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-33" data-line-number="33"&gt;[[[&lt;span class="fl"&gt;1.41863953e-06&lt;/span&gt; &lt;span class="fl"&gt;9.35392908e-01&lt;/span&gt; &lt;span class="fl"&gt;6.46056738e-02&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-34" data-line-number="34"&gt;  [&lt;span class="fl"&gt;4.50961569e-15&lt;/span&gt; &lt;span class="fl"&gt;9.71338820e-01&lt;/span&gt; &lt;span class="fl"&gt;2.86611803e-02&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-35" data-line-number="35"&gt;  [&lt;span class="fl"&gt;2.41299980e-05&lt;/span&gt; &lt;span class="fl"&gt;9.94566812e-01&lt;/span&gt; &lt;span class="fl"&gt;5.40905817e-03&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-36" data-line-number="36"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-37" data-line-number="37"&gt; [[&lt;span class="fl"&gt;5.79850503e-08&lt;/span&gt; &lt;span class="fl"&gt;9.73090671e-01&lt;/span&gt; &lt;span class="fl"&gt;2.69092713e-02&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-38" data-line-number="38"&gt;  [&lt;span class="fl"&gt;4.17758767e-09&lt;/span&gt; &lt;span class="fl"&gt;9.61671733e-01&lt;/span&gt; &lt;span class="fl"&gt;3.83282630e-02&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-39" data-line-number="39"&gt;  [&lt;span class="fl"&gt;8.78921782e-03&lt;/span&gt; &lt;span class="fl"&gt;9.54146972e-01&lt;/span&gt; &lt;span class="fl"&gt;3.70638103e-02&lt;/span&gt;]]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-40" data-line-number="40"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-41" data-line-number="41"&gt;PoissonRV([&lt;span class="fl"&gt;2.&lt;/span&gt;, &lt;span class="fl"&gt;1.&lt;/span&gt;], size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-42" data-line-number="42"&gt;[[ &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;15&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-43" data-line-number="43"&gt; [ &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;12&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-44" data-line-number="44"&gt; [ &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;21&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-45" data-line-number="45"&gt; [ &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;14&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-46" data-line-number="46"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-47" data-line-number="47"&gt;CauchyRV([&lt;span class="fl"&gt;1.&lt;/span&gt;, &lt;span class="fl"&gt;100.&lt;/span&gt;], &lt;span class="dv"&gt;30&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-48" data-line-number="48"&gt;[[ &lt;span class="fl"&gt;-86.93222925&lt;/span&gt;   &lt;span class="fl"&gt;79.9758127&lt;/span&gt; ]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-49" data-line-number="49"&gt; [  &lt;span class="fl"&gt;13.41882831&lt;/span&gt; &lt;span class="fl"&gt;-374.41779179&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-50" data-line-number="50"&gt; [  &lt;span class="fl"&gt;75.74505567&lt;/span&gt;   &lt;span class="fl"&gt;93.2944822&lt;/span&gt; ]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-51" data-line-number="51"&gt; [  &lt;span class="fl"&gt;30.0824262&lt;/span&gt;   &lt;span class="fl"&gt;130.40873511&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-52" data-line-number="52"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-53" data-line-number="53"&gt;MultinomialRV(&lt;span class="dv"&gt;20&lt;/span&gt;, [&lt;span class="dv"&gt;1&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;&lt;span class="fl"&gt;6.&lt;/span&gt;]&lt;span class="op"&gt;*&lt;/span&gt;&lt;span class="dv"&gt;6&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="dv"&gt;6&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]):&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-54" data-line-number="54"&gt;[[[&lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-55" data-line-number="55"&gt;  [&lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;5&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;3&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-56" data-line-number="56"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-57" data-line-number="57"&gt; [[&lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;5&lt;/span&gt; &lt;span class="dv"&gt;6&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-58" data-line-number="58"&gt;  [&lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;3&lt;/span&gt; &lt;span class="dv"&gt;5&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-59" data-line-number="59"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-60" data-line-number="60"&gt; [[&lt;span class="dv"&gt;6&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-61" data-line-number="61"&gt;  [&lt;span class="dv"&gt;3&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt; &lt;span class="dv"&gt;3&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;3&lt;/span&gt; &lt;span class="dv"&gt;5&lt;/span&gt;]]]&lt;/a&gt;
&lt;a class="sourceLine" id="orga89dd83-62" data-line-number="62"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As noted, there are a few long-standing difficulties surrounding the use and determination of shape information in PyMC3. &lt;code&gt;RandomVariable&lt;/code&gt; doesn’t suffer the same limitations.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;In Listing &lt;a href="#org77fdfa2"&gt;20&lt;/a&gt;, we see that a multivariate normal random variable cannot be created in PyMC3 without explicit shape information.&lt;/p&gt;
&lt;div class="sourceCode" id="org77fdfa2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org77fdfa2-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; traceback&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-3" data-line-number="3"&gt;test_mean &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;test_mean&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-4" data-line-number="4"&gt;test_cov &lt;span class="op"&gt;=&lt;/span&gt; tt.matrix(&lt;span class="st"&gt;&amp;#39;test_cov&amp;#39;&lt;/span&gt;, dtype&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;int64&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-6" data-line-number="6"&gt;test_mean.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.asarray([&lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-7" data-line-number="7"&gt;test_cov.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.asarray([[&lt;span class="dv"&gt;1&lt;/span&gt;]])&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-9" data-line-number="9"&gt;&lt;span class="cf"&gt;try&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-10" data-line-number="10"&gt;  &lt;span class="cf"&gt;with&lt;/span&gt; pm.Model():&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-11" data-line-number="11"&gt;    test_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.MvNormal(&lt;span class="st"&gt;&amp;#39;test_rv&amp;#39;&lt;/span&gt;, test_mean, test_cov)&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-12" data-line-number="12"&gt;&lt;span class="cf"&gt;except&lt;/span&gt; &lt;span class="pp"&gt;Exception&lt;/span&gt; &lt;span class="im"&gt;as&lt;/span&gt; e:&lt;/a&gt;
&lt;a class="sourceLine" id="org77fdfa2-13" data-line-number="13"&gt;  &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;&amp;quot;&lt;/span&gt;.join(traceback.format_exception_only(&lt;span class="bu"&gt;type&lt;/span&gt;(e), e)))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org9a55c25"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org9a55c25-1" data-line-number="1"&gt;&lt;span class="pp"&gt;ValueError&lt;/span&gt;: Invalid dimension &lt;span class="cf"&gt;for&lt;/span&gt; value: &lt;span class="dv"&gt;0&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9a55c25-2" data-line-number="2"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As Listing &lt;a href="#orgb7414f6"&gt;22&lt;/a&gt; demonstrates, the same construction is possible when one specifies an explicit size/shape.&lt;/p&gt;
&lt;div class="sourceCode" id="orgb7414f6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgb7414f6-1" data-line-number="1"&gt;&lt;span class="cf"&gt;try&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7414f6-2" data-line-number="2"&gt;  &lt;span class="cf"&gt;with&lt;/span&gt; pm.Model():&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7414f6-3" data-line-number="3"&gt;    test_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.MvNormal(&lt;span class="st"&gt;&amp;#39;test_rv&amp;#39;&lt;/span&gt;, test_mean, test_cov, shape&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7414f6-4" data-line-number="4"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;test_rv.distribution.shape = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(test_rv.distribution.shape))&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7414f6-5" data-line-number="5"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;test_rv.tag.test_value = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(test_rv.tag.test_value))&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7414f6-6" data-line-number="6"&gt;&lt;span class="cf"&gt;except&lt;/span&gt; &lt;span class="pp"&gt;Exception&lt;/span&gt; &lt;span class="im"&gt;as&lt;/span&gt; e:&lt;/a&gt;
&lt;a class="sourceLine" id="orgb7414f6-7" data-line-number="7"&gt;  &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;&amp;quot;&lt;/span&gt;.join(traceback.format_exception_only(&lt;span class="bu"&gt;type&lt;/span&gt;(e), e)))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orga8cc629"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orga8cc629-1" data-line-number="1"&gt;test_rv.distribution.shape &lt;span class="op"&gt;=&lt;/span&gt; [&lt;span class="dv"&gt;1&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga8cc629-2" data-line-number="2"&gt;test_rv.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; [&lt;span class="fl"&gt;1.&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orga8cc629-3" data-line-number="3"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Using &lt;code&gt;RandomVariable&lt;/code&gt;, we do not have to specify a shape, nor implement any sampling code outside of &lt;code&gt;RandomVariable.perform&lt;/code&gt; to draw random variables and generate valid test values.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;Listings &lt;a href="#org67b2727"&gt;24&lt;/a&gt; and &lt;a href="#org56bde38"&gt;26&lt;/a&gt; demonstrate how easy it is to create dependencies between random variates using &lt;code&gt;RandomVariable&lt;/code&gt;, and how sampling and test values are automatic. It uses a multivariate normal as the mean of another multivariate normal.&lt;/p&gt;
&lt;div class="sourceCode" id="org67b2727"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org67b2727-1" data-line-number="1"&gt;theano.config.compute_test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-3" data-line-number="3"&gt;mu_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;mu&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-4" data-line-number="4"&gt;C_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.matrix(&lt;span class="st"&gt;&amp;#39;C&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-5" data-line-number="5"&gt;D_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.matrix(&lt;span class="st"&gt;&amp;#39;D&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-7" data-line-number="7"&gt;X_rv &lt;span class="op"&gt;=&lt;/span&gt; MvNormalRV(mu_tt, C_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-8" data-line-number="8"&gt;Y_rv &lt;span class="op"&gt;=&lt;/span&gt; MvNormalRV(X_rv, D_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-10" data-line-number="10"&gt;&lt;span class="co"&gt;# Sample some values under specific parameter values&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-11" data-line-number="11"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt; ~ X&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt; ~ Y&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-12" data-line-number="12"&gt;    X_rv.&lt;span class="bu"&gt;eval&lt;/span&gt;({mu_tt: [&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;], C_tt: np.diag([&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;])}),&lt;/a&gt;
&lt;a class="sourceLine" id="org67b2727-13" data-line-number="13"&gt;    Y_rv.&lt;span class="bu"&gt;eval&lt;/span&gt;({mu_tt: [&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;], C_tt: np.diag([&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]), D_tt: np.diag([&lt;span class="dv"&gt;10&lt;/span&gt;, &lt;span class="dv"&gt;20&lt;/span&gt;])})))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgd1cac3d"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgd1cac3d-1" data-line-number="1"&gt;[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;1.25047147&lt;/span&gt;  &lt;span class="fl"&gt;4.87459955&lt;/span&gt;] &lt;span class="op"&gt;~&lt;/span&gt; X&lt;/a&gt;
&lt;a class="sourceLine" id="orgd1cac3d-2" data-line-number="2"&gt;[ &lt;span class="fl"&gt;2.15486205&lt;/span&gt; &lt;span class="fl"&gt;-3.3066946&lt;/span&gt; ] &lt;span class="op"&gt;~&lt;/span&gt; Y&lt;/a&gt;
&lt;a class="sourceLine" id="orgd1cac3d-3" data-line-number="3"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org56bde38"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org56bde38-1" data-line-number="1"&gt;theano.config.compute_test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;warn&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-3" data-line-number="3"&gt;mu_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;30&lt;/span&gt;, &lt;span class="dv"&gt;40&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-4" data-line-number="4"&gt;C_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.diag([&lt;span class="dv"&gt;100&lt;/span&gt;, &lt;span class="dv"&gt;10&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-5" data-line-number="5"&gt;D_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.diag([&lt;span class="dv"&gt;100&lt;/span&gt;, &lt;span class="dv"&gt;10&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-7" data-line-number="7"&gt;X_rv &lt;span class="op"&gt;=&lt;/span&gt; MvNormalRV(mu_tt, C_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-8" data-line-number="8"&gt;Y_rv &lt;span class="op"&gt;=&lt;/span&gt; MvNormalRV(X_rv, D_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-10" data-line-number="10"&gt;&lt;span class="co"&gt;# Observe the automatically generated test values&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-11" data-line-number="11"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;X test value: &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;Y test value: &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-12" data-line-number="12"&gt;    X_rv.tag.test_value,&lt;/a&gt;
&lt;a class="sourceLine" id="org56bde38-13" data-line-number="13"&gt;    Y_rv.tag.test_value))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgecacfb5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgecacfb5-1" data-line-number="1"&gt;X test value: [ &lt;span class="fl"&gt;1.78826967&lt;/span&gt; &lt;span class="fl"&gt;28.73266332&lt;/span&gt; &lt;span class="fl"&gt;38.57297111&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgecacfb5-2" data-line-number="2"&gt;Y test value: [&lt;span class="fl"&gt;33.93703352&lt;/span&gt; &lt;span class="fl"&gt;27.48925582&lt;/span&gt; &lt;span class="fl"&gt;38.21563854&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgecacfb5-3" data-line-number="3"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;In Listing &lt;a href="#orge489ad8"&gt;28&lt;/a&gt;, we specify the following hierarchical model:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
  \begin{aligned}
    M &amp;amp;\sim \text{Poisson}\left(10\right)
    \\
    \alpha_i &amp;amp;\sim \text{Uniform}\left(0, 1\right),
    \quad i \in \left\{0, \dots, M\right\}
    \\
    \pi &amp;amp;\sim \text{Dirichlet}\left(\alpha\right)
    \\
    Y &amp;amp;\sim \text{Multinomial}\left(M, \pi\right)
  \end{aligned}
  \;.
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This toy model is particularly interesting in how it specifies symbolic dependencies between continuous and discrete distributions and uses random variables to determine the shapes of other random variables.&lt;/p&gt;
&lt;div class="sourceCode" id="orge489ad8"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orge489ad8-1" data-line-number="1"&gt;theano.config.compute_test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-2" data-line-number="2"&gt;pois_rate &lt;span class="op"&gt;=&lt;/span&gt; tt.dscalar(&lt;span class="st"&gt;&amp;#39;rate&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-3" data-line-number="3"&gt;test_pois_rv &lt;span class="op"&gt;=&lt;/span&gt; PoissonRV(pois_rate)&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-4" data-line-number="4"&gt;test_alpha &lt;span class="op"&gt;=&lt;/span&gt; UniformRV(&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;, size&lt;span class="op"&gt;=&lt;/span&gt;test_pois_rv)&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-5" data-line-number="5"&gt;test_dirichlet_rv &lt;span class="op"&gt;=&lt;/span&gt; DirichletRV(test_uniform_rv)&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-6" data-line-number="6"&gt;test_multinom_rv &lt;span class="op"&gt;=&lt;/span&gt; MultinomialRV(test_pois_rv, test_dirichlet_rv)&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-8" data-line-number="8"&gt;test_multinom_draw &lt;span class="op"&gt;=&lt;/span&gt; theano.function(inputs&lt;span class="op"&gt;=&lt;/span&gt;[], outputs&lt;span class="op"&gt;=&lt;/span&gt;test_multinom_rv,&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-9" data-line-number="9"&gt;                                     givens&lt;span class="op"&gt;=&lt;/span&gt;{pois_rate: &lt;span class="fl"&gt;10.&lt;/span&gt;})&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-11" data-line-number="11"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;test_multinom_rv draw 1: &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;test_multinom_rv draw 2: &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orge489ad8-12" data-line-number="12"&gt;    test_multinom_draw(), test_multinom_draw()))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgff8bd09"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgff8bd09-1" data-line-number="1"&gt;test_multinom_rv draw &lt;span class="dv"&gt;1&lt;/span&gt;: [&lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgff8bd09-2" data-line-number="2"&gt;test_multinom_rv draw &lt;span class="dv"&gt;2&lt;/span&gt;: [&lt;span class="dv"&gt;5&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgff8bd09-3" data-line-number="3"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;section id="random-variable-pretty-printing" class="level2"&gt;
&lt;h2&gt;Random Variable Pretty Printing&lt;/h2&gt;
&lt;p&gt;In Listing &lt;a href="#org52ecc27"&gt;30&lt;/a&gt;, we implement a pretty printer that produces more readable forms of Theano graphs containing &lt;code&gt;RandomVariable&lt;/code&gt; nodes.&lt;/p&gt;
&lt;div class="sourceCode" id="org52ecc27"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org52ecc27-1" data-line-number="1"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; RandomVariablePrinter:&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-2" data-line-number="2"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Pretty print random variables.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-3" data-line-number="3"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-4" data-line-number="4"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-5" data-line-number="5"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-6" data-line-number="6"&gt;&lt;span class="co"&gt;        Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-7" data-line-number="7"&gt;&lt;span class="co"&gt;        ==========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-8" data-line-number="8"&gt;&lt;span class="co"&gt;        name: str (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-9" data-line-number="9"&gt;&lt;span class="co"&gt;            A fixed name to use for the random variables printed by this&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-10" data-line-number="10"&gt;&lt;span class="co"&gt;            printer.  If not specified, use `RandomVariable.name`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-11" data-line-number="11"&gt;&lt;span class="co"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-12" data-line-number="12"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.name &lt;span class="op"&gt;=&lt;/span&gt; name&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-14" data-line-number="14"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process_param(&lt;span class="va"&gt;self&lt;/span&gt;, idx, sform, pstate):&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-15" data-line-number="15"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Special per-parameter post-formatting.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-17" data-line-number="17"&gt;&lt;span class="co"&gt;        This can be used, for instance, to change a std. dev. into a variance.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-19" data-line-number="19"&gt;&lt;span class="co"&gt;        Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-20" data-line-number="20"&gt;&lt;span class="co"&gt;        ==========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-21" data-line-number="21"&gt;&lt;span class="co"&gt;        idx: int&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-22" data-line-number="22"&gt;&lt;span class="co"&gt;            The index value of the parameter.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-23" data-line-number="23"&gt;&lt;span class="co"&gt;        sform: str&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-24" data-line-number="24"&gt;&lt;span class="co"&gt;            The pre-formatted string form of the parameter.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-25" data-line-number="25"&gt;&lt;span class="co"&gt;        pstate: object&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-26" data-line-number="26"&gt;&lt;span class="co"&gt;            The printer state.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-27" data-line-number="27"&gt;&lt;span class="co"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-28" data-line-number="28"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; sform&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-29" data-line-number="29"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-30" data-line-number="30"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process(&lt;span class="va"&gt;self&lt;/span&gt;, output, pstate):&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-31" data-line-number="31"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; output &lt;span class="kw"&gt;in&lt;/span&gt; pstate.memo:&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-32" data-line-number="32"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; pstate.memo[output]&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-33" data-line-number="33"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-34" data-line-number="34"&gt;        pprinter &lt;span class="op"&gt;=&lt;/span&gt; pstate.pprinter&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-35" data-line-number="35"&gt;        node &lt;span class="op"&gt;=&lt;/span&gt; output.owner&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-36" data-line-number="36"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-37" data-line-number="37"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; node &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt; &lt;span class="kw"&gt;or&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(node.op, RandomVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-38" data-line-number="38"&gt;            &lt;span class="cf"&gt;raise&lt;/span&gt; &lt;span class="pp"&gt;TypeError&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;function &lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt; cannot represent a variable that is &amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-39" data-line-number="39"&gt;                            &lt;span class="st"&gt;&amp;quot;not the result of a RandomVariable operation&amp;quot;&lt;/span&gt; &lt;span class="op"&gt;%&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-40" data-line-number="40"&gt;                            &lt;span class="va"&gt;self&lt;/span&gt;.name)&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-41" data-line-number="41"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-42" data-line-number="42"&gt;        new_precedence &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;-1000&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-43" data-line-number="43"&gt;        &lt;span class="cf"&gt;try&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-44" data-line-number="44"&gt;            old_precedence &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;precedence&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-45" data-line-number="45"&gt;            pstate.precedence &lt;span class="op"&gt;=&lt;/span&gt; new_precedence&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-46" data-line-number="46"&gt;            out_name &lt;span class="op"&gt;=&lt;/span&gt; VariableWithShapePrinter.process_variable_name(&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-47" data-line-number="47"&gt;                output, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-48" data-line-number="48"&gt;            shape_info_str &lt;span class="op"&gt;=&lt;/span&gt; VariableWithShapePrinter.process_shape_info(&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-49" data-line-number="49"&gt;                output, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-50" data-line-number="50"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;latex&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-51" data-line-number="51"&gt;                dist_format &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt; &lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;sim &lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;operatorname{&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;}&lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;left(&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;right)&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-52" data-line-number="52"&gt;                dist_format &lt;span class="op"&gt;+=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;, &lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;quad &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(shape_info_str)&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-53" data-line-number="53"&gt;            &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-54" data-line-number="54"&gt;                dist_format &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt; ~ &lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;(&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;)&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-55" data-line-number="55"&gt;                dist_format &lt;span class="op"&gt;+=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;,  &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(shape_info_str)&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-56" data-line-number="56"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-57" data-line-number="57"&gt;            op_name &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.name &lt;span class="kw"&gt;or&lt;/span&gt; node.op.name&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-58" data-line-number="58"&gt;            dist_params &lt;span class="op"&gt;=&lt;/span&gt; node.inputs[:&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-59" data-line-number="59"&gt;            formatted_params &lt;span class="op"&gt;=&lt;/span&gt; [&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-60" data-line-number="60"&gt;                &lt;span class="va"&gt;self&lt;/span&gt;.process_param(i, pprinter.process(p, pstate), pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-61" data-line-number="61"&gt;                &lt;span class="cf"&gt;for&lt;/span&gt; i, p &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;enumerate&lt;/span&gt;(dist_params)&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-62" data-line-number="62"&gt;            ]&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-63" data-line-number="63"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-64" data-line-number="64"&gt;            dist_params_r &lt;span class="op"&gt;=&lt;/span&gt; dist_format &lt;span class="op"&gt;%&lt;/span&gt; (out_name,&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-65" data-line-number="65"&gt;                                           op_name,&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-66" data-line-number="66"&gt;                                           &lt;span class="st"&gt;&amp;quot;, &amp;quot;&lt;/span&gt;.join(formatted_params))&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-67" data-line-number="67"&gt;        &lt;span class="cf"&gt;finally&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-68" data-line-number="68"&gt;            pstate.precedence &lt;span class="op"&gt;=&lt;/span&gt; old_precedence&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-69" data-line-number="69"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-70" data-line-number="70"&gt;        pstate.preamble_lines &lt;span class="op"&gt;+=&lt;/span&gt; [dist_params_r]&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-71" data-line-number="71"&gt;        pstate.memo[output] &lt;span class="op"&gt;=&lt;/span&gt; out_name&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-72" data-line-number="72"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org52ecc27-73" data-line-number="73"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; out_name&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org414cfc6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org414cfc6-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; string&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-3" data-line-number="3"&gt;&lt;span class="im"&gt;from&lt;/span&gt; copy &lt;span class="im"&gt;import&lt;/span&gt; copy&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-4" data-line-number="4"&gt;&lt;span class="im"&gt;from&lt;/span&gt; collections &lt;span class="im"&gt;import&lt;/span&gt; OrderedDict&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-6" data-line-number="6"&gt;&lt;span class="im"&gt;from&lt;/span&gt; sympy &lt;span class="im"&gt;import&lt;/span&gt; Array &lt;span class="im"&gt;as&lt;/span&gt; SympyArray&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-7" data-line-number="7"&gt;&lt;span class="im"&gt;from&lt;/span&gt; sympy.printing &lt;span class="im"&gt;import&lt;/span&gt; latex &lt;span class="im"&gt;as&lt;/span&gt; sympy_latex&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-10" data-line-number="10"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; VariableWithShapePrinter:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-11" data-line-number="11"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Print variable shape info in the preamble and use readable character&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-12" data-line-number="12"&gt;&lt;span class="co"&gt;    names for unamed variables.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-13" data-line-number="13"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-14" data-line-number="14"&gt;    available_names &lt;span class="op"&gt;=&lt;/span&gt; OrderedDict.fromkeys(string.ascii_letters)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-15" data-line-number="15"&gt;    default_printer &lt;span class="op"&gt;=&lt;/span&gt; theano.printing.default_printer&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-17" data-line-number="17"&gt;    &lt;span class="at"&gt;@classmethod&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-18" data-line-number="18"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process(cls, output, pstate):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-19" data-line-number="19"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; output &lt;span class="kw"&gt;in&lt;/span&gt; pstate.memo:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-20" data-line-number="20"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; pstate.memo[output]&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-22" data-line-number="22"&gt;        using_latex &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;latex&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-23" data-line-number="23"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-24" data-line-number="24"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(output, tt.gof.Constant):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-25" data-line-number="25"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; output.ndim &lt;span class="op"&gt;&amp;gt;&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="kw"&gt;and&lt;/span&gt; using_latex:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-26" data-line-number="26"&gt;                out_name &lt;span class="op"&gt;=&lt;/span&gt; sympy_latex(SympyArray(output.data))&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-27" data-line-number="27"&gt;            &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-28" data-line-number="28"&gt;                out_name &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;str&lt;/span&gt;(output.data)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-29" data-line-number="29"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(output, tt.TensorVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-30" data-line-number="30"&gt;            &lt;span class="co"&gt;# Process name and shape&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-31" data-line-number="31"&gt;            out_name &lt;span class="op"&gt;=&lt;/span&gt; cls.process_variable_name(output, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-32" data-line-number="32"&gt;            shape_info &lt;span class="op"&gt;=&lt;/span&gt; cls.process_shape_info(output, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-33" data-line-number="33"&gt;            pstate.preamble_lines &lt;span class="op"&gt;+=&lt;/span&gt; [shape_info]&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-34" data-line-number="34"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; output.name:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-35" data-line-number="35"&gt;            out_name &lt;span class="op"&gt;=&lt;/span&gt; output.name&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-36" data-line-number="36"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-37" data-line-number="37"&gt;            out_name &lt;span class="op"&gt;=&lt;/span&gt; cls.default_printer.process(output, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-38" data-line-number="38"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-39" data-line-number="39"&gt;        pstate.memo[output] &lt;span class="op"&gt;=&lt;/span&gt; out_name&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-40" data-line-number="40"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; out_name&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-41" data-line-number="41"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-42" data-line-number="42"&gt;    &lt;span class="at"&gt;@classmethod&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-43" data-line-number="43"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process_shape_name(cls, output, pstate):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-44" data-line-number="44"&gt;        shape_of_var &lt;span class="op"&gt;=&lt;/span&gt; output.owner.inputs[&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-45" data-line-number="45"&gt;        shape_names &lt;span class="op"&gt;=&lt;/span&gt; pstate.memo.setdefault(&lt;span class="st"&gt;&amp;#39;shape_names&amp;#39;&lt;/span&gt;, {})&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-46" data-line-number="46"&gt;        out_name &lt;span class="op"&gt;=&lt;/span&gt; shape_names.setdefault(&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-47" data-line-number="47"&gt;            shape_of_var, cls.process_variable_name(output, pstate))&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-48" data-line-number="48"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; out_name&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-49" data-line-number="49"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-50" data-line-number="50"&gt;    &lt;span class="at"&gt;@classmethod&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-51" data-line-number="51"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process_variable_name(cls, output, pstate):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-52" data-line-number="52"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; output &lt;span class="kw"&gt;in&lt;/span&gt; pstate.memo:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-53" data-line-number="53"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; pstate.memo[output]&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-54" data-line-number="54"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-55" data-line-number="55"&gt;        available_names &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;available_names&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-56" data-line-number="56"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; available_names &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-57" data-line-number="57"&gt;            &lt;span class="co"&gt;# Initialize this state&amp;#39;s available names&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-58" data-line-number="58"&gt;            available_names &lt;span class="op"&gt;=&lt;/span&gt; copy(cls.available_names)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-59" data-line-number="59"&gt;            fgraph &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(output, &lt;span class="st"&gt;&amp;#39;fgraph&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-60" data-line-number="60"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; fgraph:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-61" data-line-number="61"&gt;                &lt;span class="co"&gt;# Remove known names in the graph.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-62" data-line-number="62"&gt;                _ &lt;span class="op"&gt;=&lt;/span&gt; [available_names.pop(v.name, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-63" data-line-number="63"&gt;                     &lt;span class="cf"&gt;for&lt;/span&gt; v &lt;span class="kw"&gt;in&lt;/span&gt; fgraph.variables]&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-64" data-line-number="64"&gt;            &lt;span class="bu"&gt;setattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;available_names&amp;#39;&lt;/span&gt;, available_names)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-65" data-line-number="65"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-66" data-line-number="66"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; output.name:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-67" data-line-number="67"&gt;            &lt;span class="co"&gt;# Observed an existing name; remove it.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-68" data-line-number="68"&gt;            out_name &lt;span class="op"&gt;=&lt;/span&gt; output.name&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-69" data-line-number="69"&gt;            available_names.pop(out_name, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-70" data-line-number="70"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-71" data-line-number="71"&gt;            &lt;span class="co"&gt;# Take an unused name.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-72" data-line-number="72"&gt;            out_name, _ &lt;span class="op"&gt;=&lt;/span&gt; available_names.popitem(last&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-73" data-line-number="73"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-74" data-line-number="74"&gt;        pstate.memo[output] &lt;span class="op"&gt;=&lt;/span&gt; out_name&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-75" data-line-number="75"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; out_name&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-76" data-line-number="76"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-77" data-line-number="77"&gt;    &lt;span class="at"&gt;@classmethod&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-78" data-line-number="78"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process_shape_info(cls, output, pstate):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-79" data-line-number="79"&gt;        using_latex &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;latex&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-80" data-line-number="80"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-81" data-line-number="81"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; output.dtype &lt;span class="kw"&gt;in&lt;/span&gt; tt.int_dtypes:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-82" data-line-number="82"&gt;            sspace_char &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;Z&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-83" data-line-number="83"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; output.dtype &lt;span class="kw"&gt;in&lt;/span&gt; tt.uint_dtypes:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-84" data-line-number="84"&gt;            sspace_char &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-85" data-line-number="85"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; output.dtype &lt;span class="kw"&gt;in&lt;/span&gt; tt.float_dtypes:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-86" data-line-number="86"&gt;            sspace_char &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;R&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-87" data-line-number="87"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-88" data-line-number="88"&gt;            sspace_char &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;?&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-89" data-line-number="89"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-90" data-line-number="90"&gt;        fgraph &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(output, &lt;span class="st"&gt;&amp;#39;fgraph&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-91" data-line-number="91"&gt;        shape_feature &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-92" data-line-number="92"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; fgraph:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-93" data-line-number="93"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;hasattr&lt;/span&gt;(fgraph, &lt;span class="st"&gt;&amp;#39;shape_feature&amp;#39;&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-94" data-line-number="94"&gt;                fgraph.attach_feature(tt.opt.ShapeFeature())&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-95" data-line-number="95"&gt;            shape_feature &lt;span class="op"&gt;=&lt;/span&gt; fgraph.shape_feature&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-96" data-line-number="96"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-97" data-line-number="97"&gt;        shape_dims &lt;span class="op"&gt;=&lt;/span&gt; []&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-98" data-line-number="98"&gt;        &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;range&lt;/span&gt;(output.ndim):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-99" data-line-number="99"&gt;            s_i_out &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-100" data-line-number="100"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; using_latex:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-101" data-line-number="101"&gt;                s_i_pat &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;{n^{&lt;/span&gt;&lt;span class="sc"&gt;%s}}&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt; &lt;span class="op"&gt;+&lt;/span&gt; (&lt;span class="st"&gt;&amp;#39;_{&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;}&amp;#39;&lt;/span&gt; &lt;span class="op"&gt;%&lt;/span&gt; i)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-102" data-line-number="102"&gt;            &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-103" data-line-number="103"&gt;                s_i_pat &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;n^&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt; &lt;span class="op"&gt;+&lt;/span&gt; (&lt;span class="st"&gt;&amp;#39;_&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt; &lt;span class="op"&gt;%&lt;/span&gt; i)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-104" data-line-number="104"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; shape_feature:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-105" data-line-number="105"&gt;                new_precedence &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;-1000&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-106" data-line-number="106"&gt;                &lt;span class="cf"&gt;try&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-107" data-line-number="107"&gt;                    old_precedence &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;precedence&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-108" data-line-number="108"&gt;                    pstate.precedence &lt;span class="op"&gt;=&lt;/span&gt; new_precedence&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-109" data-line-number="109"&gt;                    _s_i_out &lt;span class="op"&gt;=&lt;/span&gt; shape_feature.get_shape(output, i)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-110" data-line-number="110"&gt;                    &lt;span class="cf"&gt;if&lt;/span&gt; _s_i_out.owner:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-111" data-line-number="111"&gt;                        &lt;span class="cf"&gt;if&lt;/span&gt; (&lt;span class="bu"&gt;isinstance&lt;/span&gt;(_s_i_out.owner.op, tt.Subtensor) &lt;span class="kw"&gt;and&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-112" data-line-number="112"&gt;                            &lt;span class="bu"&gt;all&lt;/span&gt;(&lt;span class="bu"&gt;isinstance&lt;/span&gt;(i, tt.Constant)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-113" data-line-number="113"&gt;                                &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; _s_i_out.owner.inputs)):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-114" data-line-number="114"&gt;                            s_i_out &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;str&lt;/span&gt;(_s_i_out.owner.inputs[&lt;span class="dv"&gt;0&lt;/span&gt;].data[&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-115" data-line-number="115"&gt;                                _s_i_out.owner.inputs[&lt;span class="dv"&gt;1&lt;/span&gt;].data])&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-116" data-line-number="116"&gt;                        &lt;span class="cf"&gt;elif&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(_s_i_out, tt.TensorVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-117" data-line-number="117"&gt;                            s_i_out &lt;span class="op"&gt;=&lt;/span&gt; pstate.pprinter.process(_s_i_out, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-118" data-line-number="118"&gt;                &lt;span class="cf"&gt;except&lt;/span&gt; &lt;span class="pp"&gt;KeyError&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-119" data-line-number="119"&gt;                    &lt;span class="cf"&gt;pass&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-120" data-line-number="120"&gt;                &lt;span class="cf"&gt;finally&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-121" data-line-number="121"&gt;                    pstate.precedence &lt;span class="op"&gt;=&lt;/span&gt; old_precedence&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-122" data-line-number="122"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-123" data-line-number="123"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; s_i_out:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-124" data-line-number="124"&gt;                s_i_out &lt;span class="op"&gt;=&lt;/span&gt; cls.process_variable_name(output, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-125" data-line-number="125"&gt;                s_i_out &lt;span class="op"&gt;=&lt;/span&gt; s_i_pat &lt;span class="op"&gt;%&lt;/span&gt; s_i_out&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-126" data-line-number="126"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-127" data-line-number="127"&gt;            shape_dims &lt;span class="op"&gt;+=&lt;/span&gt; [s_i_out]&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-128" data-line-number="128"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-129" data-line-number="129"&gt;        shape_info &lt;span class="op"&gt;=&lt;/span&gt; cls.process_variable_name(output, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-130" data-line-number="130"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; using_latex:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-131" data-line-number="131"&gt;            shape_info &lt;span class="op"&gt;+=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39; &lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;in &lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;mathbb{&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;}&amp;#39;&lt;/span&gt; &lt;span class="op"&gt;%&lt;/span&gt; sspace_char&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-132" data-line-number="132"&gt;            shape_dims &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39; &lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;times &amp;#39;&lt;/span&gt;.join(shape_dims)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-133" data-line-number="133"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; shape_dims:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-134" data-line-number="134"&gt;                shape_info &lt;span class="op"&gt;+=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;^{&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;}&amp;#39;&lt;/span&gt; &lt;span class="op"&gt;%&lt;/span&gt; shape_dims&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-135" data-line-number="135"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-136" data-line-number="136"&gt;            shape_info &lt;span class="op"&gt;+=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39; in &lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt; &lt;span class="op"&gt;%&lt;/span&gt; sspace_char&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-137" data-line-number="137"&gt;            shape_dims &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39; x &amp;#39;&lt;/span&gt;.join(shape_dims)&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-138" data-line-number="138"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; shape_dims:&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-139" data-line-number="139"&gt;                shape_info &lt;span class="op"&gt;+=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;**(&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="st"&gt;)&amp;#39;&lt;/span&gt; &lt;span class="op"&gt;%&lt;/span&gt; shape_dims&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-140" data-line-number="140"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org414cfc6-141" data-line-number="141"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; shape_info&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgccd5273"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgccd5273-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; textwrap&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-4" data-line-number="4"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; PreamblePPrinter(theano.printing.PPrinter):&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-5" data-line-number="5"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Pretty printer that displays a preamble.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-7" data-line-number="7"&gt;&lt;span class="co"&gt;    For example,&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-9" data-line-number="9"&gt;&lt;span class="co"&gt;        X ~ N(\mu, \sigma)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-10" data-line-number="10"&gt;&lt;span class="co"&gt;        (b * X)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-12" data-line-number="12"&gt;&lt;span class="co"&gt;    XXX: Not thread-safe!&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-13" data-line-number="13"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-14" data-line-number="14"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;, &lt;span class="op"&gt;*&lt;/span&gt;args, pstate_defaults&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, &lt;span class="op"&gt;**&lt;/span&gt;kwargs):&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-15" data-line-number="15"&gt;        &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-16" data-line-number="16"&gt;&lt;span class="co"&gt;        Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-17" data-line-number="17"&gt;&lt;span class="co"&gt;        ==========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-18" data-line-number="18"&gt;&lt;span class="co"&gt;        pstate_defaults: dict (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-19" data-line-number="19"&gt;&lt;span class="co"&gt;            Default printer state parameters.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-20" data-line-number="20"&gt;&lt;span class="co"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-21" data-line-number="21"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="op"&gt;*&lt;/span&gt;args, &lt;span class="op"&gt;**&lt;/span&gt;kwargs)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-22" data-line-number="22"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.pstate_defaults &lt;span class="op"&gt;=&lt;/span&gt; pstate_defaults &lt;span class="kw"&gt;or&lt;/span&gt; {}&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-23" data-line-number="23"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.printers_dict &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;dict&lt;/span&gt;(tt.pprint.printers_dict)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-24" data-line-number="24"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.printers &lt;span class="op"&gt;=&lt;/span&gt; copy(tt.pprint.printers)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-25" data-line-number="25"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;._pstate &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-26" data-line-number="26"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-27" data-line-number="27"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; create_state(&lt;span class="va"&gt;self&lt;/span&gt;, pstate):&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-28" data-line-number="28"&gt;        &lt;span class="co"&gt;# &lt;/span&gt;&lt;span class="al"&gt;FIXME&lt;/span&gt;&lt;span class="co"&gt;: Find all the user-defined node names and make the tag&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-29" data-line-number="29"&gt;        &lt;span class="co"&gt;# generator aware of them.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-30" data-line-number="30"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; pstate &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-31" data-line-number="31"&gt;            pstate &lt;span class="op"&gt;=&lt;/span&gt; theano.printing.PrinterState(&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-32" data-line-number="32"&gt;                pprinter&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;self&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-33" data-line-number="33"&gt;                preamble_lines&lt;span class="op"&gt;=&lt;/span&gt;[],&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-34" data-line-number="34"&gt;                &lt;span class="op"&gt;**&lt;/span&gt;&lt;span class="va"&gt;self&lt;/span&gt;.pstate_defaults)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-35" data-line-number="35"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(pstate, &lt;span class="bu"&gt;dict&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-36" data-line-number="36"&gt;            pstate.setdefault(&lt;span class="st"&gt;&amp;#39;preamble_lines&amp;#39;&lt;/span&gt;, [])&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-37" data-line-number="37"&gt;            pstate.update(&lt;span class="va"&gt;self&lt;/span&gt;.pstate_defaults)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-38" data-line-number="38"&gt;            pstate &lt;span class="op"&gt;=&lt;/span&gt; theano.printing.PrinterState(pprinter&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;self&lt;/span&gt;, &lt;span class="op"&gt;**&lt;/span&gt;pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-39" data-line-number="39"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-40" data-line-number="40"&gt;        &lt;span class="co"&gt;# &lt;/span&gt;&lt;span class="al"&gt;FIXME&lt;/span&gt;&lt;span class="co"&gt;: Good old fashioned circular references...&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-41" data-line-number="41"&gt;        &lt;span class="co"&gt;# We&amp;#39;re doing this so that `self.process` will be called correctly&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-42" data-line-number="42"&gt;        &lt;span class="co"&gt;# accross all code.  (I&amp;#39;m lookin&amp;#39; about you, `DimShufflePrinter`; get&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-43" data-line-number="43"&gt;        &lt;span class="co"&gt;# your act together.)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-44" data-line-number="44"&gt;        pstate.pprinter._pstate &lt;span class="op"&gt;=&lt;/span&gt; pstate&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-45" data-line-number="45"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-46" data-line-number="46"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; pstate&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-47" data-line-number="47"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-48" data-line-number="48"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process(&lt;span class="va"&gt;self&lt;/span&gt;, r, pstate&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-49" data-line-number="49"&gt;        pstate &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;._pstate&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-50" data-line-number="50"&gt;        &lt;span class="cf"&gt;assert&lt;/span&gt; pstate&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-51" data-line-number="51"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().process(r, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-52" data-line-number="52"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-53" data-line-number="53"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process_graph(&lt;span class="va"&gt;self&lt;/span&gt;, inputs, outputs, updates&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-54" data-line-number="54"&gt;                      display_inputs&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-55" data-line-number="55"&gt;        &lt;span class="cf"&gt;raise&lt;/span&gt; &lt;span class="va"&gt;NotImplemented&lt;/span&gt;()&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-56" data-line-number="56"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-57" data-line-number="57"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__call__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;, &lt;span class="op"&gt;*&lt;/span&gt;args, latex_env&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation&amp;#39;&lt;/span&gt;, latex_label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-58" data-line-number="58"&gt;        var &lt;span class="op"&gt;=&lt;/span&gt; args[&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-59" data-line-number="59"&gt;        pstate &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;next&lt;/span&gt;(&lt;span class="bu"&gt;iter&lt;/span&gt;(args[&lt;span class="dv"&gt;1&lt;/span&gt;:]), &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-60" data-line-number="60"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(pstate, (theano.printing.PrinterState, &lt;span class="bu"&gt;dict&lt;/span&gt;)):&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-61" data-line-number="61"&gt;            pstate &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.create_state(args[&lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-62" data-line-number="62"&gt;        &lt;span class="cf"&gt;elif&lt;/span&gt; pstate &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-63" data-line-number="63"&gt;            pstate &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.create_state(&lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-64" data-line-number="64"&gt;        &lt;span class="co"&gt;# else:&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-65" data-line-number="65"&gt;        &lt;span class="co"&gt;#     # XXX: The graph processing doesn&amp;#39;t pass around the printer state!&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-66" data-line-number="66"&gt;        &lt;span class="co"&gt;#     # &lt;/span&gt;&lt;span class="al"&gt;TODO&lt;/span&gt;&lt;span class="co"&gt;: We&amp;#39;ll have to copy the code and fix it...&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-67" data-line-number="67"&gt;        &lt;span class="co"&gt;#     raise NotImplemented(&amp;#39;No preambles for graph printing, yet.&amp;#39;)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-68" data-line-number="68"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-69" data-line-number="69"&gt;        &lt;span class="co"&gt;# This pretty printer needs more information about shapes and inputs,&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-70" data-line-number="70"&gt;        &lt;span class="co"&gt;# which it gets from a `FunctionGraph`.  Create one, if `var` isn&amp;#39;t&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-71" data-line-number="71"&gt;        &lt;span class="co"&gt;# already assigned one.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-72" data-line-number="72"&gt;        fgraph &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(var, &lt;span class="st"&gt;&amp;#39;fgraph&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-73" data-line-number="73"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; fgraph:&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-74" data-line-number="74"&gt;            fgraph &lt;span class="op"&gt;=&lt;/span&gt; tt.gof.fg.FunctionGraph(&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-75" data-line-number="75"&gt;                tt.gof.graph.inputs([var]), [var])&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-76" data-line-number="76"&gt;            var &lt;span class="op"&gt;=&lt;/span&gt; fgraph.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-77" data-line-number="77"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-78" data-line-number="78"&gt;            &lt;span class="co"&gt;# Use this to get better shape info&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-79" data-line-number="79"&gt;            shape_feature &lt;span class="op"&gt;=&lt;/span&gt; tt.opt.ShapeFeature()&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-80" data-line-number="80"&gt;            fgraph.attach_feature(shape_feature)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-81" data-line-number="81"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-82" data-line-number="82"&gt;        body_str &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__call__&lt;/span&gt;(var, pstate)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-83" data-line-number="83"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-84" data-line-number="84"&gt;        latex_out &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;latex&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-85" data-line-number="85"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; pstate.preamble_lines &lt;span class="kw"&gt;and&lt;/span&gt; latex_out:&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-86" data-line-number="86"&gt;            preamble_str &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ch"&gt;\n\\\\\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.join(pstate.preamble_lines)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-87" data-line-number="87"&gt;            preamble_str &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;begin&lt;/span&gt;&lt;span class="sc"&gt;{gathered}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;%s&lt;/span&gt;&lt;span class="ch"&gt;\n\\&lt;/span&gt;&lt;span class="st"&gt;end&lt;/span&gt;&lt;span class="sc"&gt;{gathered}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt; &lt;span class="op"&gt;%&lt;/span&gt; (preamble_str)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-88" data-line-number="88"&gt;            res &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ch"&gt;\n\\\\\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.join([preamble_str, body_str])&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-89" data-line-number="89"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-90" data-line-number="90"&gt;            res &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.join(pstate.preamble_lines &lt;span class="op"&gt;+&lt;/span&gt; [body_str])&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-91" data-line-number="91"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-92" data-line-number="92"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; latex_out &lt;span class="kw"&gt;and&lt;/span&gt; latex_env:&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-93" data-line-number="93"&gt;            label_out &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;f&amp;#39;&lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="ss"&gt;label&lt;/span&gt;&lt;span class="ch"&gt;{{&lt;/span&gt;&lt;span class="sc"&gt;{&lt;/span&gt;latex_label&lt;span class="sc"&gt;}&lt;/span&gt;&lt;span class="ss"&gt;}}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="ss"&gt;&amp;#39;&lt;/span&gt; &lt;span class="cf"&gt;if&lt;/span&gt; latex_label &lt;span class="cf"&gt;else&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-94" data-line-number="94"&gt;            res &lt;span class="op"&gt;=&lt;/span&gt; textwrap.indent(res, &lt;span class="st"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ch"&gt;\t\t&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-95" data-line-number="95"&gt;            res &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="ss"&gt;f&amp;quot;&lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="ss"&gt;begin&lt;/span&gt;&lt;span class="ch"&gt;{{&lt;/span&gt;&lt;span class="sc"&gt;{&lt;/span&gt;latex_env&lt;span class="sc"&gt;}&lt;/span&gt;&lt;span class="ss"&gt;}}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-96" data-line-number="96"&gt;                   &lt;span class="ss"&gt;f&amp;quot;&lt;/span&gt;&lt;span class="sc"&gt;{&lt;/span&gt;res&lt;span class="sc"&gt;}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-97" data-line-number="97"&gt;                   &lt;span class="ss"&gt;f&amp;quot;&lt;/span&gt;&lt;span class="sc"&gt;{&lt;/span&gt;label_out&lt;span class="sc"&gt;}&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-98" data-line-number="98"&gt;                   &lt;span class="ss"&gt;f&amp;quot;&lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="ss"&gt;end&lt;/span&gt;&lt;span class="ch"&gt;{{&lt;/span&gt;&lt;span class="sc"&gt;{&lt;/span&gt;latex_env&lt;span class="sc"&gt;}&lt;/span&gt;&lt;span class="ss"&gt;}}&amp;quot;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-99" data-line-number="99"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgccd5273-100" data-line-number="100"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; res&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orgfc82717"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgfc82717-1" data-line-number="1"&gt;tt_pprint &lt;span class="op"&gt;=&lt;/span&gt; PreamblePPrinter()&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-3" data-line-number="3"&gt;tt_pprint.assign(&lt;span class="kw"&gt;lambda&lt;/span&gt; pstate, r: &lt;span class="va"&gt;True&lt;/span&gt;, VariableWithShapePrinter)&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-4" data-line-number="4"&gt;tt_pprint.assign(UniformRV, RandomVariablePrinter(&lt;span class="st"&gt;&amp;#39;U&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-5" data-line-number="5"&gt;tt_pprint.assign(GammaRV, RandomVariablePrinter(&lt;span class="st"&gt;&amp;#39;Gamma&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-6" data-line-number="6"&gt;tt_pprint.assign(ExponentialRV, RandomVariablePrinter(&lt;span class="st"&gt;&amp;#39;Exp&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-9" data-line-number="9"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; NormalRVPrinter(RandomVariablePrinter):&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-10" data-line-number="10"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-11" data-line-number="11"&gt;        &lt;span class="bu"&gt;super&lt;/span&gt;().&lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;N&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-13" data-line-number="13"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; process_param(&lt;span class="va"&gt;self&lt;/span&gt;, idx, sform, pstate):&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-14" data-line-number="14"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; idx &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-15" data-line-number="15"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(pstate, &lt;span class="st"&gt;&amp;#39;latex&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-16" data-line-number="16"&gt;                &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="ss"&gt;f&amp;#39;&lt;/span&gt;&lt;span class="ch"&gt;{{&lt;/span&gt;&lt;span class="sc"&gt;{&lt;/span&gt;sform&lt;span class="sc"&gt;}&lt;/span&gt;&lt;span class="ss"&gt;}}^&lt;/span&gt;&lt;span class="ch"&gt;{{&lt;/span&gt;&lt;span class="ss"&gt;2}}&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-17" data-line-number="17"&gt;            &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-18" data-line-number="18"&gt;                &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="ss"&gt;f&amp;#39;&lt;/span&gt;&lt;span class="sc"&gt;{&lt;/span&gt;sform&lt;span class="sc"&gt;}&lt;/span&gt;&lt;span class="ss"&gt;**2&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-19" data-line-number="19"&gt;        &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-20" data-line-number="20"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; sform&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-22" data-line-number="22"&gt;tt_pprint.assign(NormalRV, NormalRVPrinter())&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-23" data-line-number="23"&gt;tt_pprint.assign(MvNormalRV, NormalRVPrinter())&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-24" data-line-number="24"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-25" data-line-number="25"&gt;tt_pprint.assign(DirichletRV, RandomVariablePrinter(&lt;span class="st"&gt;&amp;#39;Dir&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-26" data-line-number="26"&gt;tt_pprint.assign(PoissonRV, RandomVariablePrinter(&lt;span class="st"&gt;&amp;#39;Pois&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-27" data-line-number="27"&gt;tt_pprint.assign(CauchyRV, RandomVariablePrinter(&lt;span class="st"&gt;&amp;#39;C&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-28" data-line-number="28"&gt;tt_pprint.assign(MultinomialRV, RandomVariablePrinter(&lt;span class="st"&gt;&amp;#39;MN&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-29" data-line-number="29"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-30" data-line-number="30"&gt;tt_tex_pprint &lt;span class="op"&gt;=&lt;/span&gt; PreamblePPrinter(pstate_defaults&lt;span class="op"&gt;=&lt;/span&gt;{&lt;span class="st"&gt;&amp;#39;latex&amp;#39;&lt;/span&gt;: &lt;span class="va"&gt;True&lt;/span&gt;})&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-31" data-line-number="31"&gt;tt_tex_pprint.printers &lt;span class="op"&gt;=&lt;/span&gt; copy(tt_pprint.printers)&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-32" data-line-number="32"&gt;tt_tex_pprint.printers_dict &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;dict&lt;/span&gt;(tt_pprint.printers_dict)&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-33" data-line-number="33"&gt;tt_tex_pprint.assign(tt.mul, theano.printing.OperatorPrinter(&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;odot&amp;#39;&lt;/span&gt;, &lt;span class="dv"&gt;-1&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;either&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-34" data-line-number="34"&gt;tt_tex_pprint.assign(tt.true_div, theano.printing.PatternPrinter((&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;&lt;span class="ch"&gt;\\&lt;/span&gt;&lt;span class="st"&gt;frac{&lt;/span&gt;&lt;span class="sc"&gt;%(0)s&lt;/span&gt;&lt;span class="st"&gt;}{&lt;/span&gt;&lt;span class="sc"&gt;%(1)s&lt;/span&gt;&lt;span class="st"&gt;}&amp;#39;&lt;/span&gt;, &lt;span class="dv"&gt;-1000&lt;/span&gt;)))&lt;/a&gt;
&lt;a class="sourceLine" id="orgfc82717-35" data-line-number="35"&gt;tt_tex_pprint.assign(tt.&lt;span class="bu"&gt;pow&lt;/span&gt;, theano.printing.PatternPrinter((&lt;span class="st"&gt;&amp;#39;{&lt;/span&gt;&lt;span class="sc"&gt;%(0)s&lt;/span&gt;&lt;span class="st"&gt;}^{&lt;/span&gt;&lt;span class="sc"&gt;%(1)s&lt;/span&gt;&lt;span class="st"&gt;}&amp;#39;&lt;/span&gt;, &lt;span class="dv"&gt;-1000&lt;/span&gt;)))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;Listing &lt;a href="#org1ed4a46"&gt;35&lt;/a&gt;, creates a graph with two random variables and prints the results with the default Theano pretty printer as Equation &lt;span class="math inline"&gt;\(\eqref{eq:rv-pprinter-exa}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="org0e19f4e"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org0e19f4e-1" data-line-number="1"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0e19f4e-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0e19f4e-3" data-line-number="3"&gt;tt.config.compute_test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0e19f4e-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0e19f4e-5" data-line-number="5"&gt;Z_tt &lt;span class="op"&gt;=&lt;/span&gt; UniformRV(tt.scalar(&lt;span class="st"&gt;&amp;#39;l_0&amp;#39;&lt;/span&gt;), tt.scalar(&lt;span class="st"&gt;&amp;#39;l_1&amp;#39;&lt;/span&gt;), name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;Z&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org0e19f4e-6" data-line-number="6"&gt;X_tt &lt;span class="op"&gt;=&lt;/span&gt; NormalRV(Z_tt, tt.scalar(&lt;span class="st"&gt;&amp;#39;\sigma_1&amp;#39;&lt;/span&gt;), name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org0e19f4e-7" data-line-number="7"&gt;Y_tt &lt;span class="op"&gt;=&lt;/span&gt; MvNormalRV(tt.vector(&lt;span class="st"&gt;&amp;#39;\mu&amp;#39;&lt;/span&gt;), tt.abs_(X_tt) &lt;span class="op"&gt;*&lt;/span&gt; tt.constant(np.diag([&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;])), name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org0e19f4e-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0e19f4e-9" data-line-number="9"&gt;W_tt &lt;span class="op"&gt;=&lt;/span&gt; X_tt &lt;span class="op"&gt;*&lt;/span&gt; (tt.scalar(&lt;span class="st"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;) &lt;span class="op"&gt;*&lt;/span&gt; Y_tt &lt;span class="op"&gt;+&lt;/span&gt; tt.scalar(&lt;span class="st"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org1ed4a46"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org1ed4a46-1" data-line-number="1"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(tt_tex_pprint(W_tt, latex_label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;eq:rv-pprinter-exa&amp;#39;&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation}
        \begin{gathered}
        l_0 \in \mathbb{R}
        \\
        l_1 \in \mathbb{R}
        \\
        Z \sim \operatorname{U}\left(l_0, l_1\right), \quad Z \in \mathbb{R}
        \\
        \sigma_1 \in \mathbb{R}
        \\
        X \sim \operatorname{N}\left(Z, {\sigma_1}^{2}\right), \quad X \in \mathbb{R}
        \\
        b \in \mathbb{R}
        \\
        \mu \in \mathbb{R}^{{n^{\mu}}_{0}}
        \\
        Y \sim \operatorname{N}\left(\mu, {(|X| \odot \left[\begin{matrix}1 &amp;amp; 0\\0 &amp;amp; 2\end{matrix}\right])}^{2}\right), \quad Y \in \mathbb{R}^{{n^{Y}}_{0}}
        \\
        c \in \mathbb{R}
        \end{gathered}
        \\
        (X \odot ((b \odot Y) + c))
\label{eq:rv-pprinter-exa}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="algebraic-manipulations" class="level1"&gt;
&lt;h1&gt;Algebraic Manipulations&lt;/h1&gt;
&lt;p&gt;With our new &lt;code&gt;RandomVariable&lt;/code&gt;, we can alter the replacement patterns used by &lt;code&gt;tt.gof.opt.PatternSub&lt;/code&gt; in &lt;a href="#24875a2c31fa7f94ce562adddedc0bf8"&gt;Willard, Brandon T. (2018)&lt;/a&gt; and implement a slightly better parameter lifting for affine transforms of scalar normal random variables in Listing &lt;a href="#orgc483b75"&gt;36&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="orgc483b75"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgc483b75-1" data-line-number="1"&gt;norm_lift_pats &lt;span class="op"&gt;=&lt;/span&gt; [&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-2" data-line-number="2"&gt;    &lt;span class="co"&gt;# Lift element-wise multiplication&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-3" data-line-number="3"&gt;    tt.gof.opt.PatternSub(&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-4" data-line-number="4"&gt;        (tt.mul,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-5" data-line-number="5"&gt;         &lt;span class="st"&gt;&amp;#39;a_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-6" data-line-number="6"&gt;         (NormalRV, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;sd_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;size_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;)),&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-7" data-line-number="7"&gt;        (NormalRV,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-8" data-line-number="8"&gt;         (tt.mul, &lt;span class="st"&gt;&amp;#39;a_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-9" data-line-number="9"&gt;         (tt.mul, &lt;span class="st"&gt;&amp;#39;a_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;sd_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-10" data-line-number="10"&gt;         &lt;span class="st"&gt;&amp;#39;size_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-11" data-line-number="11"&gt;         &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-12" data-line-number="12"&gt;        )),&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-13" data-line-number="13"&gt;    &lt;span class="co"&gt;# Lift element-wise addition&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-14" data-line-number="14"&gt;    tt.gof.opt.PatternSub(&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-15" data-line-number="15"&gt;        (tt.add,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-16" data-line-number="16"&gt;         (NormalRV, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;sd_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;size_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-17" data-line-number="17"&gt;         &lt;span class="st"&gt;&amp;#39;b_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-18" data-line-number="18"&gt;        (NormalRV,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-19" data-line-number="19"&gt;         (tt.add, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;b_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-20" data-line-number="20"&gt;         &lt;span class="st"&gt;&amp;#39;sd_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-21" data-line-number="21"&gt;         &lt;span class="st"&gt;&amp;#39;size_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-22" data-line-number="22"&gt;         &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-23" data-line-number="23"&gt;        )),&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-24" data-line-number="24"&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-25" data-line-number="25"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-26" data-line-number="26"&gt;norm_lift_opts &lt;span class="op"&gt;=&lt;/span&gt; tt.gof.opt.EquilibriumOptimizer(&lt;/a&gt;
&lt;a class="sourceLine" id="orgc483b75-27" data-line-number="27"&gt;    norm_lift_pats, max_use_ratio&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;div class="sourceCode" id="orgc69f52b"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgc69f52b-1" data-line-number="1"&gt;&lt;span class="co"&gt;# [[file:~/projects/websites/brandonwillard.github.io/content/articles/src/org/symbolic-math-in-pymc3-new-op.org::graph-manipulation-setup][graph-manipulation-setup]]&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano.gof &lt;span class="im"&gt;import&lt;/span&gt; FunctionGraph, Feature, NodeFinder&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-3" data-line-number="3"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano.gof.graph &lt;span class="im"&gt;import&lt;/span&gt; inputs &lt;span class="im"&gt;as&lt;/span&gt; tt_inputs, clone_get_equiv&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-5" data-line-number="5"&gt;theano.config.compute_test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;ignore&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-6" data-line-number="6"&gt;&lt;span class="co"&gt;# graph-manipulation-setup ends here&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-8" data-line-number="8"&gt;mu_X &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;\mu&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-9" data-line-number="9"&gt;sd_X &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;\sigma&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-11" data-line-number="11"&gt;a_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.fscalar(&lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-12" data-line-number="12"&gt;b_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.fscalar(&lt;span class="st"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-14" data-line-number="14"&gt;X_rv &lt;span class="op"&gt;=&lt;/span&gt; NormalRV(mu_X, sd_X, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-15" data-line-number="15"&gt;trans_X_rv &lt;span class="op"&gt;=&lt;/span&gt; a_tt &lt;span class="op"&gt;*&lt;/span&gt; X_rv &lt;span class="op"&gt;+&lt;/span&gt; b_tt&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-17" data-line-number="17"&gt;trans_X_graph &lt;span class="op"&gt;=&lt;/span&gt; FunctionGraph(tt_inputs([trans_X_rv]), [trans_X_rv])&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-19" data-line-number="19"&gt;&lt;span class="co"&gt;# Create a copy and optimize that&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-20" data-line-number="20"&gt;trans_X_graph_opt &lt;span class="op"&gt;=&lt;/span&gt; trans_X_graph.clone()&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgc69f52b-22" data-line-number="22"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; norm_lift_opts.optimize(trans_X_graph_opt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org2bd1258"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org2bd1258-1" data-line-number="1"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(tt_tex_pprint(trans_X_graph.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;], latex_env&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Before applying the optimization:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
        \begin{gathered}
        a \in \mathbb{R}
        \\
        \mu \in \mathbb{R}^{{n^{\mu}}_{0}}
        \\
        \sigma \in \mathbb{R}^{{n^{\sigma}}_{0}}
        \\
        X \sim \operatorname{N}\left(\mu, {\sigma}^{2}\right), \quad X \in \mathbb{R}^{{n^{X}}_{0}}
        \\
        b \in \mathbb{R}
        \end{gathered}
        \\
        ((a \odot X) + b)
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;div class="sourceCode" id="orge71b0ac"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orge71b0ac-1" data-line-number="1"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(tt_tex_pprint(trans_X_graph_opt.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;], latex_env&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After applying the optimization:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
        \begin{gathered}
        a \in \mathbb{R}
        \\
        \mu \in \mathbb{R}^{{n^{\mu}}_{0}}
        \\
        b \in \mathbb{R}
        \\
        \sigma \in \mathbb{R}^{{n^{\sigma}}_{0}}
        \\
        c \sim \operatorname{N}\left(((a \odot \mu) + b), {(a \odot \sigma)}^{2}\right), \quad c \in \mathbb{R}^{{n^{c}}_{0}}
        \end{gathered}
        \\
        c
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now, what if we wanted to handle affine transformations of a multivariate normal random variable? Specifically, consider the following:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
  X \sim N\left(\mu, \Sigma \right), \quad
  A X \sim N\left(A \mu, A \Sigma A^\top \right)
 \;.
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;At first, the substitution pattern in Listing &lt;a href="#org4a792de"&gt;40&lt;/a&gt; might seem reasonable.&lt;/p&gt;
&lt;div class="sourceCode" id="org4a792de"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org4a792de-1" data-line-number="1"&gt;&lt;span class="co"&gt;# Vector multiplication&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-2" data-line-number="2"&gt;tt.gof.opt.PatternSub(&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-3" data-line-number="3"&gt;    (tt.dot, &lt;span class="st"&gt;&amp;#39;A_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-4" data-line-number="4"&gt;     (MvNormalRV, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;cov_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;size_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;)),&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-5" data-line-number="5"&gt;    (MvNormalRV,&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-6" data-line-number="6"&gt;     (tt.dot, &lt;span class="st"&gt;&amp;#39;A_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-7" data-line-number="7"&gt;     (tt.dot,&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-8" data-line-number="8"&gt;      (tt.dot, &lt;span class="st"&gt;&amp;#39;A_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;cov_x&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-9" data-line-number="9"&gt;      (tt.transpose, &lt;span class="st"&gt;&amp;#39;A_x&amp;#39;&lt;/span&gt;)),&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-10" data-line-number="10"&gt;     &lt;span class="st"&gt;&amp;#39;size_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-11" data-line-number="11"&gt;     &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org4a792de-12" data-line-number="12"&gt;    ))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Unfortunately, the combination of size parameter and broadcasting complicates the scenario. Both parameters indirectly affect the distribution parameters, making the un-lifted dot-product consistent, but not necessarily the lifted products.&lt;/p&gt;
&lt;p&gt;The following example demonstrates the lifting issues brought on by broadcasting.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;We create a simple multivariate normal in Listing &lt;a href="#org7446c7b"&gt;41&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="org7446c7b"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org7446c7b-1" data-line-number="1"&gt;mu_X &lt;span class="op"&gt;=&lt;/span&gt; [&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;10&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org7446c7b-2" data-line-number="2"&gt;cov_X &lt;span class="op"&gt;=&lt;/span&gt; np.diag([&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="fl"&gt;1e-2&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="org7446c7b-3" data-line-number="3"&gt;size_X_rv &lt;span class="op"&gt;=&lt;/span&gt; [&lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org7446c7b-4" data-line-number="4"&gt;X_rv &lt;span class="op"&gt;=&lt;/span&gt; MvNormalRV(mu_X, cov_X, size&lt;span class="op"&gt;=&lt;/span&gt;size_X_rv)&lt;/a&gt;
&lt;a class="sourceLine" id="org7446c7b-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org7446c7b-6" data-line-number="6"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt; ~ X_rv&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(X_rv.tag.test_value))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org9e35ff4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org9e35ff4-1" data-line-number="1"&gt;[[[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;0.68284424&lt;/span&gt;  &lt;span class="fl"&gt;9.95587926&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org9e35ff4-2" data-line-number="2"&gt;  [ &lt;span class="fl"&gt;1.66236785&lt;/span&gt;  &lt;span class="fl"&gt;9.87590909&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org9e35ff4-3" data-line-number="3"&gt;  [ &lt;span class="fl"&gt;0.23449772&lt;/span&gt; &lt;span class="fl"&gt;10.12455681&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="org9e35ff4-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9e35ff4-5" data-line-number="5"&gt; [[ &lt;span class="fl"&gt;0.3342739&lt;/span&gt;  &lt;span class="fl"&gt;10.05580428&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org9e35ff4-6" data-line-number="6"&gt;  [&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;0.18913408&lt;/span&gt; &lt;span class="fl"&gt;10.0359336&lt;/span&gt; ]&lt;/a&gt;
&lt;a class="sourceLine" id="org9e35ff4-7" data-line-number="7"&gt;  [&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;1.2463576&lt;/span&gt;   &lt;span class="fl"&gt;9.90671218&lt;/span&gt;]]] &lt;span class="op"&gt;~&lt;/span&gt; X_rv&lt;/a&gt;
&lt;a class="sourceLine" id="org9e35ff4-8" data-line-number="8"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, we create a simple matrix operator to apply to the multivariate normal.&lt;/p&gt;
&lt;div class="sourceCode" id="org0f84661"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org0f84661-1" data-line-number="1"&gt;A_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.as_tensor_variable([[&lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;5&lt;/span&gt;, &lt;span class="dv"&gt;8&lt;/span&gt;], [&lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;4&lt;/span&gt;, &lt;span class="dv"&gt;9&lt;/span&gt;]])&lt;/a&gt;
&lt;a class="sourceLine" id="org0f84661-2" data-line-number="2"&gt;&lt;span class="co"&gt;# or A_tt = tt.as_tensor_variable([[2, 5, 8]])&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0f84661-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0f84661-4" data-line-number="4"&gt;&lt;span class="co"&gt;# It&amp;#39;s really just `mu_X`...&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0f84661-5" data-line-number="5"&gt;E_X_rv &lt;span class="op"&gt;=&lt;/span&gt; X_rv.owner.inputs[&lt;span class="dv"&gt;2&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org0f84661-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org0f84661-7" data-line-number="7"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;A * X_rv =&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(tt.dot(A_tt, X_rv).tag.test_value))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org05ebd11"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org05ebd11-1" data-line-number="1"&gt;A &lt;span class="op"&gt;*&lt;/span&gt; X_rv &lt;span class="op"&gt;=&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org05ebd11-2" data-line-number="2"&gt;[[[  &lt;span class="fl"&gt;1.18524621&lt;/span&gt; &lt;span class="fl"&gt;150.31045062&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org05ebd11-3" data-line-number="3"&gt;  [  &lt;span class="fl"&gt;1.07000851&lt;/span&gt; &lt;span class="fl"&gt;150.65771936&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="org05ebd11-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org05ebd11-5" data-line-number="5"&gt; [[  &lt;span class="fl"&gt;1.31685497&lt;/span&gt; &lt;span class="fl"&gt;160.33572146&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org05ebd11-6" data-line-number="6"&gt;  [  &lt;span class="fl"&gt;0.33506491&lt;/span&gt; &lt;span class="fl"&gt;160.82202495&lt;/span&gt;]]]&lt;/a&gt;
&lt;a class="sourceLine" id="org05ebd11-7" data-line-number="7"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As we can see, the multivariate normal’s test/sampled value has the correct shape for our matrix operator.&lt;/p&gt;
&lt;div class="sourceCode" id="orgd95a139"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgd95a139-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; traceback&lt;/a&gt;
&lt;a class="sourceLine" id="orgd95a139-2" data-line-number="2"&gt;&lt;span class="cf"&gt;try&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgd95a139-3" data-line-number="3"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;A * E[X_rv] =&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(tt.dot(A_tt, E_X_rv).tag.test_value))&lt;/a&gt;
&lt;a class="sourceLine" id="orgd95a139-4" data-line-number="4"&gt;&lt;span class="cf"&gt;except&lt;/span&gt; &lt;span class="pp"&gt;ValueError&lt;/span&gt; &lt;span class="im"&gt;as&lt;/span&gt; e:&lt;/a&gt;
&lt;a class="sourceLine" id="orgd95a139-5" data-line-number="5"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;&amp;quot;&lt;/span&gt;.join(traceback.format_exception_only(&lt;span class="bu"&gt;type&lt;/span&gt;(e), e)))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org51f4e3a"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org51f4e3a-1" data-line-number="1"&gt;&lt;span class="pp"&gt;ValueError&lt;/span&gt;: shapes (&lt;span class="dv"&gt;2&lt;/span&gt;,&lt;span class="dv"&gt;3&lt;/span&gt;) &lt;span class="kw"&gt;and&lt;/span&gt; (&lt;span class="dv"&gt;2&lt;/span&gt;,) &lt;span class="kw"&gt;not&lt;/span&gt; aligned: &lt;span class="dv"&gt;3&lt;/span&gt; (dim &lt;span class="dv"&gt;1&lt;/span&gt;) &lt;span class="op"&gt;!=&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; (dim &lt;span class="dv"&gt;0&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org51f4e3a-2" data-line-number="2"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, we see that the multivariate normal’s inputs (i.e. the &lt;code&gt;Op&lt;/code&gt; inputs)–specifically the mean parameter–do not directly reflect the support’s shape, as one might expect.&lt;/p&gt;
&lt;div class="sourceCode" id="org6e32649"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org6e32649-1" data-line-number="1"&gt;size_tile &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;tuple&lt;/span&gt;(size_X_rv) &lt;span class="op"&gt;+&lt;/span&gt; (&lt;span class="dv"&gt;1&lt;/span&gt;,)&lt;/a&gt;
&lt;a class="sourceLine" id="org6e32649-2" data-line-number="2"&gt;E_X_rv_ &lt;span class="op"&gt;=&lt;/span&gt; tt.tile(E_X_rv, size_tile, X_rv.ndim)&lt;/a&gt;
&lt;a class="sourceLine" id="org6e32649-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org6e32649-4" data-line-number="4"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;A * E[X_rv] =&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(tt.dot(A_tt, E_X_rv_).tag.test_value))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org7f64727"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org7f64727-1" data-line-number="1"&gt;A &lt;span class="op"&gt;*&lt;/span&gt; E[X_rv] &lt;span class="op"&gt;=&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org7f64727-2" data-line-number="2"&gt;[[[  &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;150&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org7f64727-3" data-line-number="3"&gt;  [  &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;150&lt;/span&gt;]]&lt;/a&gt;
&lt;a class="sourceLine" id="org7f64727-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org7f64727-5" data-line-number="5"&gt; [[  &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;160&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="org7f64727-6" data-line-number="6"&gt;  [  &lt;span class="dv"&gt;0&lt;/span&gt; &lt;span class="dv"&gt;160&lt;/span&gt;]]]&lt;/a&gt;
&lt;a class="sourceLine" id="org7f64727-7" data-line-number="7"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can manually replicate the inputs so that they match the output shape, but a solution to the general problem requires a more organized response.&lt;/p&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section id="a-problem-with-conversion-from-pymc3" class="level1"&gt;
&lt;h1&gt;A Problem with Conversion from PyMC3&lt;/h1&gt;
&lt;p&gt;As in &lt;a href="#24875a2c31fa7f94ce562adddedc0bf8"&gt;Willard, Brandon T. (2018)&lt;/a&gt;, we can create mappings between existing PyMC3 random variables and their new &lt;code&gt;RandomVariable&lt;/code&gt; equivalents.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;div class="sourceCode" id="org8bffc80"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org8bffc80-1" data-line-number="1"&gt;pymc_theano_rv_equivs &lt;span class="op"&gt;=&lt;/span&gt; {&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-2" data-line-number="2"&gt;    pm.Normal:&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-3" data-line-number="3"&gt;    &lt;span class="kw"&gt;lambda&lt;/span&gt; dist, rand_state:&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-4" data-line-number="4"&gt;    (&lt;span class="va"&gt;None&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-5" data-line-number="5"&gt;     &lt;span class="co"&gt;# PyMC3 shapes aren&amp;#39;t NumPy-like size parameters, so we attempt to&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-6" data-line-number="6"&gt;     &lt;span class="co"&gt;# adjust for that.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-7" data-line-number="7"&gt;     NormalRV(dist.mu, dist.sd, size&lt;span class="op"&gt;=&lt;/span&gt;dist.shape[&lt;span class="dv"&gt;1&lt;/span&gt;:], rng&lt;span class="op"&gt;=&lt;/span&gt;rand_state)),&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-8" data-line-number="8"&gt;    pm.MvNormal:&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-9" data-line-number="9"&gt;    &lt;span class="kw"&gt;lambda&lt;/span&gt; dist, rand_state:&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-10" data-line-number="10"&gt;    (&lt;span class="va"&gt;None&lt;/span&gt;, NormalRV(dist.mu, dist.cov, size&lt;span class="op"&gt;=&lt;/span&gt;dist.shape[&lt;span class="dv"&gt;1&lt;/span&gt;:], rng&lt;span class="op"&gt;=&lt;/span&gt;rand_state)),&lt;/a&gt;
&lt;a class="sourceLine" id="org8bffc80-11" data-line-number="11"&gt;}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;However, if we attempt the same PymC3 graph conversion approach as before (i.e. convert a PyMC3 model to a Theano &lt;code&gt;FunctionGraph&lt;/code&gt; using &lt;code&gt;model_graph&lt;/code&gt;, then replace PyMC3 random variable nodes with our new random variable types using &lt;code&gt;create_theano_rvs&lt;/code&gt;), we’re likely to run into a problem involving mismatching broadcastable dimensions.&lt;/p&gt;
&lt;p&gt;The problem arises because &lt;strong&gt;PyMC3 “knows” more broadcast information than it should&lt;/strong&gt;, since it uses the Theano variables’ test values in order to obtain concrete shapes for the random variables it creates. Using concrete, non-symbolic shapes, it can exactly determine what would otherwise be ambiguous &lt;a href="http://deeplearning.net/software/theano/library/tensor/basic.html?highlight=broadcastable#theano.tensor.TensorType.broadcastable"&gt;broadcastable dimensions&lt;/a&gt; at the symbolic level.&lt;/p&gt;
&lt;p&gt;More specifically, broadcast information is required during the construction of a Theano &lt;code&gt;TensorType&lt;/code&gt;, so PyMC3 random variable types can be inconsistent (unnecessarily restrictive, really) causing Theano to complain when we try to construct a &lt;code&gt;FunctionGraph&lt;/code&gt;.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;Consider the following example; it constructs two purely symbolic Theano vectors: one with broadcasting and one without.&lt;/p&gt;
&lt;div class="sourceCode" id="orgbd54927"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgbd54927-1" data-line-number="1"&gt;y_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.row(&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgbd54927-2" data-line-number="2"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;y_tt.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(y_tt.broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="orgbd54927-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgbd54927-4" data-line-number="4"&gt;x_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.matrix(&lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orgbd54927-5" data-line-number="5"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;x_tt.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(x_tt.broadcastable))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orga8f9d4c"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orga8f9d4c-1" data-line-number="1"&gt;y_tt.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;True&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orga8f9d4c-2" data-line-number="2"&gt;x_tt.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;False&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orga8f9d4c-3" data-line-number="3"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that it–by default–signifies no broadcasting on its first and only dimension.&lt;/p&gt;
&lt;p&gt;If we wish–or if &lt;a href="http://deeplearning.net/software/theano/library/config.html#config.compute_test_value"&gt;Theano’s configuration demands&lt;/a&gt; it–we can assign the symbolic vector arbitrary test values, as long as they’re consistent with its type (i.e. a vector, or 1-dimensional array).&lt;/p&gt;
&lt;p&gt;In the following, we assign both a broadcastable (i.e. first–and only–dimension has size 1) and non-broadcastable test value.&lt;/p&gt;
&lt;p&gt;Test value is broadcastable:&lt;/p&gt;
&lt;div class="sourceCode" id="orgaadc727"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgaadc727-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; contextlib &lt;span class="im"&gt;import&lt;/span&gt; contextmanager&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-4" data-line-number="4"&gt;x_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([[&lt;span class="dv"&gt;5&lt;/span&gt;]])&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-6" data-line-number="6"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;test_value.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-7" data-line-number="7"&gt;    tt.as_tensor_variable(x_tt.tag.test_value).broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-8" data-line-number="8"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;x_tt.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(x_tt.broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-10" data-line-number="10"&gt;&lt;span class="at"&gt;@contextmanager&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-11" data-line-number="11"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; short_exception_msg(exc_type):&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-12" data-line-number="12"&gt;    _verbosity &lt;span class="op"&gt;=&lt;/span&gt; theano.config.exception_verbosity&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-13" data-line-number="13"&gt;    theano.config.exception_verbosity &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;low&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-14" data-line-number="14"&gt;    &lt;span class="cf"&gt;try&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-15" data-line-number="15"&gt;        &lt;span class="cf"&gt;yield&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-16" data-line-number="16"&gt;    &lt;span class="cf"&gt;except&lt;/span&gt; exc_type &lt;span class="im"&gt;as&lt;/span&gt; e:&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-17" data-line-number="17"&gt;        &lt;span class="im"&gt;import&lt;/span&gt; traceback&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-18" data-line-number="18"&gt;        &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;&amp;quot;&lt;/span&gt;.join(traceback.format_exception_only(&lt;span class="bu"&gt;type&lt;/span&gt;(e), e)))&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-19" data-line-number="19"&gt;    &lt;span class="cf"&gt;finally&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-20" data-line-number="20"&gt;        theano.config.exception_verbosity &lt;span class="op"&gt;=&lt;/span&gt; _verbosity&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-22" data-line-number="22"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-23" data-line-number="23"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; short_exception_msg(&lt;span class="pp"&gt;TypeError&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-24" data-line-number="24"&gt;    x_tt.shape&lt;/a&gt;
&lt;a class="sourceLine" id="orgaadc727-25" data-line-number="25"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;shape checks out!&amp;quot;&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org9c02ec5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org9c02ec5-1" data-line-number="1"&gt;test_value.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;True&lt;/span&gt;, &lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org9c02ec5-2" data-line-number="2"&gt;x_tt.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;False&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org9c02ec5-3" data-line-number="3"&gt;shape checks out&lt;span class="op"&gt;!&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org9c02ec5-4" data-line-number="4"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org56323a0"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org56323a0-1" data-line-number="1"&gt;y_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([[&lt;span class="dv"&gt;5&lt;/span&gt;]])&lt;/a&gt;
&lt;a class="sourceLine" id="org56323a0-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org56323a0-3" data-line-number="3"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;test_value.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="org56323a0-4" data-line-number="4"&gt;    tt.as_tensor_variable(y_tt.tag.test_value).broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="org56323a0-5" data-line-number="5"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;y_tt.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(y_tt.broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="org56323a0-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org56323a0-7" data-line-number="7"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; short_exception_msg(&lt;span class="pp"&gt;TypeError&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org56323a0-8" data-line-number="8"&gt;    y_tt.shape&lt;/a&gt;
&lt;a class="sourceLine" id="org56323a0-9" data-line-number="9"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;shape checks out!&amp;quot;&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="orga78b1b0"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orga78b1b0-1" data-line-number="1"&gt;test_value.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;True&lt;/span&gt;, &lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orga78b1b0-2" data-line-number="2"&gt;y_tt.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;True&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="orga78b1b0-3" data-line-number="3"&gt;shape checks out&lt;span class="op"&gt;!&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orga78b1b0-4" data-line-number="4"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Test value is &lt;strong&gt;not&lt;/strong&gt; broadcastable:&lt;/p&gt;
&lt;div class="sourceCode" id="orge2d0568"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orge2d0568-1" data-line-number="1"&gt;x_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([[&lt;span class="dv"&gt;5&lt;/span&gt;, &lt;span class="dv"&gt;4&lt;/span&gt;]])&lt;/a&gt;
&lt;a class="sourceLine" id="orge2d0568-2" data-line-number="2"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;test_value.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="orge2d0568-3" data-line-number="3"&gt;    tt.as_tensor_variable(x_tt.tag.test_value).broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="orge2d0568-4" data-line-number="4"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;x_tt.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(x_tt.broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="orge2d0568-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="orge2d0568-6" data-line-number="6"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; short_exception_msg(&lt;span class="pp"&gt;TypeError&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="orge2d0568-7" data-line-number="7"&gt;    x_tt.shape&lt;/a&gt;
&lt;a class="sourceLine" id="orge2d0568-8" data-line-number="8"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;shape checks out!&amp;quot;&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org3ac23d5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org3ac23d5-1" data-line-number="1"&gt;test_value.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;True&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org3ac23d5-2" data-line-number="2"&gt;x_tt.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;False&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org3ac23d5-3" data-line-number="3"&gt;shape checks out&lt;span class="op"&gt;!&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org3ac23d5-4" data-line-number="4"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org53e07ae"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org53e07ae-1" data-line-number="1"&gt;y_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([[&lt;span class="dv"&gt;5&lt;/span&gt;, &lt;span class="dv"&gt;4&lt;/span&gt;], [&lt;span class="dv"&gt;3&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;]])&lt;/a&gt;
&lt;a class="sourceLine" id="org53e07ae-2" data-line-number="2"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;test_value.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="org53e07ae-3" data-line-number="3"&gt;    tt.as_tensor_variable(y_tt.tag.test_value).broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="org53e07ae-4" data-line-number="4"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;y_tt.broadcastable = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;quot;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(y_tt.broadcastable))&lt;/a&gt;
&lt;a class="sourceLine" id="org53e07ae-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org53e07ae-6" data-line-number="6"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; short_exception_msg(&lt;span class="pp"&gt;TypeError&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="org53e07ae-7" data-line-number="7"&gt;    y_tt.shape&lt;/a&gt;
&lt;a class="sourceLine" id="org53e07ae-8" data-line-number="8"&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;quot;shape checks out!&amp;quot;&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org60e8d8f"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org60e8d8f-1" data-line-number="1"&gt;test_value.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;False&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-2" data-line-number="2"&gt;y_tt.broadcastable &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="va"&gt;True&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-3" data-line-number="3"&gt;&lt;span class="pp"&gt;TypeError&lt;/span&gt;: For compute_test_value, one &lt;span class="bu"&gt;input&lt;/span&gt; test value does &lt;span class="kw"&gt;not&lt;/span&gt; have the requested &lt;span class="bu"&gt;type&lt;/span&gt;.&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-5" data-line-number="5"&gt;Backtrace when that variable &lt;span class="kw"&gt;is&lt;/span&gt; created:&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-7" data-line-number="7"&gt;  File &lt;span class="st"&gt;&amp;quot;/home/bwillard/apps/anaconda3/envs/github-website/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py&amp;quot;&lt;/span&gt;, line &lt;span class="dv"&gt;485&lt;/span&gt;, &lt;span class="kw"&gt;in&lt;/span&gt; mainloop&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-8" data-line-number="8"&gt;    &lt;span class="va"&gt;self&lt;/span&gt;.interact()&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-9" data-line-number="9"&gt;  File &lt;span class="st"&gt;&amp;quot;/home/bwillard/apps/anaconda3/envs/github-website/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py&amp;quot;&lt;/span&gt;, line &lt;span class="dv"&gt;476&lt;/span&gt;, &lt;span class="kw"&gt;in&lt;/span&gt; interact&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-10" data-line-number="10"&gt;    &lt;span class="va"&gt;self&lt;/span&gt;.run_cell(code, store_history&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-11" data-line-number="11"&gt;  File &lt;span class="st"&gt;&amp;quot;/home/bwillard/apps/anaconda3/envs/github-website/lib/python3.6/site-packages/IPython/core/interactiveshell.py&amp;quot;&lt;/span&gt;, line &lt;span class="dv"&gt;2662&lt;/span&gt;, &lt;span class="kw"&gt;in&lt;/span&gt; run_cell&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-12" data-line-number="12"&gt;    raw_cell, store_history, silent, shell_futures)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-13" data-line-number="13"&gt;  File &lt;span class="st"&gt;&amp;quot;/home/bwillard/apps/anaconda3/envs/github-website/lib/python3.6/site-packages/IPython/core/interactiveshell.py&amp;quot;&lt;/span&gt;, line &lt;span class="dv"&gt;2785&lt;/span&gt;, &lt;span class="kw"&gt;in&lt;/span&gt; _run_cell&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-14" data-line-number="14"&gt;    interactivity&lt;span class="op"&gt;=&lt;/span&gt;interactivity, compiler&lt;span class="op"&gt;=&lt;/span&gt;compiler, result&lt;span class="op"&gt;=&lt;/span&gt;result)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-15" data-line-number="15"&gt;  File &lt;span class="st"&gt;&amp;quot;/home/bwillard/apps/anaconda3/envs/github-website/lib/python3.6/site-packages/IPython/core/interactiveshell.py&amp;quot;&lt;/span&gt;, line &lt;span class="dv"&gt;2909&lt;/span&gt;, &lt;span class="kw"&gt;in&lt;/span&gt; run_ast_nodes&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-16" data-line-number="16"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.run_code(code, result):&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-17" data-line-number="17"&gt;  File &lt;span class="st"&gt;&amp;quot;/home/bwillard/apps/anaconda3/envs/github-website/lib/python3.6/site-packages/IPython/core/interactiveshell.py&amp;quot;&lt;/span&gt;, line &lt;span class="dv"&gt;2963&lt;/span&gt;, &lt;span class="kw"&gt;in&lt;/span&gt; run_code&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-18" data-line-number="18"&gt;    &lt;span class="bu"&gt;exec&lt;/span&gt;(code_obj, &lt;span class="va"&gt;self&lt;/span&gt;.user_global_ns, &lt;span class="va"&gt;self&lt;/span&gt;.user_ns)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-19" data-line-number="19"&gt;  File &lt;span class="st"&gt;&amp;quot;&amp;lt;ipython-input-19-7427b1688530&amp;gt;&amp;quot;&lt;/span&gt;, line &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;module&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-20" data-line-number="20"&gt;    __org_babel_python_fname &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;/tmp/user/1000/babel-fsZXPU/python-cZypXi&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;;&lt;/span&gt; __org_babel_python_fh &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;open&lt;/span&gt;(__org_babel_python_fname)&lt;span class="op"&gt;;&lt;/span&gt; &lt;span class="bu"&gt;exec&lt;/span&gt;(&lt;span class="bu"&gt;compile&lt;/span&gt;(__org_babel_python_fh.read(), __org_babel_python_fname, &lt;span class="st"&gt;&amp;#39;exec&amp;#39;&lt;/span&gt;))&lt;span class="op"&gt;;&lt;/span&gt; __org_babel_python_fh.close()&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-21" data-line-number="21"&gt;  File &lt;span class="st"&gt;&amp;quot;/tmp/user/1000/babel-fsZXPU/python-cZypXi&amp;quot;&lt;/span&gt;, line &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;module&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-22" data-line-number="22"&gt;    y_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.row(&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-23" data-line-number="23"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-24" data-line-number="24"&gt;The error when converting the test value to that variable &lt;span class="bu"&gt;type&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-25" data-line-number="25"&gt;Non&lt;span class="op"&gt;-&lt;/span&gt;unit value on shape on a broadcastable dimension.&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-26" data-line-number="26"&gt;(&lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-27" data-line-number="27"&gt;(&lt;span class="va"&gt;True&lt;/span&gt;, &lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="org60e8d8f-28" data-line-number="28"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Simply put: non-broadcastable Theano tensor variable types can take broadcastable and non-broadcastable values, while broadcastable types can only take broadcastable values.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;What we can take from the example above is that if we determine that a vector has broadcastable dimensions using test values–as PyMC3 does–we unnecessarily introduce restrictions and potential inconsistencies down the line. One point of origin for such issues is &lt;strong&gt;shared variables&lt;/strong&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="discussion" class="level1"&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;In follow-ups to this series, we’ll address a few loose ends, such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the inclusion of density functions and likelihoods,&lt;/li&gt;
&lt;li&gt;decompositions/reductions of overlapping multivariate types (e.g. transforms between tensors of univariate normals and equivalent multivariate normals),&lt;/li&gt;
&lt;li&gt;canonicalization of graphs containing &lt;code&gt;RandomVariable&lt;/code&gt; terms,&lt;/li&gt;
&lt;li&gt;and more optimizations that specifically target MCMC schemes (e.g. automatic conversion to scale mixture decompositions).&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content><category term="pymc3"></category><category term="theano"></category><category term="statistics"></category><category term="symbolic computation"></category><category term="python"></category><category term="probability theory"></category></entry><entry><title>Readable Strings and Relational Programming in Hy</title><link href="https://brandonwillard.github.io/readable-strings-and-relational-programming-in-hy.html" rel="alternate"></link><published>2018-12-20T00:00:00-06:00</published><updated>2019-01-07T00:00:00-06:00</updated><author><name>Brandon T. Willard</name></author><id>tag:brandonwillard.github.io,2018-12-20:/readable-strings-and-relational-programming-in-hy.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon T. Willard" /&gt;
  &lt;title&gt;Readable Strings and Relational Programming in Hy&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;style type="text/css"&gt;
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  &lt;/style&gt;
  &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;Readable Strings and Relational Programming in Hy&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon T. Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2018–12–20&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;div class="abstract"&gt;
&lt;p&gt;Just some thoughts on a generalized &lt;code&gt;repr&lt;/code&gt; for Hy and some connections with relational programming.&lt;/p&gt;
&lt;/div&gt;
&lt;section id="introduction" class="level1"&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In the past few months, I’ve been working on &lt;a href="https://github.com/hylang/hy"&gt;Hy&lt;/a&gt; a lot. It’s been great for translating symbolic computation ideas originating in the Lisp community or simply performing the generic meta-programming inherent to the subject.&lt;/p&gt;
&lt;p&gt;One feature I’ve been missing the most is “readable” print-outs from the REPL. In this case, “readable” means “a string that can be &lt;code&gt;eval&lt;/code&gt;’ed to [re-]produce the object it’s meant to represent”. &lt;a href="https://docs.python.org/3/library/functions.html#repr"&gt;Python calls the function(s) that produce these strings “&lt;code&gt;repr&lt;/code&gt;”s&lt;/a&gt; and provides a generic &lt;code&gt;repr&lt;/code&gt; function–with limited Python “readability” guarantees–and a &lt;code&gt;__repr__&lt;/code&gt; property for object/class-level customization.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;div class="sourceCode" id="org1fcc4d3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org1fcc4d3-1" data-line-number="1"&gt;test_obj &lt;span class="op"&gt;=&lt;/span&gt; {&lt;span class="st"&gt;&amp;quot;a&amp;quot;&lt;/span&gt;: &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="st"&gt;&amp;quot;b&amp;quot;&lt;/span&gt;: [&lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;]}&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-3" data-line-number="3"&gt;&lt;span class="co"&gt;# Produce a readable string using `repr`&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-4" data-line-number="4"&gt;obj_repr_str &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;repr&lt;/span&gt;(test_obj)&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-5" data-line-number="5"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(obj_repr_str)&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-7" data-line-number="7"&gt;&lt;span class="co"&gt;# Re-create the object from its readable string form&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-8" data-line-number="8"&gt;obj_from_repr &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;eval&lt;/span&gt;(obj_repr_str)&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-9" data-line-number="9"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(obj_from_repr)&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org1fcc4d3-11" data-line-number="11"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(test_obj &lt;span class="op"&gt;==&lt;/span&gt; obj_from_repr)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="org636a628"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org636a628-1" data-line-number="1"&gt;{&lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;: &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;: [&lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;]}&lt;/a&gt;
&lt;a class="sourceLine" id="org636a628-2" data-line-number="2"&gt;{&lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;: &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;: [&lt;span class="dv"&gt;2&lt;/span&gt;, &lt;span class="dv"&gt;3&lt;/span&gt;]}&lt;/a&gt;
&lt;a class="sourceLine" id="org636a628-3" data-line-number="3"&gt;&lt;span class="va"&gt;True&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="org636a628-4" data-line-number="4"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;There’s already a &lt;code&gt;hy.contrib.hy-repr&lt;/code&gt; module that gets most of the way there, but it doesn’t implement the Python standard library’s &lt;code&gt;reprlib.Repr&lt;/code&gt;. The class &lt;code&gt;reprlib.Repr&lt;/code&gt; implements limits for the display lengths of the strings it produces, and its source code provides a few standard library implementations of primitive object &lt;code&gt;repr&lt;/code&gt;s–which require only trivial changes to produce the desired Hy syntax.&lt;/p&gt;
&lt;p&gt;For these reasons–and an overall interest in using and translating more of the Python standard library to Hy–I decided to try a quick refactoring of &lt;code&gt;hy.contrib.hy-repr&lt;/code&gt; that implements &lt;code&gt;reprlib.Repr&lt;/code&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="the-hy-repr-problems" class="level1"&gt;
&lt;h1&gt;The Hy &lt;code&gt;repr&lt;/code&gt; Problem(s)&lt;/h1&gt;
&lt;p&gt;The translation of Hy AST to string form is fairly straight-forward. In most cases, one only needs to change the &lt;code&gt;repr&lt;/code&gt;s for Python primitives and basic function calls (e.g. from &lt;code&gt;func(1)&lt;/code&gt; to &lt;code&gt;(func 1)&lt;/code&gt;); however, changing just a couple lines in &lt;code&gt;repr&lt;/code&gt;/&lt;code&gt;__repr__&lt;/code&gt; functions for all the Python builtins is very annoying.&lt;/p&gt;
&lt;p&gt;Furthermore, what about those custom object &lt;code&gt;__repr__&lt;/code&gt; methods? While one might be able to manually patch most–if not all–of the (Python-implemented) standard library objects, there are far too many 3rd-party library &lt;code&gt;__repr__&lt;/code&gt;s with exactly the same trivial function-call form that can’t reasonably be patched.&lt;/p&gt;
&lt;section id="some-approaches" class="level2"&gt;
&lt;h2&gt;Some approaches&lt;/h2&gt;
&lt;p&gt;The first few things that come to mind when considering a more general approach to Python-to-Hy &lt;code&gt;__repr__&lt;/code&gt; translation involve some use of the existing &lt;code&gt;repr&lt;/code&gt; code. That might come in the form of string manipulation of &lt;code&gt;repr&lt;/code&gt; output, which &lt;code&gt;hy.contrib.hy-repr&lt;/code&gt; already does in some cases, or quite possibly some use of a &lt;code&gt;repr&lt;/code&gt; function’s source or code object.&lt;/p&gt;
&lt;p&gt;The latter seems like it has the potential to be more thorough and far-reaching, but also considerably more involved and computationally inefficient. Unfortunately, similar things can be said about the regex approach. Although it does seem a little easier to implement and–for limited cases–efficient enough for most purposes, it also comes across as much more brittle.&lt;/p&gt;
&lt;p&gt;Fortunately, the latter is unnecessary, because, when the existing &lt;code&gt;repr&lt;/code&gt; output is Python readable, it can be parsed by &lt;code&gt;ast.parse&lt;/code&gt;. The function &lt;code&gt;ast.parse&lt;/code&gt; effectively handles the regex work and yields the bulk of information needed for a Hy &lt;code&gt;repr&lt;/code&gt; string: the function name and its (positional and keyword) arguments.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;Let’s say we implement our own object and &lt;code&gt;repr&lt;/code&gt;.&lt;/p&gt;
&lt;pre id="orgcb48770" class="hy"&gt;&lt;code&gt;(defclass TestClass [object]
  (defn --init-- [self arg1 arg2 &amp;amp;optional kwarg1 kwarg2]
    (setv self.arg1 arg1
          self.arg2 arg2
          self.kwarg1 kwarg1
          self.kwarg2 kwarg2))
  (defn --repr-- [self]
    (.format &amp;quot;TestClass({}, {}, kwarg1={}, kwarg2={})&amp;quot;
             #* (lfor a [self.arg1 self.arg2
                         self.kwarg1 self.kwarg2]
                      (repr a)))))

(setv test-obj (TestClass 1 {&amp;quot;a&amp;quot; 1 &amp;quot;b&amp;quot; 2} :kwarg1 1 :kwarg2 &amp;quot;ok&amp;quot;))
(print (repr test-obj))&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="org2d96184"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org2d96184-1" data-line-number="1"&gt;TestClass(&lt;span class="dv"&gt;1&lt;/span&gt;, {&lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;: &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;: &lt;span class="dv"&gt;2&lt;/span&gt;}, kwarg1&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;, kwarg2&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;ok&amp;#39;&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since the results are readable, we can do the following:&lt;/p&gt;
&lt;pre id="org382ba33" class="hy"&gt;&lt;code&gt;(import ast astor)
(setv repr-ast (ast.parse (repr test-obj) :mode &amp;quot;eval&amp;quot;))
(print (astor.dump repr-ast))&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="orgf08b55b"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgf08b55b-1" data-line-number="1"&gt;Expression(&lt;/a&gt;
&lt;a class="sourceLine" id="orgf08b55b-2" data-line-number="2"&gt;    body&lt;span class="op"&gt;=&lt;/span&gt;Call(func&lt;span class="op"&gt;=&lt;/span&gt;Name(&lt;span class="bu"&gt;id&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;TestClass&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgf08b55b-3" data-line-number="3"&gt;              args&lt;span class="op"&gt;=&lt;/span&gt;[Num(n&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgf08b55b-4" data-line-number="4"&gt;                    Dict(keys&lt;span class="op"&gt;=&lt;/span&gt;[Str(s&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;), Str(s&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;)],&lt;/a&gt;
&lt;a class="sourceLine" id="orgf08b55b-5" data-line-number="5"&gt;                         values&lt;span class="op"&gt;=&lt;/span&gt;[Num(n&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;), Num(n&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;)])],&lt;/a&gt;
&lt;a class="sourceLine" id="orgf08b55b-6" data-line-number="6"&gt;              keywords&lt;span class="op"&gt;=&lt;/span&gt;[keyword(arg&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;kwarg1&amp;#39;&lt;/span&gt;, value&lt;span class="op"&gt;=&lt;/span&gt;Num(n&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)),&lt;/a&gt;
&lt;a class="sourceLine" id="orgf08b55b-7" data-line-number="7"&gt;                        keyword(arg&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;kwarg2&amp;#39;&lt;/span&gt;, value&lt;span class="op"&gt;=&lt;/span&gt;Str(s&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;ok&amp;#39;&lt;/span&gt;))]))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section id="a-generalized-hy-repr-prototype" class="level2"&gt;
&lt;h2&gt;A Generalized Hy &lt;code&gt;repr&lt;/code&gt; Prototype&lt;/h2&gt;
&lt;p&gt;With existing &lt;code&gt;repr&lt;/code&gt; output converted to Python AST by Python itself (using &lt;code&gt;ast.parse&lt;/code&gt;), we can produce readable Hy strings from the resulting AST objects.&lt;/p&gt;
&lt;p&gt;In this scenario, we need only be concerned with the conversion of Python AST into readable Hy strings. This works like an inverse to the Hy compiler: in other words, a Hy decompiler. For &lt;code&gt;repr&lt;/code&gt; purposes, only function call statements and their arguments need to be decompiled. Unfortunately, function arguments can consist of arbitrary Python/Hy objects, and that’s how the decompilation responsibilities start to expand. If we limit our scope to a reasonable subset of Python builtins/primitives, the results can still be quite effective, and won’t require a complete decompiler.&lt;/p&gt;
&lt;p&gt;On the down-side, if a Hy &lt;code&gt;repr&lt;/code&gt; implementation overrides the built-in &lt;code&gt;repr&lt;/code&gt;, then arguments in existing &lt;code&gt;repr&lt;/code&gt;/&lt;code&gt;__repr__&lt;/code&gt;s might already be converted by the overridden &lt;code&gt;repr&lt;/code&gt;; however, the results from &lt;code&gt;ast.parse&lt;/code&gt; will undo/discard those results. Even so, custom class &lt;code&gt;__repr__&lt;/code&gt;s aren’t guaranteed to use the built-in &lt;code&gt;repr&lt;/code&gt; on their arguments, so attempts to salvage already-converted &lt;code&gt;repr&lt;/code&gt; output are undeniably fraught with complications.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;Working from the &lt;code&gt;repr&lt;/code&gt;-produced AST above, I mocked-up a quick prototype for a generic Python-to-Hy conversion function.&lt;/p&gt;
&lt;pre id="orga431a0a" class="hy"&gt;&lt;code&gt;(import ast)
(import builtins)

(import [hy.contrib.hy-repr [hy-repr :as -hy-repr]])

(defn ast-funcall-to-hy [ast-obj repr1
                         &amp;amp;optional [level 1]]
  &amp;quot;Turn Python `ast.Call` expressions into Hy `repr` strings.

XXX: Only a very minimal subset of Python-to-Hy AST is implemented.

This can be used to turn a \&amp;quot;readable\&amp;quot; `repr` result, via an actual \&amp;quot;read\&amp;quot; by
`ast.parse`, to Python AST then Hy AST.
&amp;quot;
  (assert (and (instance? ast.Expression ast-obj)
               (instance? ast.Call ast-obj.body)))
  (setv func-name (. ast-obj body func id))
  (setv eval-fn (fn [o]
                  (if (instance? ast.Name o)
                      o.id
                      (repr1 (ast.literal-eval o) (dec level)))))
  (setv func-args (lfor a (. ast-obj body args) (eval-fn a)))
  (setv func-kwargs (lfor k (. ast-obj body keywords)
                          (.format &amp;quot;:{} {}&amp;quot; k.arg (eval-fn k.value))))
  (.format &amp;quot;({})&amp;quot; (.join &amp;quot; &amp;quot; (+ [func-name] func-args func-kwargs))))


(setv test-ast (ast.parse &amp;quot;range(x, y, blah=1, bloh=\&amp;quot;ok\&amp;quot;)&amp;quot; :mode &amp;quot;eval&amp;quot;))
(print (ast-funcall-to-hy test-ast (fn [x &amp;amp;rest y] (-hy-repr x))))&lt;/code&gt;&lt;/pre&gt;
&lt;pre id="org9d771a1" class="hy"&gt;&lt;code&gt;(range x y :blah 1 :bloh &amp;quot;ok&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ast-funcall-to-hy&lt;/code&gt; is an extremely narrow decompiler that only handles readable function calls (represented by &lt;code&gt;ast.Call&lt;/code&gt; nodes), but, as part of a fallback sequence in a Hy &lt;code&gt;repr&lt;/code&gt; implementation, it’s still pretty useful.&lt;/p&gt;
&lt;p&gt;A function like &lt;code&gt;ast-funcall-to-hy&lt;/code&gt; can be used in &lt;code&gt;repr&lt;/code&gt; logic as follows:&lt;/p&gt;
&lt;pre id="org80332ca" class="hy"&gt;&lt;code&gt;(defn hy-repr [x &amp;amp;optional [level 1] [-repr (fn [x &amp;amp;rest y] (-hy-repr x))]]
  &amp;quot;Use `builtin.repr` results to generate readable Hy `repr` strings for cases
we haven&amp;#39;t covered explicitly.
&amp;quot;
  (try
    (setv s (builtins.repr x))
    (when (not (.startswith s &amp;quot;&amp;lt;&amp;quot;))
      (do
        (setv repr-ast (ast.parse s :mode &amp;quot;eval&amp;quot;))
        (setv s (ast-funcall-to-hy repr-ast -repr))))
    s
    (except [Exception]
      (.format &amp;quot;&amp;lt;{} instance at {}&amp;gt;&amp;quot; x.__class__.__name__ (id x)))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, for the example class, &lt;code&gt;TestClass&lt;/code&gt;, we can demonstrate automatic conversion of its Python &lt;code&gt;__repr__&lt;/code&gt; implementation.&lt;/p&gt;
&lt;pre id="org21d5bb7" class="hy"&gt;&lt;code&gt;(setv test-ast (TestClass 1 {&amp;quot;a&amp;quot; 2 &amp;quot;b&amp;quot; 3} :kwarg1 1 :kwarg2 &amp;quot;ok&amp;quot;))
(print (.format &amp;quot;before: {}\nafter: {}&amp;quot;
                (repr test-ast)
                (hy-repr test-ast)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre id="orgb59b9c2" class="text"&gt;&lt;code&gt;before: TestClass(1, {&amp;#39;a&amp;#39;: 2, &amp;#39;b&amp;#39;: 3}, kwarg1=1, kwarg2=&amp;#39;ok&amp;#39;)
after: (TestClass 1 {&amp;quot;a&amp;quot; 2  &amp;quot;b&amp;quot; 3} :kwarg1 1 :kwarg2 &amp;quot;ok&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="relational-programming" class="level1"&gt;
&lt;h1&gt;Relational Programming&lt;/h1&gt;
&lt;p&gt;While considering all this, I kept thinking about how nice it would be to have a “bijective” compiler; in other words, the existing Hy compiler, which translates Hy-to-Python, &lt;strong&gt;and&lt;/strong&gt; a Python-to-Hy (de)compiler. With a Python-to-Hy AST compiler, we could more broadly convert Python AST output–like the kind in our example above–to a &lt;code&gt;repr&lt;/code&gt;/readable string in Hy.&lt;/p&gt;
&lt;p&gt;The idea isn’t too crazy, especially since one can easily work backward from a lot of the logic in the existing Hy compiler. There will be some edge cases that result in non-bijective translations (i.e. some round-trip Hy/Python translations might only be &lt;strong&gt;equivalent&lt;/strong&gt; and not exactly &lt;strong&gt;equal&lt;/strong&gt;), but this isn’t necessarily a blocking issue. Decisions regarding “canonical” or reduced forms of Hy/Python AST might be necessary, especially if the resulting AST is intended to be more human readable than not.&lt;/p&gt;
&lt;p&gt;Perhaps what’s more discouraging is the effort it would take to ensure that the compilation processes going both ways are–and stay–coherent during the course of development. For instance, when changes are made to the standard compilation process (i.e. Hy-to-Python), it’s likely that changes and tests would also be needed for the other direction.&lt;/p&gt;
&lt;p&gt;This is where a paradigm like relational programming is particularly appealing: it provides a language for defining–and means for computing–the maps&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
  \text{Hy Syntax}
  \longleftrightarrow \text{Python AST}
  \longleftrightarrow \text{Python Syntax}
  \;
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;in a cohesive way.&lt;/p&gt;
&lt;p&gt;My relational programming DSL of choice, &lt;a href="http://minikanren.org"&gt;miniKanren&lt;/a&gt;, already has an implementation in Hy: &lt;a href="https://github.com/algernon/adderall"&gt;&lt;code&gt;loghyc&lt;/code&gt; (and to be formally known as &lt;code&gt;adderall&lt;/code&gt;)&lt;/a&gt;. We’ve been using it to perform static code analysis and refactoring in the project &lt;a href="https://github.com/hylang/hydiomatic"&gt;&lt;code&gt;hydiomatic&lt;/code&gt;&lt;/a&gt;, so there’s also a precedent for parsing Hy syntax in a relational context.&lt;/p&gt;
&lt;p&gt;The missing/next step would be to output Python AST (instead of more Hy forms, like &lt;code&gt;hydiomatic&lt;/code&gt; produces, for example). In the following sections, we will construct a small relational Hy/Python compiler as a proof-of-concept.&lt;/p&gt;
&lt;section id="a-prototype-relational-compiler" class="level2"&gt;
&lt;h2&gt;A Prototype Relational Compiler&lt;/h2&gt;
&lt;p&gt;Creating a bi-directional Hy/Python AST compiler in miniKanren involves the construction of goals “relating” the two AST forms. For simplicity, we’ll just consider function call expressions, like &lt;code&gt;func(args)&lt;/code&gt; and &lt;code&gt;(func args)&lt;/code&gt;.&lt;/p&gt;
&lt;div class="remark" data-markdown=""&gt;
&lt;p&gt;Also, since these kinds of relations are more easy to specify using constraints and subtle unification adjustments, we’ll use a prototype microKanren implementation in Hy that provides immediate access to those: &lt;a href="https://github.com/brandonwillard/hypoKanren"&gt;&lt;code&gt;hypoKanren&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Regardless, given the universality of miniKanren, the goals we construct should be directly translate-able to other implementations of miniKanren (even in completely different host languages).&lt;/p&gt;
&lt;p&gt;The only obvious caveat to such translation is the availability of traditional &lt;code&gt;cons&lt;/code&gt; semantics in the host language (i.e. the standard Lisp behavior of &lt;code&gt;cons&lt;/code&gt;, &lt;code&gt;car&lt;/code&gt;, &lt;code&gt;cdr&lt;/code&gt;, and improper lists/&lt;code&gt;cons&lt;/code&gt; pairs).&lt;/p&gt;
&lt;/div&gt;
&lt;pre id="orgc53b310" class="hy"&gt;&lt;code&gt;(import ast)
(import astor)
(import types)
(import [collections [Callable]])

(import hy.models)
(import [hy.compiler [asty hy-eval hy-compile]])

(import [hypoKanren.goals [*]])
(import [hypoKanren.core [*]])


(require [hy.contrib.walk [let]])
(require [hypoKanren.goals [*]])
(require [hypoKanren.core [*]])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s examine the general structure of the Python AST output generated by the Hy compiler for the Hy function-call given by &lt;code&gt;`(func x :y z)&lt;/code&gt;.&lt;/p&gt;
&lt;pre id="org7521929" class="hy"&gt;&lt;code&gt;(astor.dump (hy-compile `(func x :y z) &amp;quot;__console__&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="orgb137229"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgb137229-1" data-line-number="1"&gt;Module(&lt;/a&gt;
&lt;a class="sourceLine" id="orgb137229-2" data-line-number="2"&gt;    body&lt;span class="op"&gt;=&lt;/span&gt;[Expr(value&lt;span class="op"&gt;=&lt;/span&gt;Call(func&lt;span class="op"&gt;=&lt;/span&gt;Name(&lt;span class="bu"&gt;id&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;func&amp;#39;&lt;/span&gt;), args&lt;span class="op"&gt;=&lt;/span&gt;[Name(&lt;span class="bu"&gt;id&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;)], keywords&lt;span class="op"&gt;=&lt;/span&gt;[keyword(arg&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, value&lt;span class="op"&gt;=&lt;/span&gt;Name(&lt;span class="bu"&gt;id&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;))]))])&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In what follows, we’ll exclude the &lt;code&gt;ast.Module&lt;/code&gt; and focus only on the &lt;code&gt;src.Expr&lt;/code&gt; and its children.&lt;/p&gt;
&lt;section id="ast-object-unification" class="level3"&gt;
&lt;h3&gt;AST Object Unification&lt;/h3&gt;
&lt;p&gt;To make existing Python AST objects amenable to the &lt;a href="https://en.wikipedia.org/wiki/Unification_(computer_science)"&gt;unification&lt;/a&gt; used by miniKanren, we implement &lt;code&gt;unify&lt;/code&gt; specializations for &lt;code&gt;ast.AST&lt;/code&gt; types. Our implementation simply generates unevaluated Hy forms, or Hy AST, that–when evaluated–would (re)create the &lt;code&gt;ast.AST&lt;/code&gt; objects.&lt;/p&gt;
&lt;div class="REMARK"&gt;
&lt;p&gt;Alternatively, we could only ever use and create unevaluated Hy forms for Python AST. Providing unification for AST objects allows for more immediate integration with existing Python code and/or what it would most likely produce.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;hypoKanren&lt;/code&gt; uses &lt;a href="https://github.com/mrocklin/multipledispatch"&gt;&lt;code&gt;multipledispatch&lt;/code&gt;&lt;/a&gt;, so augmenting the unification process is easy. This is how we’ll add support for AST objects.&lt;/p&gt;
&lt;div class="REMARK"&gt;
&lt;p&gt;There’s already a good pure Python library for unification built upon &lt;code&gt;multipledispatch&lt;/code&gt;, &lt;a href="https://github.com/mrocklin/unification"&gt;&lt;code&gt;unfication&lt;/code&gt;&lt;/a&gt;. At a later time, it might be worthwhile to simply add support for Hy objects and use that library instead.&lt;/p&gt;
&lt;/div&gt;
&lt;pre id="org1468291" class="hy"&gt;&lt;code&gt;(import [multipledispatch [dispatch]])
(import [hypoKanren.unify [*]])
(import [hy.models [*]])
(import [hy.contrib.walk [prewalk]])


(defmacro/g! dispatch-unify-trans [disp-type trans-func &amp;amp;optional [func &amp;#39;unify]]
  `(do
     #@((dispatch ~disp-type object object)
        (defn unify-post-walk [~g!u ~g!v ~g!s]
          (~func (~trans-func ~g!u) ~g!v ~g!s)))
     #@((dispatch object ~disp-type object)
        (defn unify-post-walk [~g!u ~g!v ~g!s]
          (~func ~g!u (~trans-func ~g!v) ~g!s)))
     #@((dispatch ~disp-type ~disp-type object)
        (defn unify-post-walk [~g!u ~g!v ~g!s]
          (~func (~trans-func ~g!u) (~trans-func ~g!v) ~g!s)))))

(defn py-ast-to-expr [x]
  (defn -py-ast-to-expr [u]
    (setv ast-expr
          `(~(HySymbol (+ &amp;quot;ast.&amp;quot; (name (type u))))
            ~@(chain.from-iterable
                (lfor f u.-fields
                      :if (hasattr u f)
                      [(HyKeyword f) (getattr u f)]))))
    ast-expr)
  (prewalk (fn [y] (if (instance? ast.AST y)
                       (-py-ast-to-expr y)
                       y))
           x))

;; Python AST expansion pre-unification
(dispatch-unify-trans ast.AST (fn [x] (py-ast-to-expr x)))&lt;/code&gt;&lt;/pre&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;pre id="org70c1279" class="hy"&gt;&lt;code&gt;;; One is an `ast.AST` object, the other an unevaluated `ast.AST`
;; object-generating form.
(setv unify-exa-1 (unify (ast.Expr :value [])
                         `(ast.Expr :value ~(var 0))
                         {}))

;; Both are `ast.AST` objects
(setv unify-exa-2 (unify (ast.Expr :value [])
                         (ast.Expr :value (var 0))
                         {}))

(= (.get unify-exa-1 (var 0))
   (.get unify-exa-2 (var 0))
   [])&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="orgc9b3e95"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgc9b3e95-1" data-line-number="1"&gt;&lt;span class="va"&gt;True&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Listing &lt;a href="#org70c1279"&gt;16&lt;/a&gt; illustrates unification of two &lt;code&gt;ast.AST&lt;/code&gt; forms. The &lt;code&gt;(var 0)&lt;/code&gt; objects are “logic variables” taking the value of sub-expressions that cause the two &lt;code&gt;unify&lt;/code&gt; arguments to, well, unify. The third argument to &lt;code&gt;unify&lt;/code&gt; is simply a &lt;code&gt;dict&lt;/code&gt; that stores the logic variable/sub-expression mappings.&lt;/p&gt;
&lt;p&gt;In other words, logic variables are like unknowns that &lt;code&gt;unify(u, v, s)&lt;/code&gt; will “solve” in order to make &lt;code&gt;u&lt;/code&gt; and &lt;code&gt;v&lt;/code&gt; equal.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;pre id="orgd9478e0" class="hy"&gt;&lt;code&gt;(unify (cons &amp;#39;ast.Expr (var 0))
       (ast.Expr :value [(ast.Name :id &amp;quot;a&amp;quot;)])
       {})&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="org3302cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org3302cb2-1" data-line-number="1"&gt;{(LVar &lt;span class="dv"&gt;0&lt;/span&gt;): HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org3302cb2-2" data-line-number="2"&gt;  HyKeyword(&lt;span class="st"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org3302cb2-3" data-line-number="3"&gt;  [HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org3302cb2-4" data-line-number="4"&gt;    HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Name&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org3302cb2-5" data-line-number="5"&gt;    HyKeyword(&lt;span class="st"&gt;&amp;#39;id&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org3302cb2-6" data-line-number="6"&gt;    &lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;])]])}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Listing &lt;a href="#orgd9478e0"&gt;18&lt;/a&gt; is a more interesting example that demonstrates partial/improper list unification. Since &lt;code&gt;ast.AST&lt;/code&gt; objects are expanded into equal object-instantiating Hy AST forms, &lt;code&gt;(cons 'ast.Expr (var 0))&lt;/code&gt; is ultimately unified with a &lt;code&gt;HyExpression&lt;/code&gt; (a subclass of &lt;code&gt;list&lt;/code&gt;). Under the &lt;code&gt;cons&lt;/code&gt; abstraction, &lt;code&gt;(var 0)&lt;/code&gt; can be anything that–when &lt;code&gt;cons&lt;/code&gt;ed with the symbol &lt;code&gt;ast.Expr&lt;/code&gt;–will produce the expression &lt;code&gt;(ast.Expr :value [(ast.Name :id &amp;quot;a&amp;quot;)])&lt;/code&gt;. The result is the partial &lt;code&gt;HyExpression&lt;/code&gt; comprising the arguments to the &lt;code&gt;ast.Expr&lt;/code&gt; constructor–in other words, the &lt;code&gt;cdr&lt;/code&gt; of the &lt;code&gt;ast.AST&lt;/code&gt; form.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We will also need to unify some limited Hy AST forms; specifically, &lt;code&gt;HySymbol&lt;/code&gt;s. We will want to extract only the name part of a Hy symbol and relate that to Python &lt;code&gt;ast.Name&lt;/code&gt;s via one of the latter’s constructor arguments.&lt;/p&gt;
&lt;p&gt;Similar to Python AST nodes, we will expand/lift/abstract &lt;code&gt;HySymbol&lt;/code&gt;s to Hy expressions that–when &lt;code&gt;eval&lt;/code&gt;’ed–would construct them. We can only do this in very limited cases; otherwise, we could end up producing ever-expanding forms.&lt;/p&gt;
&lt;pre id="org7b1a1a0" class="hy"&gt;&lt;code&gt;;; Hy AST expansion pre-unification
(defn unify-hysymbol [u v s]
  (cond
    [(= (first v) &amp;#39;HySymbol)
     (print )
     (unify `(HySymbol ~(name u)) v s)]
    [True
     (unify u v s)]))

#@((dispatch HySymbol HyExpression object)
   (defn unify-post-walk [u v s]
     (unify-hysymbol u v s)))

#@((dispatch HyExpression HySymbol object)
   (defn unify-post-walk [u v s]
     (unify-hysymbol v u s)))&lt;/code&gt;&lt;/pre&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;pre id="orgbc4dbe9" class="hy"&gt;&lt;code&gt;(unify &amp;#39;a `(HySymbol ~(var 0)) {})&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="orga00b5a1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orga00b5a1-1" data-line-number="1"&gt;{(LVar &lt;span class="dv"&gt;0&lt;/span&gt;): &lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Listing &lt;a href="#org7b1a1a0"&gt;20&lt;/a&gt; demonstrates the expansion and unification of Hy AST symbols.&lt;/p&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section id="call-expression-goals" class="level3"&gt;
&lt;h3&gt;Call-expression Goals&lt;/h3&gt;
&lt;p&gt;Next, we create the miniKanren goals that encapsulate the relationships between simple Hy and Python AST forms. In particular, we’ll limit ourselves to only variable reference and function call forms.&lt;/p&gt;
&lt;pre id="orge442cd6" class="hy"&gt;&lt;code&gt;(defn listo [l]
  &amp;quot;A goal stating that `l` is a list.&amp;quot;
  (conde
    [(== l []) s#]
    [(fresh [lcar lcdr]
            (== l (cons lcar lcdr))
            (listo lcdr))]
    [s# u#]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first AST relation is a simple one between &lt;code&gt;HySymbol&lt;/code&gt;s and &lt;code&gt;ast.Name&lt;/code&gt;s. This is where the &lt;code&gt;HySymbol&lt;/code&gt; unification implemented above is used.&lt;/p&gt;
&lt;pre id="org9fe6aea" class="hy"&gt;&lt;code&gt;(defn hy-py-symbolo [hy-ast py-ast]
  &amp;quot;A goal relating Hy and Python AST symbol/name objects (e.g. variable and
 function references).&amp;quot;
  (fresh [symbol-name py-ctx]
         (== hy-ast `(HySymbol ~symbol-name))
         (== py-ast `(ast.Name :id ~symbol-name
                               :ctx (ast.Load)))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some Python &lt;code&gt;ast.AST&lt;/code&gt; types have fields consisting of lists containing other &lt;code&gt;ast.AST&lt;/code&gt; objects (e.g. the &lt;code&gt;ast.Call&lt;/code&gt; expressions below). We need a goal that enforces a relation between the Hy and Python AST forms of each element in such lists.&lt;/p&gt;
&lt;pre id="org988ece9" class="hy"&gt;&lt;code&gt;(defn lapplyo [func l-in l-out]
  &amp;quot;A goal that applies the goal `func` between all elements in lists `l-in` and
 `l-out`.&amp;quot;
  (conj+
    (listo l-in)
    (conde
      [(fresh [lcar lcdr lout-car lout-cdr]
              (== l-in (cons lcar lcdr))
              (func lcar lout-car)
              (lapplyo func lcdr lout-cdr)
              (== l-out (cons lout-car lout-cdr)))]
      [(== l-in [])
       (== l-out l-in)])))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we create a goal for the AST of call expressions like &lt;code&gt;func(x, y, z)&lt;/code&gt; and &lt;code&gt;(func x y z)&lt;/code&gt;.&lt;/p&gt;
&lt;pre id="org10bec84" class="hy"&gt;&lt;code&gt;(defn hy-py-callo [hy-ast py-ast]
  &amp;quot;A goal relating call expressions in Python and Hy AST.&amp;quot;
  (fresh [hy-op hy-args py-op py-args]
         ;; Hy AST form
         (== (cons hy-op hy-args) hy-ast)
         ;; Py AST form
         (== py-ast `(ast.Expr :value
                               (ast.Call :func
                                         ~py-op
                                         :args
                                         ~py-args
                                         :keywords
                                         [])))
         ;; These two must be related symbols
         (hy-py-symbolo hy-op py-op)
         ;; The arguments are related lists containing more of each AST type.
         (lapplyo hy-py-asto hy-args py-args)))

(defn hy-py-asto [hy-ast py-ast]
  &amp;quot;A goal for a &amp;#39;branching&amp;#39; relation between multiple types of forms and their
 corresponding Python AST.&amp;quot;
  (conde
    [(hy-py-symbolo hy-ast py-ast)]
    [(hy-py-callo hy-ast py-ast)]))&lt;/code&gt;&lt;/pre&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;To demonstrate our [extremely] minimal relational compiler, we create a Hy function call expression and its corresponding Python AST.&lt;/p&gt;
&lt;pre id="org7845670" class="hy"&gt;&lt;code&gt;(setv hy-ast-exa `(print x y z))
(setv py-ast-exa (. (hy-compile hy-ast-exa &amp;quot;__console__&amp;quot;) body [0]))
(.format &amp;quot;hy_ast_exa = {}\npy_ast_exa = {}&amp;quot;
         hy-ast-exa
         (astor.dump py-ast-exa))&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="org09b193c"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org09b193c-1" data-line-number="1"&gt;hy_ast_exa &lt;span class="op"&gt;=&lt;/span&gt; HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org09b193c-2" data-line-number="2"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;print&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org09b193c-3" data-line-number="3"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org09b193c-4" data-line-number="4"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org09b193c-5" data-line-number="5"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;)])&lt;/a&gt;
&lt;a class="sourceLine" id="org09b193c-6" data-line-number="6"&gt;py_ast_exa &lt;span class="op"&gt;=&lt;/span&gt; Expr(value&lt;span class="op"&gt;=&lt;/span&gt;Call(func&lt;span class="op"&gt;=&lt;/span&gt;Name(&lt;span class="bu"&gt;id&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;print&amp;#39;&lt;/span&gt;), args&lt;span class="op"&gt;=&lt;/span&gt;[Name(&lt;span class="bu"&gt;id&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;), Name(&lt;span class="bu"&gt;id&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;), Name(&lt;span class="bu"&gt;id&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;)], keywords&lt;span class="op"&gt;=&lt;/span&gt;[]))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We first run the Hy-to-Python direction by providing &lt;code&gt;hy-expro&lt;/code&gt; the &lt;code&gt;hy-ast-exa&lt;/code&gt; value above and a logic variable (i.e. an “unknown”) for the Python AST term.&lt;/p&gt;
&lt;pre id="org5336211" class="hy"&gt;&lt;code&gt;(setv rel-res (run 1 [py-ast] (hy-py-asto hy-ast-exa py-ast)))
(setv ast-res (get rel-res 0 0))
ast-res&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="org63b2bde"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="org63b2bde-1" data-line-number="1"&gt;HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-2" data-line-number="2"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Expr&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-3" data-line-number="3"&gt;  HyKeyword(&lt;span class="st"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-4" data-line-number="4"&gt;  HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-5" data-line-number="5"&gt;    HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Call&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-6" data-line-number="6"&gt;    HyKeyword(&lt;span class="st"&gt;&amp;#39;func&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-7" data-line-number="7"&gt;    HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-8" data-line-number="8"&gt;      HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Name&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-9" data-line-number="9"&gt;      HyKeyword(&lt;span class="st"&gt;&amp;#39;id&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-10" data-line-number="10"&gt;      &lt;span class="st"&gt;&amp;#39;print&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-11" data-line-number="11"&gt;      HyKeyword(&lt;span class="st"&gt;&amp;#39;ctx&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-12" data-line-number="12"&gt;      HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-13" data-line-number="13"&gt;        HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Load&amp;#39;&lt;/span&gt;)])]),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-14" data-line-number="14"&gt;    HyKeyword(&lt;span class="st"&gt;&amp;#39;args&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-15" data-line-number="15"&gt;    HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-16" data-line-number="16"&gt;      HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-17" data-line-number="17"&gt;        HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Name&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-18" data-line-number="18"&gt;        HyKeyword(&lt;span class="st"&gt;&amp;#39;id&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-19" data-line-number="19"&gt;        &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-20" data-line-number="20"&gt;        HyKeyword(&lt;span class="st"&gt;&amp;#39;ctx&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-21" data-line-number="21"&gt;        HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-22" data-line-number="22"&gt;          HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Load&amp;#39;&lt;/span&gt;)])]),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-23" data-line-number="23"&gt;      HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-24" data-line-number="24"&gt;        HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Name&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-25" data-line-number="25"&gt;        HyKeyword(&lt;span class="st"&gt;&amp;#39;id&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-26" data-line-number="26"&gt;        &lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-27" data-line-number="27"&gt;        HyKeyword(&lt;span class="st"&gt;&amp;#39;ctx&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-28" data-line-number="28"&gt;        HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-29" data-line-number="29"&gt;          HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Load&amp;#39;&lt;/span&gt;)])]),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-30" data-line-number="30"&gt;      HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-31" data-line-number="31"&gt;        HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Name&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-32" data-line-number="32"&gt;        HyKeyword(&lt;span class="st"&gt;&amp;#39;id&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-33" data-line-number="33"&gt;        &lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-34" data-line-number="34"&gt;        HyKeyword(&lt;span class="st"&gt;&amp;#39;ctx&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-35" data-line-number="35"&gt;        HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-36" data-line-number="36"&gt;          HySymbol(&lt;span class="st"&gt;&amp;#39;ast.Load&amp;#39;&lt;/span&gt;)])])]),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-37" data-line-number="37"&gt;    HyKeyword(&lt;span class="st"&gt;&amp;#39;keywords&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="org63b2bde-38" data-line-number="38"&gt;    HyList()])])&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And, now, the other direction (i.e. known Python AST, unknown Hy AST).&lt;/p&gt;
&lt;pre id="org7148809" class="hy"&gt;&lt;code&gt;(setv rel-res (run 1 [hy-ast] (hy-py-asto hy-ast py-ast-exa)))
(setv ast-res (get rel-res 0 0))
ast-res&lt;/code&gt;&lt;/pre&gt;
&lt;div class="sourceCode" id="orgbf40b7d"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="orgbf40b7d-1" data-line-number="1"&gt;[HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="orgbf40b7d-2" data-line-number="2"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;HySymbol&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgbf40b7d-3" data-line-number="3"&gt;  &lt;span class="st"&gt;&amp;#39;print&amp;#39;&lt;/span&gt;]), HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="orgbf40b7d-4" data-line-number="4"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;HySymbol&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgbf40b7d-5" data-line-number="5"&gt;  &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;]), HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="orgbf40b7d-6" data-line-number="6"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;HySymbol&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgbf40b7d-7" data-line-number="7"&gt;  &lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;]), HyExpression([&lt;/a&gt;
&lt;a class="sourceLine" id="orgbf40b7d-8" data-line-number="8"&gt;  HySymbol(&lt;span class="st"&gt;&amp;#39;HySymbol&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="orgbf40b7d-9" data-line-number="9"&gt;  &lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;])]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content><category term="hy"></category><category term="relational programming"></category><category term="python"></category></entry><entry><title>Data Science at Citybase</title><link href="https://brandonwillard.github.io/data-science-at-citybase.html" rel="alternate"></link><published>2018-12-18T00:00:00-06:00</published><updated>2018-12-23T00:00:00-06:00</updated><author><name>Brandon T. Willard</name></author><id>tag:brandonwillard.github.io,2018-12-18:/data-science-at-citybase.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon T. Willard" /&gt;
  &lt;title&gt;Data Science at Citybase&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;Data Science at Citybase&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon T. Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2018–12–18&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;p&gt;I recently wrote about data science at CityBase on the CityBase blog: &lt;sup id="c26e94c1b0b80ac3545371089d4f9936"&gt;&lt;a href="#WillardProgrammingIntelligentCity2018a"&gt;Programming an Intelligent City: The Role of Data Science&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;section id="bibliography" class="level1"&gt;
&lt;h1&gt;Bibliography&lt;/h1&gt;
&lt;p&gt;&lt;a id="WillardProgrammingIntelligentCity2018a"&gt;&lt;/a&gt;[WillardProgrammingIntelligentCity2018a] Willard, Programming an Intelligent City: The Role of Data Science, &lt;i&gt;CityBase&lt;/i&gt;, (2018). &lt;a href="https://thecitybase.com/programming-an-intelligent-city-the-role-of-data-science/"&gt;link&lt;/a&gt;. &lt;a href="#c26e94c1b0b80ac3545371089d4f9936"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content><category term="statistics"></category><category term="symbolic computation"></category><category term="citybase"></category></entry><entry><title>Symbolic Math in PyMC3</title><link href="https://brandonwillard.github.io/symbolic-math-in-pymc3.html" rel="alternate"></link><published>2018-12-18T00:00:00-06:00</published><updated>2018-12-26T00:00:00-06:00</updated><author><name>Brandon T. Willard</name></author><id>tag:brandonwillard.github.io,2018-12-18:/symbolic-math-in-pymc3.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon T. Willard" /&gt;
  &lt;title&gt;Symbolic Math in PyMC3&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;style type="text/css"&gt;
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  &lt;/style&gt;
  &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;Symbolic Math in PyMC3&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon T. Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2018–12–18&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;section id="introduction" class="level1"&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In &lt;sup id="4407b21e48ab9ff17c017e8d62684725"&gt;&lt;a href="#WillardRoleSymbolicComputation2017"&gt;A Role for Symbolic Computation in the General Estimation of Statistical Models&lt;/a&gt;&lt;/sup&gt;, I described how symbolic computation is used by bayesian modeling software like PyMC3 and some directions it could take. It closed with an example of automatic normal-normal convolution using PyMC3 objects and Theano’s optimization framework. This article elaborates on the foundations for symbolic mathematics in Theano and PyMC3; specifically, its current state, some challenges, and potential improvements.&lt;/p&gt;
&lt;p&gt;Let’s start by reconsidering the simple normal-normal convolution model. Mathematically, we can represent the model as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation}
  X \sim N(0, 1), \quad
  Y \sim N\left(1, \frac12\right), \quad
  Z = X + Y \sim N\left(1, \frac32\right)
  \label{eq:norm_conv_model}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Using PyMC3, the model for Equation &lt;span class="math inline"&gt;\(\eqref{eq:norm_conv_model}\)&lt;/span&gt; is constructed as follows:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; sys&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" data-line-number="2"&gt;&lt;span class="im"&gt;import&lt;/span&gt; os&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" data-line-number="4"&gt;&lt;span class="im"&gt;from&lt;/span&gt; pprint &lt;span class="im"&gt;import&lt;/span&gt; pprint&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" data-line-number="6"&gt;&lt;span class="im"&gt;import&lt;/span&gt; numpy &lt;span class="im"&gt;as&lt;/span&gt; np&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-8" data-line-number="8"&gt;os.environ[&lt;span class="st"&gt;&amp;#39;MKL_THREADING_LAYER&amp;#39;&lt;/span&gt;] &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;GNU&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-10" data-line-number="10"&gt;&lt;span class="im"&gt;import&lt;/span&gt; theano&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-11" data-line-number="11"&gt;&lt;span class="im"&gt;import&lt;/span&gt; theano.tensor &lt;span class="im"&gt;as&lt;/span&gt; tt&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-13" data-line-number="13"&gt;theano.config.mode &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;FAST_COMPILE&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-14" data-line-number="14"&gt;theano.config.exception_verbosity &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;high&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-16" data-line-number="16"&gt;&lt;span class="im"&gt;import&lt;/span&gt; pymc3 &lt;span class="im"&gt;as&lt;/span&gt; pm&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" data-line-number="1"&gt;mu_X &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;mu_X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" data-line-number="2"&gt;mu_X.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;0.&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-3" data-line-number="3"&gt;sd_X &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;sd_X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-4" data-line-number="4"&gt;sd_X.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;1.&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-6" data-line-number="6"&gt;mu_Y &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;mu_Y&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-7" data-line-number="7"&gt;mu_Y.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;1.&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-8" data-line-number="8"&gt;sd_Y &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;sd_Y&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-9" data-line-number="9"&gt;sd_Y.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;0.5&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-11" data-line-number="11"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model() &lt;span class="im"&gt;as&lt;/span&gt; conv_model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-12" data-line-number="12"&gt;    X_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;X_rv&amp;#39;&lt;/span&gt;, mu_X, sd&lt;span class="op"&gt;=&lt;/span&gt;sd_X, shape&lt;span class="op"&gt;=&lt;/span&gt;(&lt;span class="dv"&gt;1&lt;/span&gt;,))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-13" data-line-number="13"&gt;    Y_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;Y_rv&amp;#39;&lt;/span&gt;, mu_Y, sd&lt;span class="op"&gt;=&lt;/span&gt;sd_Y, shape&lt;span class="op"&gt;=&lt;/span&gt;(&lt;span class="dv"&gt;1&lt;/span&gt;,))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-14" data-line-number="14"&gt;    Z_rv &lt;span class="op"&gt;=&lt;/span&gt; X_rv &lt;span class="op"&gt;+&lt;/span&gt; Y_rv&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The Python objects representing terms in &lt;span class="math inline"&gt;\(\eqref{eq:norm_conv_model}\)&lt;/span&gt; are &lt;code&gt;X_rv&lt;/code&gt;, &lt;code&gt;Y_rv&lt;/code&gt;, and &lt;code&gt;Z_rv&lt;/code&gt; in &lt;a href="#pymc3_model"&gt;pymc3_model&lt;/a&gt;. Those terms together form a Theano graph for the entirety of &lt;span class="math inline"&gt;\(\eqref{eq:norm_conv_model}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Other aspects of the model are implicitly stored in the &lt;a href="https://docs.python.org/3.6/reference/compound_stmts.html#with"&gt;Python context object&lt;/a&gt; &lt;code&gt;conv_model&lt;/code&gt;. For example, the context object tracks the model’s log likelihood function when some variables are designated as “observed”–i.e. associated with sample data. In this example, we haven’t specified an observed variable, so the context object won’t be immediately useful.&lt;/p&gt;
&lt;div class="remark" data-markdown=""&gt;
&lt;p&gt;In what follows, we’ll briefly introduce the internal aspects of PyMC3 that are immediately relevant for the topics addressed here; otherwise, see &lt;a href="https://docs.pymc.io/developer_guide.html"&gt;the PyMC3 developer’s guide&lt;/a&gt; for an explanation of its design and internal workings.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The terms &lt;code&gt;X_rv&lt;/code&gt;, &lt;code&gt;Y_rv&lt;/code&gt; are derived from both a PyMC3 &lt;a href="https://github.com/pymc-devs/pymc3/blob/v3.3/pymc3/model.py#L151"&gt;&lt;code&gt;Factor&lt;/code&gt;&lt;/a&gt; class and the standard Theano &lt;code&gt;TensorVariable&lt;/code&gt;, as illustrated in the output of &lt;a href="#pymc3_mro"&gt;pymc3_mro&lt;/a&gt;. However, the convolution term &lt;code&gt;Z_rv&lt;/code&gt; is not a PyMC3 random variable; in other words, it does &lt;strong&gt;not&lt;/strong&gt; implement the PyMC3 &lt;code&gt;Factor&lt;/code&gt; class, but it &lt;strong&gt;is&lt;/strong&gt; a Theano &lt;code&gt;TensorVariable&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb3-1" data-line-number="1"&gt;pprint({&lt;span class="st"&gt;&amp;#39;Y_rv&amp;#39;&lt;/span&gt;: &lt;span class="bu"&gt;type&lt;/span&gt;(Y_rv).mro()})&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-2" data-line-number="2"&gt;pprint({&lt;span class="st"&gt;&amp;#39;Z_rv&amp;#39;&lt;/span&gt;: &lt;span class="bu"&gt;type&lt;/span&gt;(Z_rv).mro()})&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb4-1" data-line-number="1"&gt;{&lt;span class="st"&gt;&amp;#39;Y_rv&amp;#39;&lt;/span&gt;: [&lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;pymc3.model.FreeRV&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-2" data-line-number="2"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;pymc3.model.Factor&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-3" data-line-number="3"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.tensor.var.TensorVariable&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-4" data-line-number="4"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.tensor.var._tensor_py_operators&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-5" data-line-number="5"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.gof.graph.Variable&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-6" data-line-number="6"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.gof.graph.Node&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-7" data-line-number="7"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.gof.utils.object2&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-8" data-line-number="8"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;object&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;]}&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-9" data-line-number="9"&gt;{&lt;span class="st"&gt;&amp;#39;Z_rv&amp;#39;&lt;/span&gt;: [&lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.tensor.var.TensorVariable&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-10" data-line-number="10"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.tensor.var._tensor_py_operators&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-11" data-line-number="11"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.gof.graph.Variable&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-12" data-line-number="12"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.gof.graph.Node&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-13" data-line-number="13"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;theano.gof.utils.object2&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-14" data-line-number="14"&gt;          &lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;object&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;]}&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-15" data-line-number="15"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While PyMC3 doesn’t &lt;strong&gt;need&lt;/strong&gt; to support convolution, so much within Bayesian statistics, MCMC, and probabilistic programming rely on it in some way. It’s an intrinsic part of the algebra(s) implied by the use of probability theory and essential to the implementation of more sophisticated models and sampler optimizations–in at least the same way as symbolic differentiation. Here, the question isn’t whether these algebraic properties are explicitly supported, but how easily they can be implemented when necessary.&lt;/p&gt;
&lt;p&gt;As it appears, all work related to probability theory or the algebra of random variables is performed implicitly within the context of Theano and mostly detached from the model-level meta information provided by the PyMC3 abstractions. This means that the linear/tensor algebra supported by Theano is the primary level of abstraction.&lt;/p&gt;
&lt;p&gt;More specifically, one purpose of the PyMC3 probability theory abstractions (e.g. random variable classes—&lt;code&gt;FreeRV&lt;/code&gt; and &lt;code&gt;ObservedRV&lt;/code&gt;, distributions and their likelihoods, etc.) is to associate a PyMC3 &lt;a href="https://github.com/pymc-devs/pymc3/blob/v3.3/pymc3/distributions/distribution.py#L18"&gt;&lt;code&gt;Distribution&lt;/code&gt;&lt;/a&gt; object with a Theano &lt;code&gt;TensorVariable&lt;/code&gt;. This connection is made through a &lt;code&gt;distribution&lt;/code&gt; attribute&lt;/p&gt;
&lt;div class="sourceCode" id="cb5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb5-1" data-line-number="1"&gt;pprint(Y_rv.distribution)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-2" data-line-number="2"&gt;pprint(X_rv.distribution)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb6-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;lt;&lt;/span&gt;pymc3.distributions.continuous.Normal &lt;span class="bu"&gt;object&lt;/span&gt; at &lt;span class="bn"&gt;0x7f5d1796e908&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-2" data-line-number="2"&gt;&lt;span class="op"&gt;&amp;lt;&lt;/span&gt;pymc3.distributions.continuous.Normal &lt;span class="bu"&gt;object&lt;/span&gt; at &lt;span class="bn"&gt;0x7f5d17b10208&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-3" data-line-number="3"&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;Distribution&lt;/code&gt; objects loosely represents a measure, holding distribution parameters (e.g. mean and standard deviation &lt;code&gt;mu_X&lt;/code&gt;, &lt;code&gt;sd_X&lt;/code&gt;) and constructing the appropriate conditional log likelihoods–from which the model’s total log likelihood is later derived. The distribution parameters and log-likelihoods are Theano &lt;code&gt;TensorVariable&lt;/code&gt;s–including other PyMC3-derived &lt;code&gt;TensorVariable&lt;/code&gt;s corresponding to (the output of) random variables.&lt;/p&gt;
&lt;p&gt;Again, since objects derived via algebraic manipulation of random variables are not themselves random variables within the framework of PyMC3, objects like &lt;code&gt;Z_rv&lt;/code&gt; do not have a &lt;code&gt;Distribution&lt;/code&gt; attribute. The mechanics described here provide a means for supporting terms like &lt;code&gt;Z_rv&lt;/code&gt; with the appropriate “derived” distribution.&lt;/p&gt;
&lt;p&gt;To start, we’ll have to dive deeper into the graph aspects of Theano.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="random-variables-in-graphs" class="level1"&gt;
&lt;h1&gt;Random Variables in Graphs&lt;/h1&gt;
&lt;p&gt;The Theano graph representing &lt;span class="math inline"&gt;\(\eqref{eq:norm_conv_model}\)&lt;/span&gt; consists of linear/tensor algebra operations–under the interface of &lt;code&gt;theano.gof.op.Op&lt;/code&gt;–on &lt;code&gt;TensorVariable&lt;/code&gt;s. For our example in &lt;a href="#pymc3_model"&gt;pymc3_model&lt;/a&gt;, a textual representation is given in &lt;a href="#Z_rv_debugprint"&gt;Z_rv_debugprint&lt;/a&gt; and a graphical form in &lt;a href="#fig:norm_sum_graph"&gt;fig:norm_sum_graph&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb7"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb7-1" data-line-number="1"&gt;tt.printing.debugprint(Z_rv)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="text"&gt;&lt;code&gt;Elemwise{add,no_inplace} [id A] &amp;#39;&amp;#39;
 |X_rv [id B]
 |Y_rv [id C]

&lt;/code&gt;&lt;/pre&gt;
&lt;figure id="fig:norm_sum_graph"&gt;
&lt;img src="https://brandonwillard.github.io/figures/Z_rv.png" alt="Graph of Z_rv for the PyMC3 model in 2. " /&gt;
&lt;figcaption&gt;
Graph of &lt;code&gt;Z_rv&lt;/code&gt; for the PyMC3 model in &lt;a href="#org7c56540"&gt;2&lt;/a&gt;.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;At present, PyMC3 (version &lt;code&gt;print(pm.__version__)&lt;/code&gt; 3.3) does not make very consistent use of Theano’s graph objects. For instance, notice how the dependent parameters &lt;code&gt;mu_X&lt;/code&gt; and &lt;code&gt;sd_X&lt;/code&gt; are not present in the model’s graph (e.g. &lt;a href="#fig:norm_sum_graph"&gt;fig:norm_sum_graph&lt;/a&gt;). We know that &lt;code&gt;X_rv&lt;/code&gt; and &lt;code&gt;Y_rv&lt;/code&gt; are PyMC3 random variables, but what we see in the graph is only their representations as sampled scalar/vector/matrix/tensor values. In other words, where &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt; symbolize random variables and &lt;span class="math inline"&gt;\(x \sim X\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(y \sim Y\)&lt;/span&gt; their samples, we have a graph expressing only &lt;span class="math inline"&gt;\(z = x + y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;What we need for higher-level work is a graph of &lt;span class="math inline"&gt;\(Z = X + Y\)&lt;/span&gt; that includes every term involved. This is true for graphs representing a model’s measure/log-likelihood &lt;strong&gt;and&lt;/strong&gt; its sampled values. The former is essentially covered by the log-likelihood graphs we can already produce using the PyMC3 model objects. It’s the latter that we’ll establish here, since it sets the stage for applications of numerous techniques in statistics and probability theory.&lt;/p&gt;
&lt;p&gt;One way to produce graphs that represent the full probabilistic model is to formalize the notion of random variables using the Theano API. Basically, if we want to include the relationships between distribution parameters and sampled variables, &lt;strong&gt;we need an &lt;code&gt;Op&lt;/code&gt; that represents random variables and/or the act of sampling&lt;/strong&gt;. &lt;code&gt;theano.tensor.raw_random.RandomFunction&lt;/code&gt; does exactly this; although it represents the concept of a sampling action and not exactly a random measure.&lt;/p&gt;
&lt;p&gt;Nonetheless, using &lt;code&gt;RandomFunction&lt;/code&gt;, we can replace nodes corresponding to PyMC3 random variables with newly constructed &lt;code&gt;Op&lt;/code&gt; nodes.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;We can produce the types of graphs described above through conversion of existing PyMC3 models.&lt;/p&gt;
&lt;p&gt;In order to perform any manipulations on our model’s graph, we need to create a Theano &lt;code&gt;theano.gof.FunctionGraph&lt;/code&gt; object. We create a utility function in &lt;a href="#model_graph_fn"&gt;model_graph_fn&lt;/a&gt; that constructs a &lt;code&gt;FunctionGraph&lt;/code&gt; from a PyMC3 model.&lt;/p&gt;
&lt;div class="sourceCode" id="cb9"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb9-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano.gof &lt;span class="im"&gt;import&lt;/span&gt; FunctionGraph, Feature, NodeFinder&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano.gof.graph &lt;span class="im"&gt;import&lt;/span&gt; inputs &lt;span class="im"&gt;as&lt;/span&gt; tt_inputs, clone_get_equiv&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-4" data-line-number="4"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; model_graph(pymc_model, derived_vars&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-6" data-line-number="6"&gt;    model &lt;span class="op"&gt;=&lt;/span&gt; pm.modelcontext(pymc_model)&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-8" data-line-number="8"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; derived_vars &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-9" data-line-number="9"&gt;        model_outs &lt;span class="op"&gt;=&lt;/span&gt; derived_vars&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-10" data-line-number="10"&gt;    &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-11" data-line-number="11"&gt;        model_outs &lt;span class="op"&gt;=&lt;/span&gt; [o.logpt &lt;span class="cf"&gt;for&lt;/span&gt; o &lt;span class="kw"&gt;in&lt;/span&gt; model.observed_RVs]&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-13" data-line-number="13"&gt;    model_inputs &lt;span class="op"&gt;=&lt;/span&gt; [inp &lt;span class="cf"&gt;for&lt;/span&gt; inp &lt;span class="kw"&gt;in&lt;/span&gt; tt_inputs(model_outs)]&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-14" data-line-number="14"&gt;    &lt;span class="co"&gt;# if not isinstance(inp, theano.gof.graph.Constant)]&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-16" data-line-number="16"&gt;    model_memo &lt;span class="op"&gt;=&lt;/span&gt; clone_get_equiv(model_inputs, model_outs,&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-17" data-line-number="17"&gt;                                 copy_orphans&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-19" data-line-number="19"&gt;    fg_features &lt;span class="op"&gt;=&lt;/span&gt; [&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-20" data-line-number="20"&gt;        NodeFinder(),&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-21" data-line-number="21"&gt;    ]&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-22" data-line-number="22"&gt;    model_fg &lt;span class="op"&gt;=&lt;/span&gt; FunctionGraph([model_memo[i] &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; model_inputs],&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-23" data-line-number="23"&gt;                             [model_memo[i] &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; model_outs],&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-24" data-line-number="24"&gt;                             clone&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;, features&lt;span class="op"&gt;=&lt;/span&gt;fg_features)&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-25" data-line-number="25"&gt;    model_fg.memo &lt;span class="op"&gt;=&lt;/span&gt; model_memo&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-26" data-line-number="26"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-27" data-line-number="27"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; model_fg&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When cloning the graph with &lt;code&gt;theano.gof.graph.clone_get_equiv&lt;/code&gt; in &lt;code&gt;model_graph&lt;/code&gt;, we lose the &lt;code&gt;FreeRV.distribution&lt;/code&gt; attribute–among others. Since those attributes hold all the information required to construct our &lt;code&gt;RandomFunction&lt;/code&gt; &lt;code&gt;Op&lt;/code&gt;s, we’ll need to find a way to preserve it.&lt;/p&gt;
&lt;p&gt;This can be accomplished by overriding the default Theano &lt;code&gt;clone&lt;/code&gt; function inherited by the PyMC3 random variable classes.&lt;/p&gt;
&lt;div class="sourceCode" id="cb10"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb10-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; types&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; copy &lt;span class="im"&gt;import&lt;/span&gt; copy&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-4" data-line-number="4"&gt;pymc_rv_types &lt;span class="op"&gt;=&lt;/span&gt; (pm.model.FreeRV, pm.model.ObservedRV, pm.model.TransformedRV)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-6" data-line-number="6"&gt;pymc_rv_attrs &lt;span class="op"&gt;=&lt;/span&gt; [&lt;span class="st"&gt;&amp;#39;dshape&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;dsize&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;distribution&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;logp_elemwiset&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-7" data-line-number="7"&gt;                 &lt;span class="st"&gt;&amp;#39;logp_sum_unscaledt&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;logp_nojac_unscaledt&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;total_size&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-8" data-line-number="8"&gt;                 &lt;span class="st"&gt;&amp;#39;scaling&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;missing_values&amp;#39;&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-10" data-line-number="10"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; rv_type &lt;span class="kw"&gt;in&lt;/span&gt; pymc_rv_types:&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-12" data-line-number="12"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;hasattr&lt;/span&gt;(rv_type, &lt;span class="st"&gt;&amp;#39;__clone&amp;#39;&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-13" data-line-number="13"&gt;        rv_type.__clone &lt;span class="op"&gt;=&lt;/span&gt; rv_type.clone&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-14" data-line-number="14"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-15" data-line-number="15"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; pymc_rv_clone(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-16" data-line-number="16"&gt;        cp &lt;span class="op"&gt;=&lt;/span&gt; rv_type.__clone(&lt;span class="va"&gt;self&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-17" data-line-number="17"&gt;        &lt;span class="cf"&gt;for&lt;/span&gt; attr &lt;span class="kw"&gt;in&lt;/span&gt; pymc_rv_attrs:&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-18" data-line-number="18"&gt;            &lt;span class="bu"&gt;setattr&lt;/span&gt;(cp, attr, copy(&lt;span class="bu"&gt;getattr&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;, attr, &lt;span class="va"&gt;None&lt;/span&gt;)))&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-19" data-line-number="19"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-20" data-line-number="20"&gt;        &lt;span class="co"&gt;# Allow a cloned rv to inherit the context&amp;#39;s model?&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-21" data-line-number="21"&gt;        &lt;span class="co"&gt;# try:&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-22" data-line-number="22"&gt;        &lt;span class="co"&gt;#     cp.model = pm.Model.get_context()&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-23" data-line-number="23"&gt;        &lt;span class="co"&gt;# except TypeError:&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-24" data-line-number="24"&gt;        &lt;span class="co"&gt;#     pass&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-25" data-line-number="25"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-26" data-line-number="26"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(cp, &lt;span class="st"&gt;&amp;#39;model&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;None&lt;/span&gt;) &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-27" data-line-number="27"&gt;            cp.model &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;getattr&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;model&amp;#39;&lt;/span&gt;, &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-28" data-line-number="28"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-29" data-line-number="29"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; cp&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-30" data-line-number="30"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-31" data-line-number="31"&gt;    rv_type.clone &lt;span class="op"&gt;=&lt;/span&gt; pymc_rv_clone&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, we can produce a proper &lt;code&gt;FunctionGraph&lt;/code&gt; from our PyMC3 model.&lt;/p&gt;
&lt;div class="sourceCode" id="cb11"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb11-1" data-line-number="1"&gt;Z_fgraph_tt &lt;span class="op"&gt;=&lt;/span&gt; model_graph(conv_model, derived_vars&lt;span class="op"&gt;=&lt;/span&gt;[Z_rv])&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With a &lt;code&gt;FunctionGraph&lt;/code&gt; at our disposal, we can use the graph manipulation tools provided by Theano to replace the PyMC3 &lt;code&gt;TensorVariable&lt;/code&gt;s used to represent random variables with corresponding Theano &lt;code&gt;RandomFunction&lt;/code&gt;s that represent the &lt;strong&gt;act of sampling&lt;/strong&gt; to produce said random variables.&lt;/p&gt;
&lt;p&gt;We can use a simple mapping between Pymc3 random variable nodes and &lt;code&gt;RandomFunction&lt;/code&gt; to specify the desired replacements. Fortunately, this isn’t too difficult, since &lt;code&gt;RandomFunction&lt;/code&gt; already supports numerous Numpy-provided random distributions–covering much of the same ground as the PyMC3 distributions. Otherwise, the rest of the work involves mapping distribution parameters.&lt;/p&gt;
&lt;p&gt;Also, &lt;code&gt;RandomFunction&lt;/code&gt; requires a &lt;code&gt;RandomStream&lt;/code&gt;, which it uses to track the sampler state. For our purely symbolic purposes, the stream object is not immediately useful, but it does–in the end–provide a sample-able graph as a nice side-effect. We demonstrate the PyMC3 random variable-to-&lt;code&gt;RandomFunction&lt;/code&gt; translation in &lt;a href="#random_op_mapping"&gt;random_op_mapping&lt;/a&gt; using only a single mapping.&lt;/p&gt;
&lt;div class="sourceCode" id="cb12"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb12-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano.tensor.raw_random &lt;span class="im"&gt;import&lt;/span&gt; RandomFunction&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-3" data-line-number="3"&gt;pymc_theano_rv_equivs &lt;span class="op"&gt;=&lt;/span&gt; {&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-4" data-line-number="4"&gt;    pm.Normal:&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-5" data-line-number="5"&gt;    &lt;span class="kw"&gt;lambda&lt;/span&gt; dist, rand_state:&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-6" data-line-number="6"&gt;    tt.raw_random.normal(rand_state, dist.shape.tolist(), dist.mu, dist.sd),&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-7" data-line-number="7"&gt;}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb13"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb13-1" data-line-number="1"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; create_theano_rvs(fgraph, clone&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;, rand_state&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-2" data-line-number="2"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot;Replace PyMC3 random variables with `RandomFunction` Ops.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-4" data-line-number="4"&gt;&lt;span class="co"&gt;    &lt;/span&gt;&lt;span class="al"&gt;TODO&lt;/span&gt;&lt;span class="co"&gt;: Could use a Theano graph `Feature` to trace--or even&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-5" data-line-number="5"&gt;&lt;span class="co"&gt;    replace--random variables.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-7" data-line-number="7"&gt;&lt;span class="co"&gt;    Parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-8" data-line-number="8"&gt;&lt;span class="co"&gt;    ----------&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-9" data-line-number="9"&gt;&lt;span class="co"&gt;    fgraph : FunctionGraph&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-10" data-line-number="10"&gt;&lt;span class="co"&gt;    A graph containing PyMC3 random variables.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-12" data-line-number="12"&gt;&lt;span class="co"&gt;    clone: bool, optional&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-13" data-line-number="13"&gt;&lt;span class="co"&gt;    Clone the original graph.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-14" data-line-number="14"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-15" data-line-number="15"&gt;&lt;span class="co"&gt;    rand_state : RandomStateType, optional&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-16" data-line-number="16"&gt;&lt;span class="co"&gt;    The Theano random state.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-17" data-line-number="17"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-18" data-line-number="18"&gt;&lt;span class="co"&gt;    Returns&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-19" data-line-number="19"&gt;&lt;span class="co"&gt;    -------&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-20" data-line-number="20"&gt;&lt;span class="co"&gt;    out : A cloned graph with random variables replaced and a `memo` attribute.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-22" data-line-number="22"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-23" data-line-number="23"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; clone:&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-24" data-line-number="24"&gt;        fgraph_, fgraph_memo_ &lt;span class="op"&gt;=&lt;/span&gt; fgraph.clone_get_equiv(attach_feature&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-25" data-line-number="25"&gt;        fgraph_.memo &lt;span class="op"&gt;=&lt;/span&gt; fgraph_memo_&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-26" data-line-number="26"&gt;    &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-27" data-line-number="27"&gt;        fgraph_ &lt;span class="op"&gt;=&lt;/span&gt; fgraph&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-28" data-line-number="28"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-29" data-line-number="29"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; rand_state &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-30" data-line-number="30"&gt;        rand_state &lt;span class="op"&gt;=&lt;/span&gt; theano.shared(np.random.RandomState())&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-31" data-line-number="31"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-32" data-line-number="32"&gt;    fgraph_replacements &lt;span class="op"&gt;=&lt;/span&gt; {}&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-33" data-line-number="33"&gt;    fgraph_new_inputs &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;set&lt;/span&gt;()&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-34" data-line-number="34"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-35" data-line-number="35"&gt;    &lt;span class="cf"&gt;for&lt;/span&gt; old_rv_i, old_rv &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;enumerate&lt;/span&gt;(fgraph_.inputs):&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-36" data-line-number="36"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(old_rv, pymc_rv_types):&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-37" data-line-number="37"&gt;            dist &lt;span class="op"&gt;=&lt;/span&gt; old_rv.distribution&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-38" data-line-number="38"&gt;            theano_rv_op &lt;span class="op"&gt;=&lt;/span&gt; pymc_theano_rv_equivs.get(&lt;span class="bu"&gt;type&lt;/span&gt;(dist), &lt;span class="va"&gt;None&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-39" data-line-number="39"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-40" data-line-number="40"&gt;            &lt;span class="cf"&gt;if&lt;/span&gt; theano_rv_op &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-41" data-line-number="41"&gt;                rng_tt, new_rv &lt;span class="op"&gt;=&lt;/span&gt; theano_rv_op(dist, rand_state)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-42" data-line-number="42"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-43" data-line-number="43"&gt;                &lt;span class="co"&gt;# Keep track of our replacements&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-44" data-line-number="44"&gt;                fgraph_replacements[old_rv] &lt;span class="op"&gt;=&lt;/span&gt; new_rv&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-45" data-line-number="45"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-46" data-line-number="46"&gt;                new_rv.name &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;~&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(old_rv.name)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-47" data-line-number="47"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-48" data-line-number="48"&gt;                new_rv_inputs &lt;span class="op"&gt;=&lt;/span&gt; [i &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; tt_inputs([new_rv])]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-49" data-line-number="49"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-50" data-line-number="50"&gt;                fgraph_new_inputs.update(new_rv_inputs)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-51" data-line-number="51"&gt;            &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-52" data-line-number="52"&gt;                &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt; could not be mapped to a random function&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(old_rv))&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-53" data-line-number="53"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-54" data-line-number="54"&gt;    fgraph_new_inputs_memo &lt;span class="op"&gt;=&lt;/span&gt; theano.gof.graph.clone_get_equiv(&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-55" data-line-number="55"&gt;        fgraph_new_inputs, &lt;span class="bu"&gt;list&lt;/span&gt;(fgraph_replacements.values()),&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-56" data-line-number="56"&gt;        copy_orphans&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-57" data-line-number="57"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-58" data-line-number="58"&gt;    &lt;span class="co"&gt;# Update our maps and new inputs to use the cloned objects&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-59" data-line-number="59"&gt;    fgraph_replacements &lt;span class="op"&gt;=&lt;/span&gt; {old_rv: fgraph_new_inputs_memo.pop(new_rv)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-60" data-line-number="60"&gt;                           &lt;span class="cf"&gt;for&lt;/span&gt; old_rv, new_rv &lt;span class="kw"&gt;in&lt;/span&gt; fgraph_replacements.items()}&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-61" data-line-number="61"&gt;    fgraph_new_inputs &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;set&lt;/span&gt;(&lt;span class="bu"&gt;map&lt;/span&gt;(fgraph_new_inputs_memo.pop, fgraph_new_inputs))&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-62" data-line-number="62"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-63" data-line-number="63"&gt;    &lt;span class="co"&gt;# What remains in `fgraph_new_inputs_memo` are the nodes between our desired&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-64" data-line-number="64"&gt;    &lt;span class="co"&gt;# inputs (i.e. the random variables&amp;#39; distribution parameters) and the old inputs&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-65" data-line-number="65"&gt;    &lt;span class="co"&gt;# (i.e. Theano `Variable`s corresponding to a sample of said random variables).&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-66" data-line-number="66"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-67" data-line-number="67"&gt;    _ &lt;span class="op"&gt;=&lt;/span&gt; [fgraph_.add_input(new_in) &lt;span class="cf"&gt;for&lt;/span&gt; new_in &lt;span class="kw"&gt;in&lt;/span&gt; fgraph_new_inputs&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-68" data-line-number="68"&gt;         &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(new_in, theano.gof.graph.Constant)]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-69" data-line-number="69"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-70" data-line-number="70"&gt;    &lt;span class="co"&gt;# _ = [fgraph_.add_input(new_in) for new_in in fgraph_new_inputs_memo.values()]&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-71" data-line-number="71"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-72" data-line-number="72"&gt;    fgraph_.replace_all(fgraph_replacements.items())&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-73" data-line-number="73"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-74" data-line-number="74"&gt;    &lt;span class="co"&gt;# The replace method apparently doesn&amp;#39;t remove the old inputs...&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-75" data-line-number="75"&gt;    _ &lt;span class="op"&gt;=&lt;/span&gt; [fgraph_.inputs.remove(old_rv) &lt;span class="cf"&gt;for&lt;/span&gt; old_rv &lt;span class="kw"&gt;in&lt;/span&gt; fgraph_replacements.keys()]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-76" data-line-number="76"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-77" data-line-number="77"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; fgraph_&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb14"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb14-1" data-line-number="1"&gt;Z_fgraph_rv_tt &lt;span class="op"&gt;=&lt;/span&gt; create_theano_rvs(Z_fgraph_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-3" data-line-number="3"&gt;tt.printing.debugprint(Z_fgraph_rv_tt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="text"&gt;&lt;code&gt;Elemwise{add,no_inplace} [id A] &amp;#39;&amp;#39;   10
 |RandomFunction{normal}.1 [id B] &amp;#39;~X_rv&amp;#39;   9
 | |&amp;lt;RandomStateType&amp;gt; [id C]
 | |Elemwise{Cast{int64}} [id D] &amp;#39;&amp;#39;   8
 | | |MakeVector{dtype=&amp;#39;int8&amp;#39;} [id E] &amp;#39;&amp;#39;   7
 | |   |TensorConstant{1} [id F]
 | |mu_X [id G]
 | |Elemwise{mul,no_inplace} [id H] &amp;#39;&amp;#39;   6
 |   |InplaceDimShuffle{x} [id I] &amp;#39;&amp;#39;   5
 |   | |TensorConstant{1.0} [id J]
 |   |sd_X [id K]
 |RandomFunction{normal}.1 [id L] &amp;#39;~Y_rv&amp;#39;   4
   |&amp;lt;RandomStateType&amp;gt; [id C]
   |Elemwise{Cast{int64}} [id M] &amp;#39;&amp;#39;   3
   | |MakeVector{dtype=&amp;#39;int8&amp;#39;} [id N] &amp;#39;&amp;#39;   2
   |   |TensorConstant{1} [id F]
   |mu_Y [id O]
   |Elemwise{mul,no_inplace} [id P] &amp;#39;&amp;#39;   1
     |InplaceDimShuffle{x} [id Q] &amp;#39;&amp;#39;   0
     | |TensorConstant{1.0} [id J]
     |sd_Y [id R]

&lt;/code&gt;&lt;/pre&gt;
&lt;figure id="fig:random_op_mapping_exa_graph"&gt;
&lt;img src="https://brandonwillard.github.io/figures/Z_fgraph_rv_tt.png" alt="Graph of Z = X + Y using an Op to represent sampling/a random variable. " /&gt;
&lt;figcaption&gt;
Graph of &lt;span class="math inline"&gt;\(Z = X + Y\)&lt;/span&gt; using an &lt;code&gt;Op&lt;/code&gt; to represent sampling/a random variable.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;Illustrations of the transformed graphs given in &lt;a href="#random_op_mapping_exa"&gt;random_op_mapping_exa&lt;/a&gt; and &lt;a href="#fig:random_op_mapping_exa_graph"&gt;fig:random_op_mapping_exa_graph&lt;/a&gt; show the full extent of our simple example model and provide a context in which to perform higher-level manipulations.&lt;/p&gt;
&lt;p&gt;With a graph representing the relevant terms and relationships, we can implement the convolution simplification/transformation/optimization. For instance, as shown in &lt;a href="#rv_find_nodes"&gt;rv_find_nodes&lt;/a&gt;, we can now easily query random function/variable nodes in a graph.&lt;/p&gt;
&lt;div class="sourceCode" id="cb16"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb16-1" data-line-number="1"&gt;&lt;span class="co"&gt;# Using a `FunctionGraph` &amp;quot;feature&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-2" data-line-number="2"&gt;Z_fgraph_rv_tt.attach_feature(NodeFinder())&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-4" data-line-number="4"&gt;&lt;span class="co"&gt;# The fixed `TensorType` is unnecessarily restrictive.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-5" data-line-number="5"&gt;rf_normal_type &lt;span class="op"&gt;=&lt;/span&gt; RandomFunction(&lt;span class="st"&gt;&amp;#39;normal&amp;#39;&lt;/span&gt;, tt.TensorType(&lt;span class="st"&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;, (&lt;span class="va"&gt;True&lt;/span&gt;,)))&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-6" data-line-number="6"&gt;rf_nodes &lt;span class="op"&gt;=&lt;/span&gt; Z_fgraph_rv_tt.get_nodes(rf_normal_type)&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-8" data-line-number="8"&gt;&lt;span class="co"&gt;#&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-9" data-line-number="9"&gt;&lt;span class="co"&gt;# or, more generally,...&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-10" data-line-number="10"&gt;&lt;span class="co"&gt;#&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-11" data-line-number="11"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; get_random_nodes(fgraph):&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-12" data-line-number="12"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;list&lt;/span&gt;(&lt;span class="bu"&gt;filter&lt;/span&gt;(&lt;span class="kw"&gt;lambda&lt;/span&gt; x: &lt;span class="bu"&gt;isinstance&lt;/span&gt;(x.op, RandomFunction), fgraph.apply_nodes))&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-14" data-line-number="14"&gt;rf_nodes &lt;span class="op"&gt;=&lt;/span&gt; get_random_nodes(Z_fgraph_rv_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-16" data-line-number="16"&gt;tt.printing.debugprint(rf_nodes)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="text"&gt;&lt;code&gt;RandomFunction{normal}.0 [id A] &amp;#39;&amp;#39;
 |&amp;lt;RandomStateType&amp;gt; [id B]
 |Elemwise{Cast{int64}} [id C] &amp;#39;&amp;#39;
 | |MakeVector{dtype=&amp;#39;int8&amp;#39;} [id D] &amp;#39;&amp;#39;
 |   |TensorConstant{1} [id E]
 |mu_X [id F]
 |Elemwise{mul,no_inplace} [id G] &amp;#39;&amp;#39;
   |InplaceDimShuffle{x} [id H] &amp;#39;&amp;#39;
   | |TensorConstant{1.0} [id I]
   |sd_X [id J]
RandomFunction{normal}.1 [id A] &amp;#39;~X_rv&amp;#39;
RandomFunction{normal}.0 [id K] &amp;#39;&amp;#39;
 |&amp;lt;RandomStateType&amp;gt; [id B]
 |Elemwise{Cast{int64}} [id L] &amp;#39;&amp;#39;
 | |MakeVector{dtype=&amp;#39;int8&amp;#39;} [id M] &amp;#39;&amp;#39;
 |   |TensorConstant{1} [id E]
 |mu_Y [id N]
 |Elemwise{mul,no_inplace} [id O] &amp;#39;&amp;#39;
   |InplaceDimShuffle{x} [id P] &amp;#39;&amp;#39;
   | |TensorConstant{1.0} [id I]
   |sd_Y [id Q]
RandomFunction{normal}.1 [id K] &amp;#39;~Y_rv&amp;#39;

&lt;/code&gt;&lt;/pre&gt;
&lt;/section&gt;
&lt;section id="performing-high-level-simplifications" class="level1"&gt;
&lt;h1&gt;Performing High-level Simplifications&lt;/h1&gt;
&lt;p&gt;To apply optimizations like our simple convolution, we need to first identify the appropriate circumstances for its application. This means finding all sub-graphs for which we are able to replace existing nodes with a convolution node.&lt;/p&gt;
&lt;p&gt;Theano provides some &lt;a href="https://en.wikipedia.org/wiki/Unification_(computer_science)"&gt;unification&lt;/a&gt; tools that facilitate the search component. We’ll use those to implement an extremely restrictive form of our convolution.&lt;/p&gt;
&lt;div class="example" data-markdown=""&gt;
&lt;p&gt;In &lt;a href="#normal_conv_pattern"&gt;normal_conv_pattern&lt;/a&gt;, we create patterns for our expressions of interest that are unified against the elements in our graph and reified with a replacement expression. The patterns are expressed as tuples in a LISP-like fashion, e.g. &lt;code&gt;(add, 1, 2)&lt;/code&gt; corresponding to an unevaluated &lt;code&gt;add(1, 2)&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb18"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb18-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; operator &lt;span class="im"&gt;import&lt;/span&gt; attrgetter, itemgetter&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-4" data-line-number="4"&gt;&lt;span class="co"&gt;# &lt;/span&gt;&lt;span class="al"&gt;FIXME&lt;/span&gt;&lt;span class="co"&gt;: This fixed `TensorType` specification is restrictive.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-5" data-line-number="5"&gt;NormalRV &lt;span class="op"&gt;=&lt;/span&gt; RandomFunction(&lt;span class="st"&gt;&amp;#39;normal&amp;#39;&lt;/span&gt;, tt.TensorType(&lt;span class="st"&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;, (&lt;span class="va"&gt;True&lt;/span&gt;,)))&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-7" data-line-number="7"&gt;norm_conv_pat_tt &lt;span class="op"&gt;=&lt;/span&gt; [&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-8" data-line-number="8"&gt;    tt.gof.opt.PatternSub(&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-9" data-line-number="9"&gt;        &lt;span class="co"&gt;# Search expression pattern&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-10" data-line-number="10"&gt;      (tt.add,&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-11" data-line-number="11"&gt;       (NormalRV, &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;shp_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;sd_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-12" data-line-number="12"&gt;       (NormalRV, &lt;span class="st"&gt;&amp;#39;rs_y&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;shp_y&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;mu_y&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;sd_y&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-13" data-line-number="13"&gt;      ),&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-14" data-line-number="14"&gt;        &lt;span class="co"&gt;# Replacement expression&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-15" data-line-number="15"&gt;      (itemgetter(&lt;span class="dv"&gt;1&lt;/span&gt;), &lt;span class="co"&gt;#&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-16" data-line-number="16"&gt;       (NormalRV,&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-17" data-line-number="17"&gt;        &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-18" data-line-number="18"&gt;        &lt;span class="st"&gt;&amp;#39;shp_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-19" data-line-number="19"&gt;        (tt.add, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;mu_y&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-20" data-line-number="20"&gt;        (tt.sqrt, (tt.add, (tt.square, &lt;span class="st"&gt;&amp;#39;sd_x&amp;#39;&lt;/span&gt;), (tt.square, &lt;span class="st"&gt;&amp;#39;sd_y&amp;#39;&lt;/span&gt;))),&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-21" data-line-number="21"&gt;       )),&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-22" data-line-number="22"&gt;    ),&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-23" data-line-number="23"&gt;]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;itemgetter(1)&lt;/code&gt; applied to the replacement result is necessary because the &lt;code&gt;Op&lt;/code&gt; &lt;code&gt;RandomFunction&lt;/code&gt; returns two outputs and the second is the &lt;code&gt;TensorVariable&lt;/code&gt; corresponding to a sample from that random variable.&lt;/p&gt;
&lt;p&gt;We also need to specify exactly how the pattern matching and replacement are to be performed for the entire graph. Do we match a single sum of normal distributions or all of them? What happens when a replacement creates yet another sum of normals that can be reduced?&lt;/p&gt;
&lt;p&gt;In this case, we choose to apply the operation until it reaches a fixed point, i.e. until it produces no changes in the graph.&lt;/p&gt;
&lt;div class="sourceCode" id="cb19"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb19-1" data-line-number="1"&gt;norm_conv_opt_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.gof.opt.EquilibriumOptimizer(norm_conv_pat_tt,&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-2" data-line-number="2"&gt;                                                   max_use_ratio&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, we manually perform our Theano optimization.&lt;/p&gt;
&lt;div class="sourceCode" id="cb20"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb20-1" data-line-number="1"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; norm_conv_opt_tt.optimize(Z_fgraph_rv_tt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The optimization was applied within our graph, as evidenced by the single new &lt;code&gt;RandomFunction&lt;/code&gt; node.&lt;/p&gt;
&lt;div class="sourceCode" id="cb21"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb21-1" data-line-number="1"&gt;tt.printing.debugprint(Z_fgraph_rv_tt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="text"&gt;&lt;code&gt;RandomFunction{normal}.1 [id A] &amp;#39;&amp;#39;   11
 |&amp;lt;RandomStateType&amp;gt; [id B]
 |Elemwise{Cast{int64}} [id C] &amp;#39;&amp;#39;   10
 | |MakeVector{dtype=&amp;#39;int8&amp;#39;} [id D] &amp;#39;&amp;#39;   9
 |   |TensorConstant{1} [id E]
 |Elemwise{add,no_inplace} [id F] &amp;#39;&amp;#39;   8
 | |mu_X [id G]
 | |mu_Y [id H]
 |Elemwise{sqrt,no_inplace} [id I] &amp;#39;&amp;#39;   7
   |Elemwise{add,no_inplace} [id J] &amp;#39;&amp;#39;   6
     |Elemwise{sqr,no_inplace} [id K] &amp;#39;&amp;#39;   5
     | |Elemwise{mul,no_inplace} [id L] &amp;#39;&amp;#39;   4
     |   |InplaceDimShuffle{x} [id M] &amp;#39;&amp;#39;   3
     |   | |TensorConstant{1.0} [id N]
     |   |sd_X [id O]
     |Elemwise{sqr,no_inplace} [id P] &amp;#39;&amp;#39;   2
       |Elemwise{mul,no_inplace} [id Q] &amp;#39;&amp;#39;   1
         |InplaceDimShuffle{x} [id R] &amp;#39;&amp;#39;   0
         | |TensorConstant{1.0} [id N]
         |sd_Y [id S]

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Likewise, the resulting distribution terms in the optimized graph reflect the normal-normal random variable sum. Figure &lt;a href="#fig:norm_sum_merge_graph"&gt;fig:norm_sum_merge_graph&lt;/a&gt; shows the graph under our optimization.&lt;/p&gt;
&lt;div class="sourceCode" id="cb23"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb23-1" data-line-number="1"&gt;conv_rv_tt &lt;span class="op"&gt;=&lt;/span&gt; Z_fgraph_rv_tt.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;].owner&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-3" data-line-number="3"&gt;new_mu, new_sd &lt;span class="op"&gt;=&lt;/span&gt; conv_rv_tt.inputs[&lt;span class="dv"&gt;2&lt;/span&gt;:&lt;span class="dv"&gt;4&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-5" data-line-number="5"&gt;&lt;span class="co"&gt;# Test values of the original means/new moments&amp;#39; inputs&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-6" data-line-number="6"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;, &amp;#39;&lt;/span&gt;.join([&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt; = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(tt.pprint(o), o.tag.test_value)&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-7" data-line-number="7"&gt;                 &lt;span class="cf"&gt;for&lt;/span&gt; o &lt;span class="kw"&gt;in&lt;/span&gt; new_mu.owner.inputs]))&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-8" data-line-number="8"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(tt.pprint(new_mu))&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-10" data-line-number="10"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;, &amp;#39;&lt;/span&gt;.join([&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt; = &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(tt.pprint(o), o.tag.test_value)&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-11" data-line-number="11"&gt;                 &lt;span class="cf"&gt;for&lt;/span&gt; o &lt;span class="kw"&gt;in&lt;/span&gt; new_sd.owner.inputs]))&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-12" data-line-number="12"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(tt.pprint(new_sd))&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-14" data-line-number="14"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;&amp;#39;mean: &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="ch"&gt;\n&lt;/span&gt;&lt;span class="st"&gt;std. dev.: &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-15" data-line-number="15"&gt;    new_mu.tag.test_value,&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-16" data-line-number="16"&gt;    new_sd.tag.test_value))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="text"&gt;&lt;code&gt;mu_X = [0.], mu_Y = [1.]
(mu_X + mu_Y)
(sqr((TensorConstant{1.0} * sd_X)) + sqr((TensorConstant{1.0} * sd_Y))) = [1.25]
sqrt((sqr((TensorConstant{1.0} * sd_X)) + sqr((TensorConstant{1.0} * sd_Y))))
mean: [1.]
std. dev.: [1.11803399]

&lt;/code&gt;&lt;/pre&gt;
&lt;figure id="fig:norm_sum_merge_graph"&gt;
&lt;img src="https://brandonwillard.github.io/figures/Z_fgraph_opt_tt.png" alt="Graph of merged normal variables. " /&gt;
&lt;figcaption&gt;
Graph of merged normal variables.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/section&gt;
&lt;section id="generalizing-operations" class="level1"&gt;
&lt;h1&gt;Generalizing Operations&lt;/h1&gt;
&lt;p&gt;Our example above was admittedly too simple; for instance, what about scale and location transformed variables? Most models/graphs will consist of more elaborate manipulations of random variables, so it’s necessary that we account for as many basic manipulations, as well.&lt;/p&gt;
&lt;p&gt;We start by adding an optimization that lifts scale parameters into the arguments/parameters of a random variable. In other words,&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{gather*}
  X \sim N(\mu, \sigma^2) \\
  Z = a X \sim N\left(a \mu, (a \sigma)^2\right)
  \;.
\end{gather*}\]&lt;/span&gt;&lt;/p&gt;
&lt;div class="sourceCode" id="cb25"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb25-1" data-line-number="1"&gt;norm_conv_pat_tt &lt;span class="op"&gt;+=&lt;/span&gt; [&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-2" data-line-number="2"&gt;    tt.gof.opt.PatternSub(&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-3" data-line-number="3"&gt;        &lt;span class="co"&gt;# Search expression pattern&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-4" data-line-number="4"&gt;        (tt.mul,&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-5" data-line-number="5"&gt;         &lt;span class="st"&gt;&amp;#39;a_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-6" data-line-number="6"&gt;         (NormalRV, &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;shp_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;sd_x&amp;#39;&lt;/span&gt;)),&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-7" data-line-number="7"&gt;        &lt;span class="co"&gt;# Replacement expression&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-8" data-line-number="8"&gt;        (itemgetter(&lt;span class="dv"&gt;1&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-9" data-line-number="9"&gt;         (NormalRV,&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-10" data-line-number="10"&gt;          &lt;span class="co"&gt;# RNG&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-11" data-line-number="11"&gt;                &lt;span class="st"&gt;&amp;#39;rs_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-12" data-line-number="12"&gt;          &lt;span class="co"&gt;# Convolution shape&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-13" data-line-number="13"&gt;                &lt;span class="st"&gt;&amp;#39;shp_x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-14" data-line-number="14"&gt;          &lt;span class="co"&gt;# Convolution mean&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-15" data-line-number="15"&gt;                (tt.mul, &lt;span class="st"&gt;&amp;#39;a_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;mu_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-16" data-line-number="16"&gt;          &lt;span class="co"&gt;# Convolution std. dev.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-17" data-line-number="17"&gt;                (tt.mul, &lt;span class="st"&gt;&amp;#39;a_x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;sd_x&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-18" data-line-number="18"&gt;         )),&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-19" data-line-number="19"&gt;    )&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-20" data-line-number="20"&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-22" data-line-number="22"&gt;norm_conv_opt_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.gof.opt.EquilibriumOptimizer(&lt;/a&gt;
&lt;a class="sourceLine" id="cb25-23" data-line-number="23"&gt;    norm_conv_pat_tt, max_use_ratio&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The additional optimization is demonstrated in &lt;a href="#mat_mul_scaling_exa"&gt;mat_mul_scaling_exa&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb26"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb26-1" data-line-number="1"&gt;mu_X &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;mu_X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-2" data-line-number="2"&gt;mu_X.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;0.&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-3" data-line-number="3"&gt;sd_X &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;sd_X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-4" data-line-number="4"&gt;sd_X.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;1.&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-6" data-line-number="6"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model() &lt;span class="im"&gt;as&lt;/span&gt; conv_scale_model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-7" data-line-number="7"&gt;    X_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;X_rv&amp;#39;&lt;/span&gt;, mu_X, sd&lt;span class="op"&gt;=&lt;/span&gt;sd_X, shape&lt;span class="op"&gt;=&lt;/span&gt;(&lt;span class="dv"&gt;1&lt;/span&gt;,))&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-8" data-line-number="8"&gt;    Z_rv &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;5&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt; X_rv&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-10" data-line-number="10"&gt;Z_mul_tt &lt;span class="op"&gt;=&lt;/span&gt; model_graph(conv_scale_model, derived_vars&lt;span class="op"&gt;=&lt;/span&gt;[Z_rv])&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-11" data-line-number="11"&gt;Z_mul_rv &lt;span class="op"&gt;=&lt;/span&gt; create_theano_rvs(Z_mul_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-13" data-line-number="13"&gt;Z_mul_rv_merged &lt;span class="op"&gt;=&lt;/span&gt; Z_mul_rv.clone()&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-14" data-line-number="14"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb26-15" data-line-number="15"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; norm_conv_opt_tt.optimize(Z_mul_rv_merged)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href="#fig:scaled_random_sum_before"&gt;fig:scaled_random_sum_before&lt;/a&gt; and &lt;a href="#fig:scaled_random_sum_after"&gt;fig:scaled_random_sum_after&lt;/a&gt; demonstrate the a scaled normal random variable before and after the optimization, respectively.&lt;/p&gt;
&lt;figure id="fig:scaled_random_sum_before"&gt;
&lt;img src="https://brandonwillard.github.io/figures/Z_mul_rv.png" alt="Graph of a single term scaled in a normal-normal convolution. " /&gt;
&lt;figcaption&gt;
Graph of a single term scaled in a normal-normal convolution.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure id="fig:scaled_random_sum_after"&gt;
&lt;img src="https://brandonwillard.github.io/figures/Z_mul_rv_merged.png" alt="Graph of a single term scaled in a normal-normal convolution after the convolution optimization. " /&gt;
&lt;figcaption&gt;
Graph of a single term scaled in a normal-normal convolution after the convolution optimization.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/section&gt;
&lt;section id="challenges" class="level1"&gt;
&lt;h1&gt;Challenges&lt;/h1&gt;
&lt;p&gt;If we change the dimensions of our example above, the pattern employed by our scaling optimization will not match. To fix this, we can generalize the form of our &lt;code&gt;RandomFunction&lt;/code&gt; operator so that it includes more cases of broadcastable dimensions–instead of only &lt;code&gt;(True, )&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We could also extend the reach of our &lt;code&gt;PatternSub&lt;/code&gt;s; however, this direction introduces more complexity into the process of writing optimizations and provides no foreseeable benefit elsewhere.&lt;/p&gt;
&lt;p&gt;More generally, one of the major challenges in this kind of work is due to the design of &lt;code&gt;RandomFunction&lt;/code&gt;; its type is dependent on a &lt;code&gt;TensorType&lt;/code&gt; parameter that requires an array of “broadcast” dimensions.&lt;/p&gt;
&lt;p&gt;This situation arises–in part–from PyMC3, Theano, and NumPy’s use of a “size” parameter in combination with random variable dimensions inferred from distribution parameters. A few outstanding &lt;a href="https://github.com/pymc-devs/pymc3/pull/1125"&gt;PyMC3 issues seem to revolve&lt;/a&gt; around the interactions between these elements.&lt;/p&gt;
&lt;p&gt;The size parameter is like a sample size, but with all the samples considered together as a single tensor (e.g. each sample of a multivariate normal random variable, say, acting as a column in a matrix). The size parameter is independent of a random variable’s parameters’ sizes (e.g. dimensions of a mean and covariance), but, together, the size and distribution parameters effectively compose the size/dimension of a random variable’s support (e.g. the matrix in the above example is the resulting random variable).&lt;/p&gt;
&lt;p&gt;Needless to say, PyMC3 and Theano’s terms–and their relation to mathematical notions–are a bit confusing, and likely driven more by software design choices than the mathematical frameworks in use. However, those design choices significantly affect our ability to manipulate graphs and express common mathematical notions. For instance, these terms and design choices put greater demand on the graph manipulation steps, due to the ambiguous dimensions of the elements involved.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="next-steps" class="level1"&gt;
&lt;h1&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;In a follow-up, I’ll introduce a new &lt;code&gt;Op&lt;/code&gt; that overcomes some of the dimensionality issues and allows for much easier graph manipulation. It replaces &lt;code&gt;RandomFunction&lt;/code&gt; with a single &lt;code&gt;Op&lt;/code&gt; for each distribution type and [re]moves the type specifier from the definition of the &lt;code&gt;Op&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Essentially, the &lt;code&gt;TensorType&lt;/code&gt; argument to the &lt;code&gt;RandomFunction&lt;/code&gt; constructor is moved into &lt;code&gt;RandomFunction&lt;/code&gt;’s &lt;code&gt;make_node&lt;/code&gt; method and, thus, generated/inferred from the symbolic inputs.&lt;/p&gt;
&lt;p&gt;To be clear, we’re talking about two distinct aspects of &lt;code&gt;RandomFunction&lt;/code&gt;: one is the &lt;code&gt;NormalRV = RandomFunction('normal', TensorType('float64', bcast))&lt;/code&gt; step, in which we &lt;strong&gt;create the &lt;code&gt;Op&lt;/code&gt;&lt;/strong&gt; corresponding to a specific type of normal random variable, and the other in which we &lt;strong&gt;use the &lt;code&gt;Op&lt;/code&gt;&lt;/strong&gt; (e.g. &lt;code&gt;NormalRV(rng, 1, 2)&lt;/code&gt;)–to, say, produce a tensor variable corresponding to an instance of said random variable.&lt;/p&gt;
&lt;p&gt;This distinction is important for pattern matching because &lt;code&gt;NormalRV&lt;/code&gt;, as defined above, isn’t very general and mostly due to the &lt;code&gt;TensorType('float64', bcast))&lt;/code&gt; covering only some Theano tensor types (i.e. those that match the fixed broadcast dimensions specified by &lt;code&gt;bcast&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;As stated previously, there have been real difficulties with the handling of shape and type information in PyMC3 (see &lt;a href="https://github.com/pymc-devs/pymc3/pull/1125"&gt;PyMC3 PR 1125&lt;/a&gt;). These problems are related to the same concerns involving &lt;code&gt;TensorType&lt;/code&gt;s. In refactoring the type information requirement for &lt;code&gt;RandomFunction&lt;/code&gt;, we’ll end up addressing those PyMC3 issues as well.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="bibliography" class="level1"&gt;
&lt;h1&gt;Bibliography&lt;/h1&gt;
&lt;p&gt;&lt;a id="WillardRoleSymbolicComputation2017"&gt;&lt;/a&gt;[WillardRoleSymbolicComputation2017] Willard, A Role for Symbolic Computation in the General Estimation of Statistical Models, &lt;i&gt;Brandon T. Willard&lt;/i&gt;, (2017). &lt;a href="https://brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html"&gt;link&lt;/a&gt;. &lt;a href="#4407b21e48ab9ff17c017e8d62684725"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content><category term="pymc3"></category><category term="theano"></category><category term="statistics"></category><category term="symbolic computation"></category><category term="python"></category><category term="probability theory"></category></entry><entry><title>More Proximal Estimation</title><link href="https://brandonwillard.github.io/more-proximal-estimation.html" rel="alternate"></link><published>2017-03-06T00:00:00-06:00</published><updated>2017-03-06T00:00:00-06:00</updated><author><name>Brandon T. Willard</name></author><id>tag:brandonwillard.github.io,2017-03-06:/more-proximal-estimation.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon T. Willard" /&gt;
  &lt;title&gt;More Proximal Estimation&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;style type="text/css"&gt;
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  &lt;/style&gt;
  &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;More Proximal Estimation&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon T. Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2017–03–06&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;section id="introduction" class="level1"&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The focal point of this short exposition will be an elaboration of the basic &lt;span class="math inline"&gt;\(\ell_1\)&lt;/span&gt; penalization problem discussed in &lt;span class="citation" data-cites="willard_role_2017"&gt;Willard (2017)&lt;/span&gt;, &lt;span class="math display"&gt;\[\begin{equation}
\operatorname*{argmin}_{\beta} \left\{
  \frac{1}{2} \|y - X \beta\|^2_2
    + \lambda \|\beta\|_1
  \right\}
  \;.
  \label{eq:lasso}
\end{equation}\]&lt;/span&gt; We continue our discussion on topics concerning automation and symbolic computation in Theano &lt;span class="citation" data-cites="bergstra_theano_2010"&gt;(Bergstra et al. 2010)&lt;/span&gt;, as well as the mathematical methodology we believe is suitable for such implementations. Again, our framing of the problem is in terms of “proximal methods” &lt;span class="citation" data-cites="parikh_proximal_2014 combettes_proximal_2011"&gt;(Parikh and Boyd 2014; Combettes and Pesquet 2011)&lt;/span&gt;. Along the way we propose one simple means of placing the well-known technique of coordinate descent within the scope of proximal methods via a general property of proximal operators. These efforts are a continued outgrowth of our work in &lt;span class="citation" data-cites="polson_proximal_2015"&gt;Polson, Scott, and Willard (2015)&lt;/span&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="proximal-and-computational-components" class="level1"&gt;
&lt;h1&gt;Proximal and Computational Components&lt;/h1&gt;
&lt;p&gt;First, we [re]-introduce the workhorse of proximal methods: the &lt;em&gt;proximal operator&lt;/em&gt;.&lt;/p&gt;
&lt;div class="definition" data-markdown="" data-title-name="[Proximal Operator]"&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
\operatorname*{prox}_{\phi}(x) =
    \operatorname*{argmin}_{z} \left\{
    \frac{1}{2} \left(z - x\right)^2 + \phi(z)
    \right\}
    \;.
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Inspired by Equation &lt;span class="math inline"&gt;\(\eqref{eq:lasso}\)&lt;/span&gt;, we produce a toy dataset as follows:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano &lt;span class="im"&gt;import&lt;/span&gt; shared &lt;span class="im"&gt;as&lt;/span&gt; tt_shared&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" data-line-number="3"&gt;M &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;50&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" data-line-number="4"&gt;M_nonzero &lt;span class="op"&gt;=&lt;/span&gt; M &lt;span class="op"&gt;*&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="op"&gt;//&lt;/span&gt; &lt;span class="dv"&gt;10&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" data-line-number="6"&gt;beta_true &lt;span class="op"&gt;=&lt;/span&gt; np.zeros(M)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-7" data-line-number="7"&gt;beta_true[:M_nonzero] &lt;span class="op"&gt;=&lt;/span&gt; np.exp(&lt;span class="op"&gt;-&lt;/span&gt;np.arange(M_nonzero)) &lt;span class="op"&gt;*&lt;/span&gt; &lt;span class="dv"&gt;100&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-9" data-line-number="9"&gt;N &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;int&lt;/span&gt;(np.alen(beta_true) &lt;span class="op"&gt;*&lt;/span&gt; &lt;span class="fl"&gt;0.4&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-10" data-line-number="10"&gt;X &lt;span class="op"&gt;=&lt;/span&gt; np.random.randn(N, M)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-11" data-line-number="11"&gt;mu_true &lt;span class="op"&gt;=&lt;/span&gt; X.dot(beta_true)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-12" data-line-number="12"&gt;y &lt;span class="op"&gt;=&lt;/span&gt; mu_true &lt;span class="op"&gt;+&lt;/span&gt; sc.stats.norm.rvs(np.zeros(N), scale&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-14" data-line-number="14"&gt;X_tt &lt;span class="op"&gt;=&lt;/span&gt; tt_shared(X, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;X&amp;#39;&lt;/span&gt;, borrow&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-15" data-line-number="15"&gt;y_tt &lt;span class="op"&gt;=&lt;/span&gt; tt_shared(y, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, borrow&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-17" data-line-number="17"&gt;&lt;span class="co"&gt;# Estimation starting parameters...&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-18" data-line-number="18"&gt;beta_0 &lt;span class="op"&gt;=&lt;/span&gt; np.zeros(X.shape[&lt;span class="dv"&gt;1&lt;/span&gt;]).astype(&lt;span class="st"&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-19" data-line-number="19"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-20" data-line-number="20"&gt;&lt;span class="co"&gt;# Gradient [starting] step size&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-21" data-line-number="21"&gt;alpha_0 &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;1.&lt;/span&gt; &lt;span class="op"&gt;/&lt;/span&gt; np.linalg.norm(X, &lt;span class="dv"&gt;2&lt;/span&gt;)&lt;span class="op"&gt;**&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-22" data-line-number="22"&gt;&lt;span class="co"&gt;# np.linalg.matrix_rank(X)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-23" data-line-number="23"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-24" data-line-number="24"&gt;&lt;span class="co"&gt;# Regularization value heuristic&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-25" data-line-number="25"&gt;&lt;span class="co"&gt;# beta_ols = np.linalg.lstsq(X, y)[0]&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-26" data-line-number="26"&gt;&lt;span class="co"&gt;# lambda_max = 0.1 * np.linalg.norm(beta_ols, np.inf)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-27" data-line-number="27"&gt;lambda_max &lt;span class="op"&gt;=&lt;/span&gt; np.linalg.norm(X.T.dot(y), np.inf)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As in &lt;span class="citation" data-cites="willard_role_2017"&gt;Willard (2017)&lt;/span&gt;, we can start with a model defined within a system like PyMC3 &lt;span class="citation" data-cites="salvatier_probabilistic_2016"&gt;(Salvatier, Wiecki, and Fonnesbeck 2016)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" data-line-number="1"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model() &lt;span class="im"&gt;as&lt;/span&gt; lasso_model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" data-line-number="2"&gt;    beta_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Laplace(&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;0&lt;/span&gt;, b&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-3" data-line-number="3"&gt;                         shape&lt;span class="op"&gt;=&lt;/span&gt;X.shape[&lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-4" data-line-number="4"&gt;    y_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;X_tt.dot(beta_rv), sd&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-5" data-line-number="5"&gt;                     shape&lt;span class="op"&gt;=&lt;/span&gt;y.shape[&lt;span class="dv"&gt;0&lt;/span&gt;], observed&lt;span class="op"&gt;=&lt;/span&gt;y_tt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this setting one might then arrive at the necessary steps toward estimation automatically (i.e. identify the underlying &lt;span class="math inline"&gt;\(\ell_1\)&lt;/span&gt; estimation problem). We discuss this more in &lt;span class="citation" data-cites="willard_role_2017"&gt;Willard (2017)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For simplicity, we’ll just assume that all components of the estimation problem are know–i.e. loss and penalty functions. The proximal operator that arises in this standard example is the &lt;em&gt;soft thresholding&lt;/em&gt; operator. In Theano, it can be implemented with the following:&lt;/p&gt;
&lt;div class="sourceCode" id="cb3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb3-1" data-line-number="1"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; tt_soft_threshold(beta_, lambda_):&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-2" data-line-number="2"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; tt.sgn(beta_) &lt;span class="op"&gt;*&lt;/span&gt; tt.maximum(tt.abs_(beta_) &lt;span class="op"&gt;-&lt;/span&gt; lambda_, &lt;span class="dv"&gt;0&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="remark" data-markdown="" data-title-name=""&gt;
&lt;p&gt;This operator can take other forms and the one used here is not particularly special. For instance, the &lt;code&gt;maximum&lt;/code&gt; can be replaced by other conditional-like statements–such as &lt;span class="math display"&gt;\[\begin{equation*}
\operatorname{S}(z, \lambda) =
    \begin{cases}
     {\mathop{\mathrm{sgn}}}(\beta) (\beta - \lambda) &amp;amp; \beta &amp;gt; \lambda
     \\
     0 &amp;amp; \text{otherwise}
    \end{cases}
    \;.
\end{equation*}\]&lt;/span&gt; If we were to–say–multiply the output of this operator with another more difficult to compute result, then we might also wish to “optimize” this implementation by pushing the multiplication into the definition of the operator and altogether avoid its computation in the &lt;span class="math inline"&gt;\(\beta \leq \lambda\)&lt;/span&gt; case.&lt;/p&gt;
&lt;p&gt;Barring any reuses of this quantity, or a need to preserve undefined results produced by an expensive product with zero, we would really like a “compiler” to make such an optimization itself. It isn’t clear how a standard compiler–or interpreter/hybrid–could safely make this optimization, whereas it does seem more reasonable as a symbolic/Theano optimization.&lt;/p&gt;
&lt;p&gt;Optimizations like this are–I think–a necessary step to enable expressive, generalized methods and truly rapid prototyping at the math level.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now, assuming that we’ve obtained the relevant loss and penalty functions–for example, in PyMC3–then we can proceed by setting up the exact context of our proximal problem.&lt;/p&gt;
&lt;div class="sourceCode" id="cb4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb4-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano &lt;span class="im"&gt;import&lt;/span&gt; clone &lt;span class="im"&gt;as&lt;/span&gt; tt_clone&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-3" data-line-number="3"&gt;&lt;span class="co"&gt;# Clone the negative log-likelihood of our observation model.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-4" data-line-number="4"&gt;nlogl_rv &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="op"&gt;-&lt;/span&gt;lasso_model.observed_RVs[&lt;span class="dv"&gt;0&lt;/span&gt;].logpt&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-5" data-line-number="5"&gt;nlogl &lt;span class="op"&gt;=&lt;/span&gt; tt_clone(nlogl_rv)&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-6" data-line-number="6"&gt;nlogl.name &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;-logl&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-7" data-line-number="7"&gt;beta_tt &lt;span class="op"&gt;=&lt;/span&gt; tt_inputs([nlogl])[&lt;span class="dv"&gt;4&lt;/span&gt;]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section id="proximal-gradient" class="level1"&gt;
&lt;h1&gt;Proximal Gradient&lt;/h1&gt;
&lt;p&gt;In what follows it will be convenient to generalize a bit and work in terms of arbitrary loss and penalty functions &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt;, respectively, which in our case corresponds to &lt;span class="math display"&gt;\[\begin{equation*}
\begin{gathered}
  l(\beta) = \frac12 \|y - X \beta\|^2_2, \quad
  \text{and}\;
  \phi(\beta) = \|\beta\|_1
  \;.\end{gathered}
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The proximal gradient &lt;span class="citation" data-cites="combettes_proximal_2011"&gt;(Combettes and Pesquet 2011)&lt;/span&gt; algorithm is a staple of the proximal framework that provides solutions to problems of the form &lt;span class="math display"&gt;\[\begin{equation*}
\operatorname*{argmin}_\beta \left\{
    l(\beta) + \lambda \phi(\beta)
  \right\}
  \;,
\end{equation*}\]&lt;/span&gt; when both &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt; are lower semi-continuous convex functions, and &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; is differentiable with Lipschitz gradient.&lt;/p&gt;
&lt;p&gt;The solution is given as the following fixed-point: &lt;span class="math display"&gt;\[\begin{equation}
\beta = \operatorname*{prox}_{\alpha \lambda \phi}(\beta - \alpha \nabla l(\beta))
  \;.
  \label{eq:forward-backward}
\end{equation}\]&lt;/span&gt; The constant step size &lt;span class="math inline"&gt;\(\alpha\)&lt;/span&gt; is related to the Lipschitz constant of &lt;span class="math inline"&gt;\(\nabla l\)&lt;/span&gt;, but can also be a sequence obeying certain constraints. Since our &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; under consideration is &lt;span class="math inline"&gt;\(\ell_2\)&lt;/span&gt;, we have the incredibly standard &lt;span class="math inline"&gt;\(\nabla l(\beta) = X^\top (X \beta - y)\)&lt;/span&gt;.&lt;/p&gt;
&lt;section id="implementation" class="level2"&gt;
&lt;h2&gt;Implementation&lt;/h2&gt;
&lt;p&gt;As in &lt;span class="citation" data-cites="willard_role_2017"&gt;Willard (2017)&lt;/span&gt;, we provide an implementation of a proximal gradient step.&lt;/p&gt;
&lt;div class="sourceCode" id="cb5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb5-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano &lt;span class="im"&gt;import&lt;/span&gt; function &lt;span class="im"&gt;as&lt;/span&gt; tt_function&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano.&lt;span class="bu"&gt;compile&lt;/span&gt;.nanguardmode &lt;span class="im"&gt;import&lt;/span&gt; NanGuardMode&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-4" data-line-number="4"&gt;tt_func_mode &lt;span class="op"&gt;=&lt;/span&gt; NanGuardMode(nan_is_error&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-5" data-line-number="5"&gt;                            inf_is_error&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-6" data-line-number="6"&gt;                            big_is_error&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-9" data-line-number="9"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; prox_gradient_step(loss, beta_tt, prox_func,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-10" data-line-number="10"&gt;                       alpha_tt&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, lambda_tt&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-11" data-line-number="11"&gt;                       return_loss_grad&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-12" data-line-number="12"&gt;                       tt_func_kwargs&lt;span class="op"&gt;=&lt;/span&gt;{&lt;span class="st"&gt;&amp;#39;mode&amp;#39;&lt;/span&gt;: tt_func_mode}&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-13" data-line-number="13"&gt;                       ):&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-14" data-line-number="14"&gt;    &lt;span class="co"&gt;r&amp;quot;&amp;quot;&amp;quot; Creates a function that produces a proximal gradient step.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-16" data-line-number="16"&gt;&lt;span class="co"&gt;    Arguments&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-17" data-line-number="17"&gt;&lt;span class="co"&gt;    =========&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-18" data-line-number="18"&gt;&lt;span class="co"&gt;    loss: TensorVariable&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-19" data-line-number="19"&gt;&lt;span class="co"&gt;        Continuously differentiable &amp;quot;loss&amp;quot; function in the objective&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-20" data-line-number="20"&gt;&lt;span class="co"&gt;        function.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-21" data-line-number="21"&gt;&lt;span class="co"&gt;    beta_tt: TensorVariable&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-22" data-line-number="22"&gt;&lt;span class="co"&gt;        Variable argument of the loss function.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-23" data-line-number="23"&gt;&lt;span class="co"&gt;    prox_fn: function&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-24" data-line-number="24"&gt;&lt;span class="co"&gt;        Function that computes the proximal operator for the &amp;quot;penalty&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-25" data-line-number="25"&gt;&lt;span class="co"&gt;        function.  Must take two parameters: the first a&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-26" data-line-number="26"&gt;&lt;span class="co"&gt;TensorVariable&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-27" data-line-number="27"&gt;&lt;span class="co"&gt;        of the gradient step, the second a float or Scalar value.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-28" data-line-number="28"&gt;&lt;span class="co"&gt;    alpha_tt: float, Scalar (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-29" data-line-number="29"&gt;&lt;span class="co"&gt;        Gradient step size.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-30" data-line-number="30"&gt;&lt;span class="co"&gt;    lambda_tt: float, Scalar (optional)&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-31" data-line-number="31"&gt;&lt;span class="co"&gt;        Additional scalar value passed to `prox_fn`.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-32" data-line-number="32"&gt;&lt;span class="co"&gt;        &lt;/span&gt;&lt;span class="al"&gt;TODO&lt;/span&gt;&lt;span class="co"&gt;: Not sure if this should be here; is redundant.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-33" data-line-number="33"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-34" data-line-number="34"&gt;    loss_grad &lt;span class="op"&gt;=&lt;/span&gt; tt.grad(loss, wrt&lt;span class="op"&gt;=&lt;/span&gt;beta_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-35" data-line-number="35"&gt;    loss_grad.name &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;loss_grad&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-36" data-line-number="36"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-37" data-line-number="37"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; alpha_tt &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-38" data-line-number="38"&gt;        alpha_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.scalar(name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;alpha&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-39" data-line-number="39"&gt;        alpha_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-40" data-line-number="40"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; lambda_tt &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-41" data-line-number="41"&gt;        lambda_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.scalar(name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;lambda&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-42" data-line-number="42"&gt;        lambda_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-43" data-line-number="43"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-44" data-line-number="44"&gt;    beta_grad_step &lt;span class="op"&gt;=&lt;/span&gt; beta_tt &lt;span class="op"&gt;-&lt;/span&gt; alpha_tt &lt;span class="op"&gt;*&lt;/span&gt; loss_grad&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-45" data-line-number="45"&gt;    beta_grad_step.name &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;beta_grad_step&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-46" data-line-number="46"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-47" data-line-number="47"&gt;    prox_grad_step &lt;span class="op"&gt;=&lt;/span&gt; prox_func(beta_grad_step, lambda_tt &lt;span class="op"&gt;*&lt;/span&gt; alpha_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-48" data-line-number="48"&gt;    prox_grad_step.name &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;prox_grad_step&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-49" data-line-number="49"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-50" data-line-number="50"&gt;    inputs &lt;span class="op"&gt;=&lt;/span&gt; []&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-51" data-line-number="51"&gt;    updates &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-52" data-line-number="52"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(beta_tt, tt.sharedvar.SharedVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-53" data-line-number="53"&gt;        updates &lt;span class="op"&gt;=&lt;/span&gt; [(beta_tt, prox_grad_step)]&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-54" data-line-number="54"&gt;    &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-55" data-line-number="55"&gt;        inputs &lt;span class="op"&gt;+=&lt;/span&gt; [beta_tt]&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-56" data-line-number="56"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(alpha_tt, tt.sharedvar.SharedVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-57" data-line-number="57"&gt;        inputs &lt;span class="op"&gt;+=&lt;/span&gt; [alpha_tt]&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-58" data-line-number="58"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(lambda_tt, tt.sharedvar.SharedVariable):&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-59" data-line-number="59"&gt;        inputs &lt;span class="op"&gt;+=&lt;/span&gt; [lambda_tt]&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-60" data-line-number="60"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-61" data-line-number="61"&gt;    prox_grad_step_fn &lt;span class="op"&gt;=&lt;/span&gt; tt_function(inputs,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-62" data-line-number="62"&gt;                                    prox_grad_step,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-63" data-line-number="63"&gt;                                    updates&lt;span class="op"&gt;=&lt;/span&gt;updates,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-64" data-line-number="64"&gt;                                    &lt;span class="op"&gt;**&lt;/span&gt;tt_func_kwargs)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-65" data-line-number="65"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-66" data-line-number="66"&gt;    res &lt;span class="op"&gt;=&lt;/span&gt; (prox_grad_step_fn,)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-67" data-line-number="67"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; return_loss_grad:&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-68" data-line-number="68"&gt;        res &lt;span class="op"&gt;+=&lt;/span&gt; (loss_grad,)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-69" data-line-number="69"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-70" data-line-number="70"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; res&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section id="step-sizes" class="level2"&gt;
&lt;h2&gt;Step Sizes&lt;/h2&gt;
&lt;p&gt;A critical aspect of the proximal gradient approach–and most optimizations–involves the use of an appropriate step size, &lt;span class="math inline"&gt;\(\alpha\)&lt;/span&gt;. The step sizes needn’t always be fixed values and, because of this, we can search for a suitable value during estimation. Furthermore, in some cases, step sizes can be sequences amenable to acceleration techniques &lt;span class="citation" data-cites="beck_fast_2014"&gt;(Beck and Teboulle 2014)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Step sizes–and the values that drive them–have critical connections to the performance of an optimization method and do not simply ensure convergence. In that sense, the power of an implementation can depend on how much support it has for various types of step size sequences and when they can be/are used.&lt;/p&gt;
&lt;p&gt;Often, acceptable ranges of step size values are derived from broad properties of the functions involved and their gradients (e.g. Lipschitz). When explicitly parameterized, these properties can give meaning to what some call “tuning parameters”. The connections between function-analytic properties and “tuning parameters” themselves highlight the need for more mathematical coverage/symbolic assessment within implementations. Currently, most tuning parameter act as stand-ins for information that’s theoretically obtained from the know functions.&lt;/p&gt;
&lt;p&gt;In this spirit, one particularly relevant direction of work can be found in Theano’s experimental matrix “Hints”. Matrix-property hints like &lt;code&gt;theano.sandbox.linalg.ops.{psd, spectral_radius_bound}&lt;/code&gt; are good examples of the machinery needed to automatically determine applicable and efficient &lt;span class="math inline"&gt;\(\alpha\)&lt;/span&gt; constants and sequences.&lt;/p&gt;
&lt;p&gt;For our example, we will simply use backtracking line-search.&lt;/p&gt;
&lt;div class="sourceCode" id="cb6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb6-1" data-line-number="1"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; backtracking_search(beta_, alpha_,&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-2" data-line-number="2"&gt;                        prox_fn, loss_fn, loss_grad_fn,&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-3" data-line-number="3"&gt;                        lambda_&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;, bt_rate&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;0.5&lt;/span&gt;, obj_tol&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1e-5&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-4" data-line-number="4"&gt;    &lt;span class="co"&gt;# alpha_start = alpha_&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-5" data-line-number="5"&gt;    z &lt;span class="op"&gt;=&lt;/span&gt; beta_&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-6" data-line-number="6"&gt;    beta_start_ &lt;span class="op"&gt;=&lt;/span&gt; beta_&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-7" data-line-number="7"&gt;    loss_start_ &lt;span class="op"&gt;=&lt;/span&gt; loss_fn(beta_)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-8" data-line-number="8"&gt;    loss_grad_start_ &lt;span class="op"&gt;=&lt;/span&gt; loss_grad_fn(beta_)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-9" data-line-number="9"&gt;    &lt;span class="cf"&gt;while&lt;/span&gt; &lt;span class="va"&gt;True&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-11" data-line-number="11"&gt;        beta_ &lt;span class="op"&gt;=&lt;/span&gt; beta_start_ &lt;span class="op"&gt;-&lt;/span&gt; alpha_ &lt;span class="op"&gt;*&lt;/span&gt; loss_grad_start_&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-12" data-line-number="12"&gt;        z &lt;span class="op"&gt;=&lt;/span&gt; prox_fn(beta_, alpha_ &lt;span class="op"&gt;*&lt;/span&gt; lambda_)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-14" data-line-number="14"&gt;        loss_z &lt;span class="op"&gt;=&lt;/span&gt; loss_fn(z)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-15" data-line-number="15"&gt;        step_diff &lt;span class="op"&gt;=&lt;/span&gt; z &lt;span class="op"&gt;-&lt;/span&gt; beta_start_&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-16" data-line-number="16"&gt;        loss_diff &lt;span class="op"&gt;=&lt;/span&gt; loss_z &lt;span class="op"&gt;-&lt;/span&gt; loss_start_&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-17" data-line-number="17"&gt;        line_diff &lt;span class="op"&gt;=&lt;/span&gt; alpha_ &lt;span class="op"&gt;*&lt;/span&gt; (loss_diff &lt;span class="op"&gt;-&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-18" data-line-number="18"&gt;loss_grad_start_.T.dot(step_diff))&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-19" data-line-number="19"&gt;        line_diff &lt;span class="op"&gt;-=&lt;/span&gt; step_diff.T.dot(step_diff) &lt;span class="op"&gt;/&lt;/span&gt; &lt;span class="fl"&gt;2.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-20" data-line-number="20"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-21" data-line-number="21"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; line_diff &lt;span class="op"&gt;&amp;lt;=&lt;/span&gt; obj_tol:&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-22" data-line-number="22"&gt;            &lt;span class="cf"&gt;return&lt;/span&gt; z, alpha_, loss_z&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-23" data-line-number="23"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-24" data-line-number="24"&gt;        alpha_ &lt;span class="op"&gt;*=&lt;/span&gt; bt_rate&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-25" data-line-number="25"&gt;        &lt;span class="cf"&gt;assert&lt;/span&gt; alpha_ &lt;span class="op"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;invalid step size: &lt;/span&gt;&lt;span class="sc"&gt;{}&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;&lt;/span&gt;.&lt;span class="bu"&gt;format&lt;/span&gt;(alpha_)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="remark" data-markdown="" data-title-name=""&gt;
&lt;p&gt;Routines–like this–that make use of the gradient and other quantities might also be good candidates for execution in Theano, if only for the graph optimizations that are able to remedy obviously redundant computations.&lt;/p&gt;
&lt;p&gt;In this vein, we could consider performing the line-search, and/or the entire optimization loop, within a Theano &lt;code&gt;scan&lt;/code&gt; operation. We could also create an &lt;code&gt;Op&lt;/code&gt; that represents gradient and line-search steps. These might make graph construction much simpler and be more suited for the current optimization framework.&lt;/p&gt;
&lt;p&gt;Although there’s no guarantee that &lt;code&gt;scan&lt;/code&gt; and tighter Theano integrations will always produce better results than our current implementation, we wish to emphasize that it’s possible–given work in these symbolic directions.&lt;/p&gt;
&lt;p&gt;Likewise, an &lt;code&gt;Op&lt;/code&gt; for the proximal operator might also be necessary for solving many proximal operators found within a log-likelihood/objective function graph automatically and in closed-form. An effective implementation could be as simple as the use of lookup tables combined with some algebraic relationships/identities. State-of-the-art symbolic algebra libraries effectively use the same approach for symbolic integration.&lt;/p&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="examples" class="level1"&gt;
&lt;h1&gt;Examples&lt;/h1&gt;
&lt;p&gt;First, to compute anything from our Theano graphs, we need to compile them to Theano functions.&lt;/p&gt;
&lt;div class="sourceCode" id="cb7"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb7-1" data-line-number="1"&gt;lambda_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.scalar(&lt;span class="st"&gt;&amp;#39;lambda&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-2" data-line-number="2"&gt;lambda_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-4" data-line-number="4"&gt;prox_fn &lt;span class="op"&gt;=&lt;/span&gt; tt_function([beta_tt, lambda_tt],&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-5" data-line-number="5"&gt;                      tt_soft_threshold(beta_tt, lambda_tt))&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-7" data-line-number="7"&gt;prox_grad_step_fn, loss_grad &lt;span class="op"&gt;=&lt;/span&gt; prox_gradient_step(&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-8" data-line-number="8"&gt;    nlogl, beta_tt, tt_soft_threshold,&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-9" data-line-number="9"&gt;    return_loss_grad&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-11" data-line-number="11"&gt;loss_fn &lt;span class="op"&gt;=&lt;/span&gt; tt_function([beta_tt], nlogl)&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-12" data-line-number="12"&gt;loss_grad_fn &lt;span class="op"&gt;=&lt;/span&gt; tt_function([beta_tt], loss_grad)&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-14" data-line-number="14"&gt;cols_fns &lt;span class="op"&gt;=&lt;/span&gt; [&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-15" data-line-number="15"&gt;    (&lt;span class="kw"&gt;lambda&lt;/span&gt; i, b: i, &lt;span class="vs"&gt;r&amp;#39;$i$&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-16" data-line-number="16"&gt;    (&lt;span class="kw"&gt;lambda&lt;/span&gt; i, b: np.asscalar(loss_fn(b)),&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-17" data-line-number="17"&gt;        &lt;span class="vs"&gt;r&amp;#39;$l(\beta^{(i)})$&amp;#39;&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-18" data-line-number="18"&gt;    (&lt;span class="kw"&gt;lambda&lt;/span&gt; i, b: np.linalg.norm(b &lt;span class="op"&gt;-&lt;/span&gt; beta_true, &lt;span class="dv"&gt;2&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-19" data-line-number="19"&gt;        &lt;span class="vs"&gt;r&amp;#39;$\|\beta^{(i)} - \beta^*\|^2_2$&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-20" data-line-number="20"&gt;]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For a baseline comparison–and sanity check–we’ll use the &lt;code&gt;cvxpy&lt;/code&gt; library &lt;span class="citation" data-cites="diamond_cvxpy:_2016"&gt;(Diamond and Boyd 2016)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb8"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb8-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; cvxpy &lt;span class="im"&gt;as&lt;/span&gt; cvx&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-3" data-line-number="3"&gt;beta_var_cvx &lt;span class="op"&gt;=&lt;/span&gt; cvx.Variable(M, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-4" data-line-number="4"&gt;lambda_cvx &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;1e-2&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt; lambda_max &lt;span class="op"&gt;*&lt;/span&gt; N&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-6" data-line-number="6"&gt;cvx_obj &lt;span class="op"&gt;=&lt;/span&gt; cvx.Minimize(&lt;span class="fl"&gt;0.5&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt; cvx.sum_squares(y &lt;span class="op"&gt;-&lt;/span&gt; X &lt;span class="op"&gt;*&lt;/span&gt; beta_var_cvx)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-7" data-line-number="7"&gt;                       &lt;span class="op"&gt;+&lt;/span&gt; lambda_cvx &lt;span class="op"&gt;*&lt;/span&gt; cvx.norm(beta_var_cvx, &lt;span class="dv"&gt;1&lt;/span&gt;) )&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-8" data-line-number="8"&gt;cvx_prob &lt;span class="op"&gt;=&lt;/span&gt; cvx.Problem(cvx_obj)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-10" data-line-number="10"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; cvx_prob.solve(solver&lt;span class="op"&gt;=&lt;/span&gt;cvx.CVXOPT, verbose&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-12" data-line-number="12"&gt;beta_cvx &lt;span class="op"&gt;=&lt;/span&gt; np.asarray(beta_var_cvx.value).squeeze()&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-13" data-line-number="13"&gt;loss_cvx &lt;span class="op"&gt;=&lt;/span&gt; loss_fn(beta_cvx)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-14" data-line-number="14"&gt;beta_cvx_err &lt;span class="op"&gt;=&lt;/span&gt; np.linalg.norm(beta_cvx &lt;span class="op"&gt;-&lt;/span&gt; beta_true, &lt;span class="dv"&gt;2&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We now have the necessary pieces to perform an example estimation. We’ll start with an exceedingly large step size and let backtracking line-search find a good value.&lt;/p&gt;
&lt;div class="sourceCode" id="cb9"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb9-1" data-line-number="1"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; ProxGradient(&lt;span class="bu"&gt;object&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-3" data-line-number="3"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;, y, X, beta_0,&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-4" data-line-number="4"&gt;                 prox_fn_, loss_fn_, loss_grad_fn_,&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-5" data-line-number="5"&gt;                 alpha_0):&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-7" data-line-number="7"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.y &lt;span class="op"&gt;=&lt;/span&gt; y&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-8" data-line-number="8"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.X &lt;span class="op"&gt;=&lt;/span&gt; X&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-9" data-line-number="9"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.alpha_val &lt;span class="op"&gt;=&lt;/span&gt; alpha_0&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-10" data-line-number="10"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.beta_0 &lt;span class="op"&gt;=&lt;/span&gt; beta_0&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-11" data-line-number="11"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.N, &lt;span class="va"&gt;self&lt;/span&gt;.M &lt;span class="op"&gt;=&lt;/span&gt; X.shape&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-12" data-line-number="12"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.prox_fn_ &lt;span class="op"&gt;=&lt;/span&gt; prox_fn_&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-13" data-line-number="13"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.loss_fn_ &lt;span class="op"&gt;=&lt;/span&gt; loss_fn_&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-14" data-line-number="14"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.loss_grad_fn_ &lt;span class="op"&gt;=&lt;/span&gt; loss_grad_fn_&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-16" data-line-number="16"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; step(&lt;span class="va"&gt;self&lt;/span&gt;, beta):&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-17" data-line-number="17"&gt;        beta_val &lt;span class="op"&gt;=&lt;/span&gt; np.copy(beta)&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-19" data-line-number="19"&gt;        beta_val, &lt;span class="va"&gt;self&lt;/span&gt;.alpha_val, _ &lt;span class="op"&gt;=&lt;/span&gt; backtracking_search(&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-20" data-line-number="20"&gt;            beta_val, &lt;span class="va"&gt;self&lt;/span&gt;.alpha_val,&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-21" data-line-number="21"&gt;            &lt;span class="va"&gt;self&lt;/span&gt;.prox_fn_, &lt;span class="va"&gt;self&lt;/span&gt;.loss_fn_, &lt;span class="va"&gt;self&lt;/span&gt;.loss_grad_fn_)&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-22" data-line-number="22"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-23" data-line-number="23"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; beta_val&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb10"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb10-1" data-line-number="1"&gt;beta_0 &lt;span class="op"&gt;=&lt;/span&gt; np.zeros(M).astype(&lt;span class="st"&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-2" data-line-number="2"&gt;lambda_val &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;1e-2&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt; lambda_max&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-3" data-line-number="3"&gt;pg_step &lt;span class="op"&gt;=&lt;/span&gt; ProxGradient(y, X, beta_0,&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-4" data-line-number="4"&gt;                       &lt;span class="kw"&gt;lambda&lt;/span&gt; x, a: prox_fn(x, N &lt;span class="op"&gt;*&lt;/span&gt; lambda_val &lt;span class="op"&gt;*&lt;/span&gt; a),&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-5" data-line-number="5"&gt;                       loss_fn, loss_grad_fn, &lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-7" data-line-number="7"&gt;pg_cols_fns &lt;span class="op"&gt;=&lt;/span&gt; cols_fns &lt;span class="op"&gt;+&lt;/span&gt; [(&lt;span class="kw"&gt;lambda&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt;args, &lt;span class="op"&gt;**&lt;/span&gt;kwargs: pg_step.alpha_val,&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-8" data-line-number="8"&gt;&lt;span class="vs"&gt;r&amp;#39;$\alpha$&amp;#39;&lt;/span&gt;)]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-9" data-line-number="9"&gt;pg_est_data, _ &lt;span class="op"&gt;=&lt;/span&gt; iterative_run(pg_step, loss_fn, pg_cols_fns)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-10" data-line-number="10"&gt;pg_ls_data &lt;span class="op"&gt;=&lt;/span&gt; pd.DataFrame(pg_est_data)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-11" data-line-number="11"&gt;&lt;span class="co"&gt;# pg_ls_data = pg_ls_data.append(pg_est_data, ignore_index=True)&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span id="fig:pg_ls_plot"&gt;&lt;span id="fig:pg_ls_plot_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{1}\label{fig:pg_ls_plot}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;img src="https://brandonwillard.github.io/figures/more_proximal_estimation_pg_ls_plot_1.png" title="fig:" alt="Minimization by proximal gradient with backtracking line-search." /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Figure &lt;span class="math inline"&gt;\(\ref{fig:pg_ls_plot}\)&lt;/span&gt; shows a couple convergence measures for proximal gradient steps alongside the step size changes due to backtracking line-search. Regarding the latter, in our example a sufficient step size is found within the first few iterations, so the overall result isn’t too interesting. Fortunately, this sort of behaviour isn’t uncommon, which makes line-search quite effective in practice.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="coordinate-wise-estimation" class="level1"&gt;
&lt;h1&gt;Coordinate-wise Estimation&lt;/h1&gt;
&lt;p&gt;Given that our loss is a composition of &lt;span class="math inline"&gt;\(\ell_2\)&lt;/span&gt; and a linear operator of finite dimension (i.e. &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;), we can conveniently exploit conditional separability and obtain simple estimation steps in each coordinate. This is, effectively, what characterizes coordinate–or cyclic–descent. Since it is a common technique in the estimation of &lt;span class="math inline"&gt;\(\ell_1\)&lt;/span&gt; models &lt;span class="citation" data-cites="friedman_pathwise_2007 mazumder_regularization_2009 scikit-learn_sklearn.linear_model.elasticnet_2017"&gt;(Friedman et al. 2007; Mazumder, Hastie, and Tibshirani 2009; scikit-learn 2017)&lt;/span&gt;, it’s worthwhile to consider how it can viewed in terms of proximal operators.&lt;/p&gt;
&lt;p&gt;From a statistical perspective, the basics of coordinate-wise methods begin with the “partial residuals”, &lt;span class="math inline"&gt;\(r_{-m} \in {{\mathbb{R}}}^{N}\)&lt;/span&gt; discussed in &lt;span class="citation" data-cites="friedman_pathwise_2007"&gt;Friedman et al. (2007)&lt;/span&gt;, and implicitly defined by &lt;span class="math display"&gt;\[\begin{equation}
\begin{aligned}
    \beta^*
    &amp;amp;= \operatorname*{argmin}_{\beta} \left\{
      \frac12
      \|
    y - X(\beta - e_m \beta_m)
        - X e_m \cdot \beta_{m}\|^2_2
      + \lambda \left|\beta_m\right|
      + \lambda \sum_{m^\prime \neq m} \left|\beta_{m^\prime}\right|
      \right\}
    \\
    &amp;amp;= \operatorname*{argmin}_{\beta} \left\{
      \frac12
      \|r_{-m} - X e_m \cdot \beta_{m}\|^2_2
      + \lambda \left|\beta_m\right|
      + \dots
    \right\}
  \;.
  \end{aligned}
  \label{eq:partial_resid}
\end{equation}\]&lt;/span&gt; The last expression hints at the most basic idea behind the coordinate-wise approach: conditional minimization in each &lt;span class="math inline"&gt;\(m\)&lt;/span&gt;. Its exact solution in each coordinate is given by the aforementioned soft-thresholding function, which–as we’ve already stated–is a proximal operator. In symbols, &lt;span class="math inline"&gt;\(\operatorname*{prox}_{\lambda \left|\cdot\right|}(x) = \operatorname{S}_\lambda(x)\)&lt;/span&gt;, where the latter is the soft-thresholding operator.&lt;/p&gt;
&lt;p&gt;Now, we can relate Equation &lt;span class="math inline"&gt;\(\eqref{eq:partial_resid}\)&lt;/span&gt; to proximal methods through the proximal gradient fixed-point solution–i.e. Equation &lt;span class="math inline"&gt;\(\eqref{eq:forward-backward}\)&lt;/span&gt;–and the following property of proximal operators:&lt;/p&gt;
&lt;div id="lem:prox_ortho_basis" class="lemma" data-markdown="" data-title-name=""&gt;
&lt;p&gt;&lt;span id="lem:prox_ortho_basis_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{1}\label{lem:prox_ortho_basis}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
\operatorname*{prox}_{\lambda \phi \circ e^\top_m}(z) =
    \sum^M_m \operatorname*{prox}_{\lambda \phi}\left(e^\top_m z\right) e_m
    \;.
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;div class="proof" data-markdown="" data-title-name=""&gt;
&lt;p&gt;See &lt;span class="citation" data-cites="chaux_variational_2007"&gt;Chaux et al. (2007)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The next result yields our desired connection.&lt;/p&gt;
&lt;div id="eq:prox_grad_descent" class="proposition" data-markdown="" data-title-name=""&gt;
&lt;p&gt;&lt;span id="eq:prox_grad_descent_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{1}\label{eq:prox_grad_descent}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; such that &lt;span class="math inline"&gt;\({{\bf 1}}^\top X e_m = 0\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(e^\top_m X^\top X e_m = 1\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(m \in \{1, \dots, M\}\)&lt;/span&gt;, the coordinate-wise step of the Lasso in &lt;span class="citation" data-cites="friedman_pathwise_2007"&gt;Friedman et al. (2007 Equation (9))&lt;/span&gt;, &lt;span class="math display"&gt;\[\begin{equation*}
\beta_m = \operatorname{S}_{\lambda}\left[
      \sum_{n}^N X_{n,m} \left(
      y_n - \sum^M_{m^\prime \neq m} X_{n,m^\prime} \beta_{m^\prime}
      \right)
    \right]
    \;,
\end{equation*}\]&lt;/span&gt; has a proximal gradient fixed-point solution under a Euclidean basis decomposition with the form &lt;span class="math display"&gt;\[\begin{equation*}
\beta =
    \sum^M_m \operatorname*{prox}_{\alpha \lambda \phi}\left[
      e^\top_m \left(\beta - \alpha \nabla l(\beta)\right)
    \right] e_m
    \;.
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;div class="proof" data-markdown="" data-title-name=""&gt;
&lt;p&gt;We start with an expansion of the terms in &lt;span class="math inline"&gt;\(\operatorname*{prox}_{\lambda \phi} \equiv \operatorname{S}_\lambda\)&lt;/span&gt;. After simplifying the notation with &lt;span class="math display"&gt;\[\begin{equation*}
\begin{gathered}
    \sum^N_{n} X_{n,m} z_n = e^\top_m X^\top z, \quad \text{and} \quad
    \sum^M_{m^\prime \neq m} X_{n,m^\prime} \beta_{m^\prime} =
    X \left(\beta - \beta_m e_m \right)
    \;,
  \end{gathered}
\end{equation*}\]&lt;/span&gt; the expanded argument of &lt;span class="math inline"&gt;\(\operatorname{S}\)&lt;/span&gt; reduces to &lt;span class="math display"&gt;\[\begin{equation*}
\begin{aligned}
      e^\top_m X^\top \left(y - X\left( \beta - e_m \beta_m\right)\right)
      &amp;amp;= e^\top_m X^\top X e_m \beta_m + e^\top_m X^\top \left(y - X \beta\right)
      \\
      &amp;amp;= \beta_m + e^\top_m X^\top \left(y - X \beta\right)
      \\
      &amp;amp;= e^\top_m \left(\beta + X^\top \left(y - X \beta\right)\right)
    \end{aligned}
\end{equation*}\]&lt;/span&gt; where the last step follows from &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; standardization. This establishes the relationship with Equation &lt;span class="math inline"&gt;\(\eqref{eq:forward-backward}\)&lt;/span&gt; only component-wise. Using Lemma &lt;span class="math inline"&gt;\(\eqref{lem:prox_ortho_basis}\)&lt;/span&gt; together with &lt;span class="math inline"&gt;\(z = \beta - \alpha \nabla  l(\beta)\)&lt;/span&gt; yields the proximal gradient fixed-point statement, i.e. &lt;span class="math display"&gt;\[\begin{equation*}
\begin{aligned}
      \beta
      &amp;amp;=
      \sum^M_m \operatorname*{prox}_{\alpha \lambda \phi}\left[
    e^\top_m \left(\beta - \alpha \nabla l(\beta)\right)
      \right] e_m
      \\
      &amp;amp;=
      \sum^M_m \operatorname*{prox}_{\alpha \lambda \phi}\left(
      \beta_m + \alpha e_m^\top X^\top \left(y - X \beta \right)
      \right) e_m
      \;.
    \end{aligned}
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="rem:bases" class="remark" data-markdown="" data-title-name=""&gt;
&lt;p&gt;&lt;span id="rem:bases_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{3}\label{rem:bases}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The property in Lemma &lt;span class="math inline"&gt;\(\eqref{lem:prox_ortho_basis}\)&lt;/span&gt; can be used with other orthonormal bases–providing yet another connection between proximal methods and established dimensionality reduction and sparse estimation techniques &lt;span class="citation" data-cites="chaux_variational_2007"&gt;(Chaux et al. 2007)&lt;/span&gt;. Also, this property provides a neat way to think about &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;-based orthogonalizations in estimations for regression and grouped-penalization problems.&lt;/p&gt;
&lt;/div&gt;
&lt;section id="implementation-1" class="level2"&gt;
&lt;h2&gt;Implementation&lt;/h2&gt;
&lt;p&gt;The following performs a standard form of coordinate descent:&lt;/p&gt;
&lt;div class="sourceCode" id="cb11"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb11-1" data-line-number="1"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; CoordDescent(&lt;span class="bu"&gt;object&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-3" data-line-number="3"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; &lt;span class="fu"&gt;__init__&lt;/span&gt;(&lt;span class="va"&gt;self&lt;/span&gt;, y, X, beta_0, prox_fn_, col_seq&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-5" data-line-number="5"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.y &lt;span class="op"&gt;=&lt;/span&gt; y&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-6" data-line-number="6"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.X &lt;span class="op"&gt;=&lt;/span&gt; X&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-7" data-line-number="7"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.beta_0 &lt;span class="op"&gt;=&lt;/span&gt; beta_0&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-8" data-line-number="8"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.N, &lt;span class="va"&gt;self&lt;/span&gt;.M &lt;span class="op"&gt;=&lt;/span&gt; X.shape&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-9" data-line-number="9"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.Xb &lt;span class="op"&gt;=&lt;/span&gt; np.dot(&lt;span class="va"&gt;self&lt;/span&gt;.X, &lt;span class="va"&gt;self&lt;/span&gt;.beta_0)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-10" data-line-number="10"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.prox_fn_ &lt;span class="op"&gt;=&lt;/span&gt; prox_fn_&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-12" data-line-number="12"&gt;        &lt;span class="co"&gt;# (Inverse) 2-norm of each column/feature, i.e.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-13" data-line-number="13"&gt;        &lt;span class="co"&gt;#   np.reciprocal(np.diag(np.dot(X.T, X)))&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-14" data-line-number="14"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.alpha_vals &lt;span class="op"&gt;=&lt;/span&gt; np.reciprocal((&lt;span class="va"&gt;self&lt;/span&gt;.X&lt;span class="op"&gt;**&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;).&lt;span class="bu"&gt;sum&lt;/span&gt;(axis&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;0&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-16" data-line-number="16"&gt;        &lt;span class="cf"&gt;if&lt;/span&gt; col_seq &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-17" data-line-number="17"&gt;            &lt;span class="va"&gt;self&lt;/span&gt;.col_seq &lt;span class="op"&gt;=&lt;/span&gt; np.arange(&lt;span class="va"&gt;self&lt;/span&gt;.M)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-19" data-line-number="19"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; reset(&lt;span class="va"&gt;self&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-20" data-line-number="20"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.Xb &lt;span class="op"&gt;=&lt;/span&gt; np.dot(&lt;span class="va"&gt;self&lt;/span&gt;.X, &lt;span class="va"&gt;self&lt;/span&gt;.beta_0)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-22" data-line-number="22"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; step(&lt;span class="va"&gt;self&lt;/span&gt;, beta):&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-23" data-line-number="23"&gt;        beta_val &lt;span class="op"&gt;=&lt;/span&gt; np.copy(beta)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-24" data-line-number="24"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-25" data-line-number="25"&gt;        &lt;span class="cf"&gt;for&lt;/span&gt; j &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.col_seq:&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-26" data-line-number="26"&gt;            X_j &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.X[:, j]&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-27" data-line-number="27"&gt;            alpha_val &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.alpha_vals[j]&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-28" data-line-number="28"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-29" data-line-number="29"&gt;            &lt;span class="co"&gt;# A little cheaper to just subtract the column&amp;#39;s&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-30" data-line-number="30"&gt;contribution...&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-31" data-line-number="31"&gt;            &lt;span class="va"&gt;self&lt;/span&gt;.Xb &lt;span class="op"&gt;-=&lt;/span&gt; X_j &lt;span class="op"&gt;*&lt;/span&gt; beta_val[j]&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-32" data-line-number="32"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-33" data-line-number="33"&gt;            Xt_r &lt;span class="op"&gt;=&lt;/span&gt; np.dot(X_j.T, &lt;span class="va"&gt;self&lt;/span&gt;.y &lt;span class="op"&gt;-&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.Xb) &lt;span class="op"&gt;*&lt;/span&gt; alpha_val&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-34" data-line-number="34"&gt;            beta_val[j] &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="va"&gt;self&lt;/span&gt;.prox_fn_(np.atleast_1d(Xt_r),&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-35" data-line-number="35"&gt;alpha_val)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-36" data-line-number="36"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-37" data-line-number="37"&gt;            &lt;span class="co"&gt;# ...and add the updated column back.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-38" data-line-number="38"&gt;            &lt;span class="va"&gt;self&lt;/span&gt;.Xb &lt;span class="op"&gt;+=&lt;/span&gt; X_j &lt;span class="op"&gt;*&lt;/span&gt; beta_val[j]&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-39" data-line-number="39"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-40" data-line-number="40"&gt;        &lt;span class="va"&gt;self&lt;/span&gt;.beta_last &lt;span class="op"&gt;=&lt;/span&gt; beta_val&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-41" data-line-number="41"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-42" data-line-number="42"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; beta_val&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our example randomizes the order of coordinates to loosely demonstrate the range of efficiency possible in coordinate descent.&lt;/p&gt;
&lt;div class="sourceCode" id="cb12"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb12-1" data-line-number="1"&gt;beta_0 &lt;span class="op"&gt;=&lt;/span&gt; np.zeros(M).astype(&lt;span class="st"&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-2" data-line-number="2"&gt;lambda_val &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;1e-2&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt; lambda_max&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-3" data-line-number="3"&gt;cd_step &lt;span class="op"&gt;=&lt;/span&gt; CoordDescent(y, X, beta_0,&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-4" data-line-number="4"&gt;                       &lt;span class="kw"&gt;lambda&lt;/span&gt; x, a: prox_fn(x, N &lt;span class="op"&gt;*&lt;/span&gt; lambda_val &lt;span class="op"&gt;*&lt;/span&gt; a))&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-6" data-line-number="6"&gt;cd_cols_fns &lt;span class="op"&gt;=&lt;/span&gt; cols_fns &lt;span class="op"&gt;+&lt;/span&gt; [(&lt;span class="kw"&gt;lambda&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt;args, &lt;span class="op"&gt;**&lt;/span&gt;kwargs: j, &lt;span class="st"&gt;&amp;quot;replication&amp;quot;&lt;/span&gt;)]&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-8" data-line-number="8"&gt;pg_coord_data &lt;span class="op"&gt;=&lt;/span&gt; pd.DataFrame()&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-9" data-line-number="9"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; j &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;range&lt;/span&gt;(&lt;span class="dv"&gt;15&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-10" data-line-number="10"&gt;    est_data, _ &lt;span class="op"&gt;=&lt;/span&gt; iterative_run(cd_step, loss_fn, cd_cols_fns)&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-11" data-line-number="11"&gt;    pg_coord_data &lt;span class="op"&gt;=&lt;/span&gt; pg_coord_data.append(est_data,&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-12" data-line-number="12"&gt;                                         ignore_index&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-13" data-line-number="13"&gt;    &lt;span class="co"&gt;# Reset internal state of our step method, since we&amp;#39;re&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-14" data-line-number="14"&gt;    &lt;span class="co"&gt;# running multiple replications.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-15" data-line-number="15"&gt;    cd_step.reset()&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-16" data-line-number="16"&gt;    np.random.shuffle(cd_step.col_seq)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span id="fig:pg_coord_plot"&gt;&lt;span id="fig:pg_coord_plot_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{2}\label{fig:pg_coord_plot}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;img src="https://brandonwillard.github.io/figures/more_proximal_estimation_pg_coord_plot_1.png" title="fig:" alt="Minimization by coordinate descent." /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Figure &lt;span class="math inline"&gt;\(\ref{fig:pg_coord_plot}\)&lt;/span&gt; shows convergence measures for each randomized coordinate order. The [average] difference in the number of iterations required for coordinate descent and proximal gradient is fairly noticeable. Nonetheless, both reach effectively the same limits.&lt;/p&gt;
&lt;div class="remark" data-markdown="" data-title-name=""&gt;
&lt;p&gt;Similar ideas behind batched vs. non-batched steps and block sampling–found within the Gibbs sampling literature &lt;span class="citation" data-cites="roberts_updating_1997"&gt;(Roberts and Sahu 1997)&lt;/span&gt;–could explain the variation due to coordinate order and the relative efficiency of coordinate descent. There are also connections with our comments in Remark &lt;span class="math inline"&gt;\(\ref{rem:bases}\)&lt;/span&gt; and, to some extent, stochastic gradient descent (SGD) &lt;span class="citation" data-cites="bertsekas_incremental_2010"&gt;(Bertsekas 2010)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In a woefully lacking over-generalization, let’s say that it comes down to the [spectral] properties of the composite operator(s) &lt;span class="math inline"&gt;\(l \circ X\)&lt;/span&gt; and/or &lt;span class="math inline"&gt;\(\nabla l \circ X\)&lt;/span&gt;. These determine the bounds of efficiency for steps in certain directions and how blocking or partitioning the dimensions of &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; nears or distances from those bounds.&lt;/p&gt;
&lt;/div&gt;
&lt;section id="regularization-paths" class="level3"&gt;
&lt;h3&gt;Regularization Paths&lt;/h3&gt;
&lt;p&gt;Also, due to the relatively fast convergence of coordinate descent, the method is a little more suitable for the computation of regularization paths– i.e. varying &lt;span class="math inline"&gt;\(\lambda\)&lt;/span&gt; between iterations. There is much more to this topic, but for simplicity let’s just note that each &lt;span class="math inline"&gt;\(\lambda\)&lt;/span&gt; step has a “warm-start” from the previous descent iteration–which helps–and that we’re otherwise fine with the solution provided by this approach.&lt;/p&gt;
&lt;p&gt;Next, we make a small extension to demonstrate the computation of regularization paths–using &lt;code&gt;lasso_path&lt;/code&gt; for comparison.&lt;/p&gt;
&lt;div class="sourceCode" id="cb13"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb13-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; sklearn.linear_model &lt;span class="im"&gt;import&lt;/span&gt; lasso_path, enet_path&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-3" data-line-number="3"&gt;beta_0 &lt;span class="op"&gt;=&lt;/span&gt; np.zeros(M).astype(&lt;span class="st"&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-5" data-line-number="5"&gt;lambda_path, beta_path, _ &lt;span class="op"&gt;=&lt;/span&gt; lasso_path(X, y)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-6" data-line-number="6"&gt;path_len &lt;span class="op"&gt;=&lt;/span&gt; np.alen(lambda_path)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-8" data-line-number="8"&gt;beta_last &lt;span class="op"&gt;=&lt;/span&gt; beta_0&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-9" data-line-number="9"&gt;pg_path_data &lt;span class="op"&gt;=&lt;/span&gt; pd.DataFrame()&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-10" data-line-number="10"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; i, lambda_ &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;enumerate&lt;/span&gt;(lambda_path):&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-11" data-line-number="11"&gt;    cd_path_step &lt;span class="op"&gt;=&lt;/span&gt; CoordDescent(y, X, beta_last,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-12" data-line-number="12"&gt;                        &lt;span class="kw"&gt;lambda&lt;/span&gt; x, a: prox_fn(x, N &lt;span class="op"&gt;*&lt;/span&gt; lambda_ &lt;span class="op"&gt;*&lt;/span&gt; a))&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-14" data-line-number="14"&gt;    cd_cols_fns &lt;span class="op"&gt;=&lt;/span&gt; cols_fns[&lt;span class="dv"&gt;1&lt;/span&gt;:] &lt;span class="op"&gt;+&lt;/span&gt; [&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-15" data-line-number="15"&gt;        (&lt;span class="kw"&gt;lambda&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt;args, &lt;span class="op"&gt;**&lt;/span&gt;kwargs: lambda_, &lt;span class="vs"&gt;r&amp;#39;$\lambda$&amp;#39;&lt;/span&gt;)]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-16" data-line-number="16"&gt;    est_data, beta_last &lt;span class="op"&gt;=&lt;/span&gt; iterative_run(cd_path_step, loss_fn,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-17" data-line-number="17"&gt;                                        cd_cols_fns,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-18" data-line-number="18"&gt;                                        stop_tol&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1e-4&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-19" data-line-number="19"&gt;                                        stop_loss&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-20" data-line-number="20"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-21" data-line-number="21"&gt;    pg_path_data &lt;span class="op"&gt;=&lt;/span&gt; pg_path_data.append(est_data.iloc[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;, :],&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-22" data-line-number="22"&gt;                                       ignore_index&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb14"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb14-1" data-line-number="1"&gt;cd_cols_fns &lt;span class="op"&gt;=&lt;/span&gt; cols_fns[&lt;span class="dv"&gt;1&lt;/span&gt;:] &lt;span class="op"&gt;+&lt;/span&gt; [&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-2" data-line-number="2"&gt;    (&lt;span class="kw"&gt;lambda&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt;args, &lt;span class="op"&gt;**&lt;/span&gt;kwargs: lambda_path[args[&lt;span class="dv"&gt;0&lt;/span&gt;]], &lt;span class="vs"&gt;r&amp;#39;$\lambda$&amp;#39;&lt;/span&gt;)]&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-4" data-line-number="4"&gt;iter_values &lt;span class="op"&gt;=&lt;/span&gt; []&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-5" data-line-number="5"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; i, beta_ &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;enumerate&lt;/span&gt;(beta_path.T):&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-6" data-line-number="6"&gt;    iter_values.append([col_fn(i, beta_)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-7" data-line-number="7"&gt;                        &lt;span class="cf"&gt;for&lt;/span&gt; col_fn, _ &lt;span class="kw"&gt;in&lt;/span&gt; cd_cols_fns])&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-9" data-line-number="9"&gt;sklearn_path_data &lt;span class="op"&gt;=&lt;/span&gt; pd.DataFrame(iter_values,&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-10" data-line-number="10"&gt;                                 columns&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="bu"&gt;zip&lt;/span&gt;(&lt;span class="op"&gt;*&lt;/span&gt;cd_cols_fns)[&lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-11" data-line-number="11"&gt;sklearn_path_data &lt;span class="op"&gt;=&lt;/span&gt; sklearn_path_data.assign(&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-12" data-line-number="12"&gt;    replication&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;, &lt;span class="bu"&gt;type&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;sklearn&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-14" data-line-number="14"&gt;pg_path_data &lt;span class="op"&gt;=&lt;/span&gt; pg_path_data.assign(&lt;span class="bu"&gt;type&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;pg&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-15" data-line-number="15"&gt;pg_path_data &lt;span class="op"&gt;=&lt;/span&gt; pg_path_data.append(sklearn_path_data,&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-16" data-line-number="16"&gt;                                   ignore_index&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span id="fig:pg_path_plot"&gt;&lt;span id="fig:pg_path_plot_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{3}\label{fig:pg_path_plot}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;img src="https://brandonwillard.github.io/figures/more_proximal_estimation_pg_path_plot_1.png" title="fig:" alt="Regularization paths via coordinate descent." /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="discussion" class="level1"&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;Among the changes discussed earlier regarding Theano &lt;code&gt;Op&lt;/code&gt;s for the proximal objects used here, we would also like to motivate much larger changes to the applied mathematician/statistician’s standard tools by demonstrating the relevance of less common–yet increasingly useful–abstractions. For instance, the proximal methods are neatly framed within operator theory and set-valued analysis, where concepts like the resolvent, sub-differential/gradient and others are common. Abstractions like these provide a compact means of extending familiar ideas into new contexts–such as non-differentiable functions.&lt;/p&gt;
&lt;p&gt;Unfortunately, numerical libraries do not provide much in the way of utilizing these abstractions. Most are strictly founded in the representation of point-valued mappings, which can require significant work-arounds to handle even the most basic non-differentiable functions (e.g. the absolute value within our example problem). Our use of the proximal framework is, in part, motivated by its near seamless use &lt;em&gt;and&lt;/em&gt; simultaneous bypassing of set-valued maps–in implementation, at least.&lt;/p&gt;
&lt;p&gt;There is no fundamental restriction blocking support for set-valued maps, however–aside from the necessary labor and community interest. Even minimal support could provide a context that makes frameworks like ours merely minor abstractions. A similar idea can be found in the symbolic calculation of limits via filters &lt;span class="citation" data-cites="beeson_meaning_2005"&gt;(Beeson and Wiedijk 2005)&lt;/span&gt;. Perhaps we can liken these changes to the modern evolution of linear algebra libraries to tensor libraries.&lt;/p&gt;
&lt;p&gt;We would also like to stress that the value provided by the symbolic tools discussed here (Theano, really) are not &lt;em&gt;just&lt;/em&gt; in their ability to act as compilers at a “math level”, but more for their ability to concretely encode mathematical characterizations of optimization problems and methods. Work in this direction is not new by any means; however, the combination of open-source tools and industry interest in algorithms that fall under the broad class of proximal methods (e.g. gradient descent, ADMM, EM, etc.) provides a more immediate reason to pursue these abstractions in code and automate their use.&lt;/p&gt;
&lt;p&gt;Regarding the proximal methods, we can consider Theano optimizations that make direct use of the orthonormal basis property in Lemma &lt;span class="math inline"&gt;\(\eqref{lem:prox_ortho_basis}\)&lt;/span&gt;, or the Moreau-Fenchel theorem, and automate consideration for various estimation methods via splitting (e.g. ADMM, Douglas-Rachford, etc.)–perhaps by making decisions based on inferred or specified tensor, function, and operator properties. In future installments we’ll delve into the details of these ideas.&lt;/p&gt;
&lt;p&gt;&lt;span class="citation" data-cites="wytock_new_2016"&gt;(Wytock et al. 2016)&lt;/span&gt; also discuss similar ideas in an optimization setting, such as the use of symbolic graphs and a close coupling with useful mathematical abstractions–including proximal operators. Additionally, there are many other good examples &lt;span class="citation" data-cites="diamond_cvxpy:_2016"&gt;(Diamond and Boyd 2016)&lt;/span&gt; of constructive mathematical abstractions applied in code.&lt;/p&gt;
&lt;p&gt;In most cases, libraries providing optimization tools and supporting model estimation do not attempt to root their implementations within an independently developed symbolic framework and then realize their relevant methodologies in that context. Too often the mathematical abstractions–or the resulting methods alone–are directly implemented at the highest levels of abstraction possible. This is what we see as the result of popular libraries like &lt;code&gt;scikit-learn&lt;/code&gt; and the body of &lt;code&gt;R&lt;/code&gt; packages. One can also find the same efforts for proximal methods themselves–e.g. in &lt;span class="citation" data-cites="svaiter_pyprox_2017"&gt;(svaiter 2017)&lt;/span&gt;, where individual functions for ADMM, forward-backward/proximal gradient and Douglas-Rachford are the end result. This is the most common approach and it makes sense in terms of simplicity, but offers very little of the extensibility, generalization, or efficiencies provided by shared efforts across related projects and fields.&lt;/p&gt;
&lt;p&gt;In the context of Theano, implementations immediately benefit from its code conversion, parallelization and relevant improvements to its basic graph optimizations. The latter covers both low-level computational efficiency–such as relevant application of BLAS functions–and high-level tensor algebra simplifications.&lt;/p&gt;
&lt;p&gt;In a development community that builds on these tools, related efficiency and performance gains can occur much more often, without necessarily sacrificing the specificity inherent to certain areas of application. For example, we can safely use the Rao-Blackwell theorem as the basis of a graph optimization in PyMC3, so it could be included among that project’s default offerings; however, it would be far too cumbersome to use productively in a less specific context.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="bibliography" class="level1 unnumbered"&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id="refs" class="references"&gt;
&lt;div id="ref-beck_fast_2014"&gt;
&lt;p&gt;Beck, Amir, and Marc Teboulle. 2014. “A Fast Dual Proximal Gradient Algorithm for Convex Minimization and Applications.” &lt;em&gt;Operations Research Letters&lt;/em&gt; 42 (1): 1–6. &lt;a href="http://www.sciencedirect.com/science/article/pii/S0167637713001454" class="uri"&gt;http://www.sciencedirect.com/science/article/pii/S0167637713001454&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-beeson_meaning_2005"&gt;
&lt;p&gt;Beeson, Michael, and Freek Wiedijk. 2005. “The Meaning of Infinity in Calculus and Computer Algebra Systems.” &lt;em&gt;Journal of Symbolic Computation&lt;/em&gt;, Automated reasoning and computer algebra systems (ar-ca)AR-ca, 39 (5): 523–38. &lt;a href="https://www.sciencedirect.com/science/article/pii/S074771710500026X" class="uri"&gt;https://www.sciencedirect.com/science/article/pii/S074771710500026X&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-bergstra_theano_2010"&gt;
&lt;p&gt;Bergstra, James, Olivier Breuleux, Frédéric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. 2010. “Theano: A CPU and GPU Math Expression Compiler.” In &lt;em&gt;Proceedings of the Python for Scientific Computing Conference (SciPy)&lt;/em&gt;. Austin, TX.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-bertsekas_incremental_2010"&gt;
&lt;p&gt;Bertsekas, Dimitri P. 2010. “Incremental Gradient, Subgradient, and Proximal Methods for Convex Optimization: A Survey.” &lt;a href="http://web.mit.edu/dimitrib/www/Incremental_Survey_LIDS.pdf" class="uri"&gt;http://web.mit.edu/dimitrib/www/Incremental_Survey_LIDS.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-chaux_variational_2007"&gt;
&lt;p&gt;Chaux, Caroline, Patrick L Combettes, Jean-Christophe Pesquet, and Valérie R Wajs. 2007. “A Variational Formulation for Frame-Based Inverse Problems.” &lt;em&gt;Inverse Problems&lt;/em&gt; 23 (4): 1495.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-combettes_proximal_2011"&gt;
&lt;p&gt;Combettes, Patrick L, and Jean-Christophe Pesquet. 2011. “Proximal Splitting Methods in Signal Processing.” &lt;em&gt;Fixed-Point Algorithms for Inverse Problems in Science and Engineering&lt;/em&gt;, 185–212.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-diamond_cvxpy:_2016"&gt;
&lt;p&gt;Diamond, Steven, and Stephen Boyd. 2016. “CVXPY: A Python-Embedded Modeling Language for Convex Optimization.” &lt;em&gt;Journal of Machine Learning Research&lt;/em&gt; 17 (83): 1–5.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-friedman_pathwise_2007"&gt;
&lt;p&gt;Friedman, Jerome, Trevor Hastie, Holger Höfling, Robert Tibshirani, and others. 2007. “Pathwise Coordinate Optimization.” &lt;em&gt;The Annals of Applied Statistics&lt;/em&gt; 1 (2): 302–32. &lt;a href="http://projecteuclid.org/euclid.aoas/1196438020" class="uri"&gt;http://projecteuclid.org/euclid.aoas/1196438020&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-mazumder_regularization_2009"&gt;
&lt;p&gt;Mazumder, Rahul, Trevor Hastie, and Rob Tibshirani. 2009. “Regularization Methods for Learning Incomplete Matrices.” &lt;em&gt;arXiv Preprint arXiv:0906.2034&lt;/em&gt;. &lt;a href="https://arxiv.org/abs/0906.2034" class="uri"&gt;https://arxiv.org/abs/0906.2034&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-parikh_proximal_2014"&gt;
&lt;p&gt;Parikh, Neal, and Stephen Boyd. 2014. “Proximal Algorithms.” &lt;em&gt;Foundations and Trends in Optimization&lt;/em&gt; 1 (3): 123–231. &lt;a href="https://doi.org/10.1561/2400000003" class="uri"&gt;https://doi.org/10.1561/2400000003&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-polson_proximal_2015"&gt;
&lt;p&gt;Polson, Nicholas G., James G. Scott, and Brandon T. Willard. 2015. “Proximal Algorithms in Statistics and Machine Learning.” &lt;em&gt;Statistical Science&lt;/em&gt; 30 (4): 559–81. &lt;a href="http://projecteuclid.org/euclid.ss/1449670858" class="uri"&gt;http://projecteuclid.org/euclid.ss/1449670858&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-roberts_updating_1997"&gt;
&lt;p&gt;Roberts, Gareth O., and Sujit K. Sahu. 1997. “Updating Schemes, Correlation Structure, Blocking and Parameterization for the Gibbs Sampler.” &lt;em&gt;Journal of the Royal Statistical Society: Series B (Statistical Methodology)&lt;/em&gt; 59 (2): 291–317. &lt;a href="http://onlinelibrary.wiley.com/doi/10.1111/1467-9868.00070/abstract" class="uri"&gt;http://onlinelibrary.wiley.com/doi/10.1111/1467-9868.00070/abstract&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-salvatier_probabilistic_2016"&gt;
&lt;p&gt;Salvatier, John, Thomas V. Wiecki, and Christopher Fonnesbeck. 2016. “Probabilistic Programming in Python Using PyMC3.” &lt;em&gt;PeerJ Computer Science&lt;/em&gt; 2 (April): e55. &lt;a href="https://peerj.com/articles/cs-55" class="uri"&gt;https://peerj.com/articles/cs-55&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-scikit-learn_sklearn.linear_model.elasticnet_2017"&gt;
&lt;p&gt;scikit-learn. 2017. “Sklearn.Linear_model.ElasticNet Scikit-Learn 0.19.Dev0 Documentation.” &lt;a href="http://scikit-learn.org/dev/modules/generated/sklearn.linear_model.ElasticNet.html\#sklearn-linear-model-elasticnet" class="uri"&gt;http://scikit-learn.org/dev/modules/generated/sklearn.linear_model.ElasticNet.html\#sklearn-linear-model-elasticnet&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-svaiter_pyprox_2017"&gt;
&lt;p&gt;svaiter. 2017. “Pyprox.” &lt;a href="https://github.com/svaiter/pyprox" class="uri"&gt;https://github.com/svaiter/pyprox&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-willard_role_2017"&gt;
&lt;p&gt;Willard, Brandon T. 2017. “A Role for Symbolic Computation in the General Estimation of Statistical Models.” &lt;a href="https://brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html" class="uri"&gt;https://brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-wytock_new_2016"&gt;
&lt;p&gt;Wytock, Matt, Steven Diamond, Felix Heide, and Stephen Boyd. 2016. “A New Architecture for Optimization Modeling Frameworks.” &lt;em&gt;arXiv Preprint arXiv:1609.03488&lt;/em&gt;. &lt;a href="https://arxiv.org/abs/1609.03488" class="uri"&gt;https://arxiv.org/abs/1609.03488&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content></entry><entry><title>A Role for Symbolic Computation in the General Estimation of Statistical Models</title><link href="https://brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html" rel="alternate"></link><published>2017-01-18T00:00:00-06:00</published><updated>2017-01-18T00:00:00-06:00</updated><author><name>Brandon T. Willard</name></author><id>tag:brandonwillard.github.io,2017-01-18:/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon T. Willard" /&gt;
  &lt;title&gt;A Role for Symbolic Computation in the General Estimation of Statistical Models&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;style type="text/css"&gt;
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  &lt;/style&gt;
  &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;A Role for Symbolic Computation in the General Estimation of Statistical Models&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon T. Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2017–01–18&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;section id="introduction" class="level1"&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this document we describe how symbolic computation can be used to provide generalizable statistical estimation through a combination of existing open source frameworks. Specifically, we will show how symbolic tools can be used to address the estimation of non-smooth functions that appear in models with parameter regularization, shrinkage and sparsity. We employ a mathematical framework that makes extensive use of &lt;em&gt;proximal operators&lt;/em&gt; &lt;span class="citation" data-cites="parikh_proximal_2014 combettes_proximal_2011"&gt;(Parikh and Boyd 2014; Combettes and Pesquet 2011)&lt;/span&gt; and their properties for maximum a posteriori (MAP) estimation: i.e. the &lt;em&gt;proximal framework&lt;/em&gt;. This framework produces what we’ll call &lt;em&gt;proximal methods&lt;/em&gt; and their implementations as &lt;em&gt;proximal algorithms&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;span class="citation" data-cites="polson_proximal_2015"&gt;Polson, Scott, and Willard (2015)&lt;/span&gt; we outlined a set of seemingly disparate optimization techniques within the fields of statistics, computer vision, and machine learning (e.g. gradient descent, ADMM, EM, Douglas-Rachford) that are unified by their various applications of proximal methods. These methods–and the concepts behind them–have found much success in recent times and admit quite a few interesting paths for research. In other words, there are many reasons to alone discuss the implementation of proximal methods.&lt;/p&gt;
&lt;p&gt;Proximal operators also enjoy a breadth of closed-form solutions and useful properties that are amenable to symbolic computation. In more than a few cases, the work required to produce a proximal algorithm overlaps with well-established features of computer algebra systems and symbolic mathematics, such as symbolic differentiation and algebraic equation solving.&lt;/p&gt;
&lt;p&gt;Symbolic integration provides an excellent example of how proximal operators could be implemented in a symbolic system. In these systems, mappings between functions (as canonicalized graphs) and their generalized hypergeometric equivalents are used to exploit the latter’s relevant convolution identities. In the same vein, it is possible to use tables of closed-form proximal operators and their properties to produce a wide array of estimation algorithms for many non-smooth functions. We outline how this might be done in the following sections.&lt;/p&gt;
&lt;p&gt;Otherwise, the ideas discussed here are part of a never-ending attempt to answer a question that arises naturally in both mathematics and programming–at all levels: &lt;em&gt;How does one provide a means of generating robust solutions to as many problems as possible?&lt;/em&gt; Instead of the common efforts to independently implement each model, method and/or combination of the two–followed by their placement in an API or library of functions–implementations can be encoded in and organized by the very mathematics from which they were derived. This close coupling between mathematical principles and their implementations might be the only reasonable way to remove barriers between theory, research and practice.&lt;/p&gt;
&lt;section id="a-context" class="level2"&gt;
&lt;h2&gt;A Context&lt;/h2&gt;
&lt;p&gt;Much recent work in statistical modeling and estimation has had the goal of producing sparse results and/or efficient, near automatic model selection. This objective is shared with other related practices–such as Deep Learning and Compressed Sensing. In the former case, we can point to Dropout &lt;span class="citation" data-cites="srivastava_dropout_2014"&gt;(Srivastava et al. 2014)&lt;/span&gt; and–in the latter–&lt;span class="math inline"&gt;\(\ell_p\)&lt;/span&gt; regularization &lt;span class="citation" data-cites="donoho_compressed_2006"&gt;(Donoho 2006)&lt;/span&gt; as basic examples.&lt;/p&gt;
&lt;p&gt;Here we’ll simply assume that a practitioner intends to produce sparse estimates using the well-known LASSO–or &lt;span class="math inline"&gt;\(\ell_1\)&lt;/span&gt; penalty.&lt;/p&gt;
&lt;p&gt;In PyMC3 &lt;span class="citation" data-cites="salvatier_probabilistic_2016"&gt;(Salvatier, Wiecki, and Fonnesbeck 2016)&lt;/span&gt;, the Bayes version of LASSO &lt;span class="citation" data-cites="park_bayesian_2008"&gt;(Park and Casella 2008)&lt;/span&gt; is easily specified.&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; numpy &lt;span class="im"&gt;as&lt;/span&gt; np&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" data-line-number="2"&gt;&lt;span class="im"&gt;import&lt;/span&gt; scipy &lt;span class="im"&gt;as&lt;/span&gt; sc&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" data-line-number="4"&gt;&lt;span class="im"&gt;import&lt;/span&gt; pymc3 &lt;span class="im"&gt;as&lt;/span&gt; pm&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" data-line-number="5"&gt;&lt;span class="im"&gt;import&lt;/span&gt; theano&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" data-line-number="6"&gt;&lt;span class="im"&gt;import&lt;/span&gt; theano.tensor &lt;span class="im"&gt;as&lt;/span&gt; tt&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-7" data-line-number="7"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano &lt;span class="im"&gt;import&lt;/span&gt; shared &lt;span class="im"&gt;as&lt;/span&gt; tt_shared&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-9" data-line-number="9"&gt;theano.config.mode &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;FAST_COMPILE&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-11" data-line-number="11"&gt;mu_true &lt;span class="op"&gt;=&lt;/span&gt; np.zeros(&lt;span class="dv"&gt;100&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-12" data-line-number="12"&gt;mu_true[:&lt;span class="dv"&gt;20&lt;/span&gt;] &lt;span class="op"&gt;=&lt;/span&gt; np.exp(&lt;span class="op"&gt;-&lt;/span&gt;np.arange(&lt;span class="dv"&gt;20&lt;/span&gt;)) &lt;span class="op"&gt;*&lt;/span&gt; &lt;span class="dv"&gt;100&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-14" data-line-number="14"&gt;X &lt;span class="op"&gt;=&lt;/span&gt; np.random.randn(&lt;span class="bu"&gt;int&lt;/span&gt;(np.alen(mu_true) &lt;span class="op"&gt;*&lt;/span&gt; &lt;span class="fl"&gt;0.7&lt;/span&gt;), np.alen(mu_true))&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-15" data-line-number="15"&gt;y &lt;span class="op"&gt;=&lt;/span&gt; sc.stats.norm.rvs(loc&lt;span class="op"&gt;=&lt;/span&gt;X.dot(mu_true), scale&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-17" data-line-number="17"&gt;X_tt &lt;span class="op"&gt;=&lt;/span&gt; tt_shared(X, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;X&amp;#39;&lt;/span&gt;, borrow&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-18" data-line-number="18"&gt;y_tt &lt;span class="op"&gt;=&lt;/span&gt; tt_shared(y, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, borrow&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-19" data-line-number="19"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-20" data-line-number="20"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model() &lt;span class="im"&gt;as&lt;/span&gt; lasso_model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-21" data-line-number="21"&gt;    &lt;span class="co"&gt;# Would be nice if we could pass the symbolic y_tt.shape, so&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-22" data-line-number="22"&gt;    &lt;span class="co"&gt;# that our model would automatically conform to changes in&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-23" data-line-number="23"&gt;    &lt;span class="co"&gt;# the shared variables X_tt.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-24" data-line-number="24"&gt;    &lt;span class="co"&gt;# See https://github.com/pymc-devs/pymc3/pull/1125&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-25" data-line-number="25"&gt;    beta_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Laplace(&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;0&lt;/span&gt;, b&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;, shape&lt;span class="op"&gt;=&lt;/span&gt;X.shape[&lt;span class="dv"&gt;1&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-26" data-line-number="26"&gt;    y_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;X_tt.dot(beta_rv), sd&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-27" data-line-number="27"&gt;                     shape&lt;span class="op"&gt;=&lt;/span&gt;y.shape[&lt;span class="dv"&gt;0&lt;/span&gt;], observed&lt;span class="op"&gt;=&lt;/span&gt;y_tt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, the negative total log likelihood in our example has a non-smooth &lt;span class="math inline"&gt;\(\ell_1\)&lt;/span&gt; term. Keeping this in mind, let’s say we wanted to produce a MAP estimate using PyMC3. A function is already provided for this task: &lt;code&gt;find_MAP&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" data-line-number="1"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; lasso_model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" data-line-number="2"&gt;    params_0 &lt;span class="op"&gt;=&lt;/span&gt; pm.find_MAP(&lt;span class="bu"&gt;vars&lt;/span&gt;&lt;span class="op"&gt;=&lt;/span&gt;[beta_rv])&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In our run of the above, an exception was thrown due to &lt;code&gt;nan&lt;/code&gt; values within the gradient evaluation. We can inspect the gradient at &lt;span class="math inline"&gt;\(\beta = 0, 1\)&lt;/span&gt; and reproduce the result.&lt;/p&gt;
&lt;div class="sourceCode" id="cb3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb3-1" data-line-number="1"&gt;start &lt;span class="op"&gt;=&lt;/span&gt; pm.Point({&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;: np.zeros(X.shape[&lt;span class="dv"&gt;1&lt;/span&gt;])}, model&lt;span class="op"&gt;=&lt;/span&gt;lasso_model)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-2" data-line-number="2"&gt;bij &lt;span class="op"&gt;=&lt;/span&gt; pm.DictToArrayBijection(pm.ArrayOrdering(lasso_model.&lt;span class="bu"&gt;vars&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-3" data-line-number="3"&gt;start)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-4" data-line-number="4"&gt;logp &lt;span class="op"&gt;=&lt;/span&gt; bij.mapf(lasso_model.fastlogp)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-5" data-line-number="5"&gt;dlogp &lt;span class="op"&gt;=&lt;/span&gt; bij.mapf(lasso_model.fastdlogp(lasso_model.&lt;span class="bu"&gt;vars&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-7" data-line-number="7"&gt;&lt;span class="co"&gt;# Could also inspect the log likelihood of the prior:&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-8" data-line-number="8"&gt;&lt;span class="co"&gt;# beta_rv.dlogp().f(np.zeros_like(start[&amp;#39;beta&amp;#39;]))&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-10" data-line-number="10"&gt;grad_at_0 &lt;span class="op"&gt;=&lt;/span&gt; dlogp(np.zeros_like(start[&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;]))&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-11" data-line-number="11"&gt;grad_at_1 &lt;span class="op"&gt;=&lt;/span&gt; dlogp(np.ones_like(start[&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;]))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb4-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;print&lt;/span&gt;(np.&lt;span class="bu"&gt;sum&lt;/span&gt;(np.isnan(grad_at_0)))&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-2" data-line-number="2"&gt;&lt;span class="dv"&gt;100&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-3" data-line-number="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;print&lt;/span&gt;(np.&lt;span class="bu"&gt;sum&lt;/span&gt;(np.isnan(grad_at_1)))&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-4" data-line-number="4"&gt;&lt;span class="dv"&gt;0&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The s are not due to any short-coming of PyMC3; they only demonstrate a suitable place for our ideas and improvements. Additionally, by working within PyMC3, we can readily apply certain mathematical results. For instance, theorems that apply only to distributions. This idea is more relevant to the graph optimizations we consider later, but is still very important.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="the-proximal-context" class="level1"&gt;
&lt;h1&gt;The Proximal Context&lt;/h1&gt;
&lt;p&gt;We start with the essential ingredient: the proximal operator.&lt;/p&gt;
&lt;div class="Def" data-markdown="" data-title-name="[Proximal Operator]"&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
\operatorname*{prox}_{\phi}(x) =
    \operatorname*{argmin}_{z} \left\{
    \frac{1}{2} \left(z - x\right)^2 + \phi(z)
    \right\}
    \;.
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;As we mentioned earlier, the proximal operator is the main tool of proximal algorithms. Exact solutions to proximal operators exist for many &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt;, and, since they’re often quite simple in form, their computation is relatively cheap: a property that the proximal methods themselves can inherit.&lt;/p&gt;
&lt;p&gt;Consider the MAP estimation of a penalized likelihood, i.e. &lt;span class="math display"&gt;\[\begin{equation}
\beta^* = \operatorname*{argmin}_\beta \left\{ l(\beta) + \gamma \phi(\beta) \right\}
  \;,
  \label{eq:prox_problem}
\end{equation}\]&lt;/span&gt; where functions &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt; are commonly referred to as likelihood and prior terms (or loss and penalty), respectively. The proximal framework usually assumes &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt; are at least lower semi-continuous and convex–although quite a few useful results still hold for non-convex functions.&lt;/p&gt;
&lt;p&gt;Notice that Equation &lt;span class="math inline"&gt;\(\eqref{eq:prox_problem}\)&lt;/span&gt; takes the form of a proximal operator when &lt;span class="math inline"&gt;\(l(\beta) = \frac{1}{2} (y - \beta)^2\)&lt;/span&gt;. Otherwise, in regression problems, we have &lt;span class="math inline"&gt;\(l(\beta) = \frac{1}{2} \|y - X \beta\|^2\)&lt;/span&gt;. In this case, properties of the proximal operator can be used to produce independent proximal operators in each dimension of &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt;. Since more than one property of the proximal operator can accomplish this–and result in distinct approaches–one might begin to see here a reason for the breadth of proximal methods.&lt;/p&gt;
&lt;p&gt;The proximal operator relevant to our example, &lt;span class="math inline"&gt;\(\operatorname*{prox}_{|\cdot|}\)&lt;/span&gt;, is equivalent to the soft-thresholding operator. Its implementation in Theano is somewhat trivial, but–for the sake of exposition–we provide an example.&lt;/p&gt;
&lt;div class="sourceCode" id="cb5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb5-1" data-line-number="1"&gt;beta_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;, dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-2" data-line-number="2"&gt;beta_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.r_[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;, &lt;span class="dv"&gt;-1&lt;/span&gt;, &lt;span class="fl"&gt;-0.2&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="fl"&gt;0.2&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-3" data-line-number="3"&gt;&lt;span class="dv"&gt;10&lt;/span&gt;].astype(tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-5" data-line-number="5"&gt;lambda_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.scalar(&lt;span class="st"&gt;&amp;#39;lambda&amp;#39;&lt;/span&gt;, dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-6" data-line-number="6"&gt;lambda_tt.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array(&lt;span class="fl"&gt;0.5&lt;/span&gt;).astype(tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-8" data-line-number="8"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; soft_threshold(beta_, lambda_):&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-9" data-line-number="9"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; tt.sgn(beta_) &lt;span class="op"&gt;*&lt;/span&gt; tt.maximum(tt.abs_(beta_) &lt;span class="op"&gt;-&lt;/span&gt; lambda_, &lt;span class="dv"&gt;0&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb6-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;print&lt;/span&gt;(soft_threshold(beta_tt, lambda_tt).tag.test_value)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-2" data-line-number="2"&gt;[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;9.5&lt;/span&gt; &lt;span class="fl"&gt;-0.5&lt;/span&gt; &lt;span class="fl"&gt;-0.&lt;/span&gt;   &lt;span class="fl"&gt;0.&lt;/span&gt;   &lt;span class="fl"&gt;0.&lt;/span&gt;   &lt;span class="fl"&gt;0.5&lt;/span&gt;  &lt;span class="fl"&gt;9.5&lt;/span&gt;]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Proximal operators can be composed with a gradient step to produce the &lt;em&gt;proximal gradient&lt;/em&gt; algorithm: &lt;span class="math display"&gt;\[\begin{equation}
\beta = \operatorname*{prox}_{\alpha \lambda \phi}(\beta - \alpha \nabla l(\beta))
  \;.
  \label{eq:forward-backward}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Besides the proximal operator for &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt;, steps in the proximal gradient algorithm are very straightforward and require only the gradient of &lt;span class="math inline"&gt;\(l(\beta)\)&lt;/span&gt;. This is where a tangible benefit of symbolic computation becomes apparent: &lt;span class="math inline"&gt;\(\nabla l(\beta)\)&lt;/span&gt; can be computed automatically and efficiently. With [backtracking] line search to handle unknown step sizes, &lt;span class="math inline"&gt;\(\alpha\)&lt;/span&gt;, the proximal gradient algorithm provides a surprisingly general means of sparse estimation.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="the-symbolic-operations" class="level1"&gt;
&lt;h1&gt;The Symbolic Operations&lt;/h1&gt;
&lt;p&gt;In order to identify a relevant, non-smooth problem, check that a given proximal method’s conditions are satisfied (e.g. convexity), and potentially solve the resulting proximal operators in closed-form, we need to obtain expressions for &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In some cases, we’re able to tease apart &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt; using only the interface provided by PyMC3. Specifically, the &lt;em&gt;observed&lt;/em&gt; and &lt;em&gt;unobserved&lt;/em&gt; random variable fields in PyMC3 models.&lt;/p&gt;
&lt;div class="sourceCode" id="cb7"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb7-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano &lt;span class="im"&gt;import&lt;/span&gt; clone &lt;span class="im"&gt;as&lt;/span&gt; tt_clone&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-3" data-line-number="3"&gt;logl &lt;span class="op"&gt;=&lt;/span&gt; tt_clone(lasso_model.observed_RVs[&lt;span class="dv"&gt;0&lt;/span&gt;].logpt,&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-4" data-line-number="4"&gt;                {beta_rv: beta_tt})&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-5" data-line-number="5"&gt;logl.name &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;logl&amp;quot;&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Instead, let’s assume we’re extending &lt;code&gt;find_MAP&lt;/code&gt; with even more generality, so that we can’t determine &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt; in this way. This situation can occur when a user specifies custom distributions or potential functions. Regardless, we need to operate at a more symbolic level.&lt;/p&gt;
&lt;div class="remark" data-markdown="" data-title-name=""&gt;
&lt;p&gt;At this point, it is extremely worthwhile to browse the &lt;a href="http://deeplearning.net/software/theano/extending/graphstructures.html"&gt;Theano documentation&lt;/a&gt; regarding graphs and their constituent objects.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The total log-likelihood is a good place to start. Let’s look at the symbolic graph for the log-likelihood of our model.&lt;/p&gt;
&lt;div class="sourceCode" id="cb8"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb8-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano &lt;span class="im"&gt;import&lt;/span&gt; pp &lt;span class="im"&gt;as&lt;/span&gt; tt_pp&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-2" data-line-number="2"&gt;&lt;span class="im"&gt;from&lt;/span&gt; theano &lt;span class="im"&gt;import&lt;/span&gt; pprint &lt;span class="im"&gt;as&lt;/span&gt; tt_pprint&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb9"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb9-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;print&lt;/span&gt;(tt_pp(lasso_model.logpt))&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-2" data-line-number="2"&gt;(Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64}(Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64}(((&lt;span class="op"&gt;-&lt;/span&gt;log(TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;}))&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-3" data-line-number="3"&gt;&lt;span class="op"&gt;-&lt;/span&gt; (&lt;span class="op"&gt;|&lt;/span&gt;(&lt;span class="op"&gt;\&lt;/span&gt;beta &lt;span class="op"&gt;-&lt;/span&gt; TensorConstant{&lt;span class="dv"&gt;0&lt;/span&gt;})&lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;/&lt;/span&gt; TensorConstant{&lt;span class="dv"&gt;1&lt;/span&gt;})))) &lt;span class="op"&gt;+&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-4" data-line-number="4"&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64}(Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64}(switch(TensorConstant{&lt;span class="dv"&gt;1&lt;/span&gt;},&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-5" data-line-number="5"&gt;(((TensorConstant{&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;1.0&lt;/span&gt;} &lt;span class="op"&gt;*&lt;/span&gt; ((y &lt;span class="op"&gt;-&lt;/span&gt; (X &lt;span class="op"&gt;\&lt;/span&gt;dot &lt;span class="op"&gt;\&lt;/span&gt;beta)) &lt;span class="op"&gt;**&lt;/span&gt; TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;}))&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-6" data-line-number="6"&gt;&lt;span class="op"&gt;+&lt;/span&gt; log(TensorConstant{&lt;span class="fl"&gt;0.159154943092&lt;/span&gt;})) &lt;span class="op"&gt;/&lt;/span&gt; TensorConstant{&lt;span class="fl"&gt;2.0&lt;/span&gt;}),&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-7" data-line-number="7"&gt;TensorConstant{&lt;span class="op"&gt;-&lt;/span&gt;inf}))))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;a href="http://deeplearning.net/software/theano/tutorial/printing_drawing.html#pretty-printing"&gt;pretty printed&lt;/a&gt; Theano graph tells us–among other things–that we indeed have a sum of &lt;span class="math inline"&gt;\(\ell_2\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\ell_1\)&lt;/span&gt; terms, although they are found among other confusing results (such as a &lt;code&gt;switch&lt;/code&gt; statement).&lt;/p&gt;
&lt;p&gt;As with most graphs produced by symbolic algebra systems, we need to understand how operations and objects are expressed in a graph and exactly which ones are relevant to us. After doing so, we can develop a means of finding what we want. The &lt;a href="http://deeplearning.net/software/theano/tutorial/printing_drawing.html#debug-print"&gt;debug printout&lt;/a&gt; is often a better visual summary of graphs, since it expresses branches clearly.&lt;/p&gt;
&lt;div class="sourceCode" id="cb10"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb10-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; tt.printing.debugprint(lasso_model.logpt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-2" data-line-number="2"&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; A] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-3" data-line-number="3"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64} [&lt;span class="bu"&gt;id&lt;/span&gt; B] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-4" data-line-number="4"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64} [&lt;span class="bu"&gt;id&lt;/span&gt; C] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-5" data-line-number="5"&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{sub,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; D] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-6" data-line-number="6"&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; E] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-7" data-line-number="7"&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{neg,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; F] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-8" data-line-number="8"&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{log,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; G] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-9" data-line-number="9"&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; H]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-10" data-line-number="10"&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{true_div,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; I] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-11" data-line-number="11"&gt; &lt;span class="op"&gt;|&lt;/span&gt;       &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{abs_,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; J] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-12" data-line-number="12"&gt; &lt;span class="op"&gt;|&lt;/span&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{sub,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; K] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-13" data-line-number="13"&gt; &lt;span class="op"&gt;|&lt;/span&gt;       &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;beta [&lt;span class="bu"&gt;id&lt;/span&gt; L]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-14" data-line-number="14"&gt; &lt;span class="op"&gt;|&lt;/span&gt;       &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; M] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-15" data-line-number="15"&gt; &lt;span class="op"&gt;|&lt;/span&gt;       &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;0&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; N]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-16" data-line-number="16"&gt; &lt;span class="op"&gt;|&lt;/span&gt;       &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; O] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-17" data-line-number="17"&gt; &lt;span class="op"&gt;|&lt;/span&gt;         &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;1&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; P]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-18" data-line-number="18"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64} [&lt;span class="bu"&gt;id&lt;/span&gt; Q] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-19" data-line-number="19"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64} [&lt;span class="bu"&gt;id&lt;/span&gt; R] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-20" data-line-number="20"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{switch,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; S] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-21" data-line-number="21"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; T] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-22" data-line-number="22"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;1&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; P]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-23" data-line-number="23"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{true_div,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; U] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-24" data-line-number="24"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; V] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-25" data-line-number="25"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; W] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-26" data-line-number="26"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; X] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-27" data-line-number="27"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;1.0&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; Y]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-28" data-line-number="28"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{&lt;span class="bu"&gt;pow&lt;/span&gt;,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; Z] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-29" data-line-number="29"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{sub,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; BA] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-30" data-line-number="30"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;y [&lt;span class="bu"&gt;id&lt;/span&gt; BB]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-31" data-line-number="31"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;dot [&lt;span class="bu"&gt;id&lt;/span&gt; BC] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-32" data-line-number="32"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;X [&lt;span class="bu"&gt;id&lt;/span&gt; BD]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-33" data-line-number="33"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;beta [&lt;span class="bu"&gt;id&lt;/span&gt; L]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-34" data-line-number="34"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; BE] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-35" data-line-number="35"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; H]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-36" data-line-number="36"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; BF] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-37" data-line-number="37"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{log,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; BG] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-38" data-line-number="38"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="fl"&gt;0.159154943092&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; BH]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-39" data-line-number="39"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; BI] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-40" data-line-number="40"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="fl"&gt;2.0&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; BJ]&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-41" data-line-number="41"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; BK] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-42" data-line-number="42"&gt;         &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="op"&gt;-&lt;/span&gt;inf} [&lt;span class="bu"&gt;id&lt;/span&gt; BL]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We see that the top-most operator is an &lt;code&gt;Elemwise&lt;/code&gt; that applies the scalar &lt;code&gt;add&lt;/code&gt; operation. This is the “&lt;span class="math inline"&gt;\(+\)&lt;/span&gt;” in &lt;span class="math inline"&gt;\(l + \phi\)&lt;/span&gt;. If we were to consider the inputs of this operator as candidates for &lt;span class="math inline"&gt;\(l\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\phi\)&lt;/span&gt;, then we could do the following:&lt;/p&gt;
&lt;div class="sourceCode" id="cb11"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb11-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;print&lt;/span&gt;(lasso_model.logpt.owner.inputs)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-2" data-line-number="2"&gt;[Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64}.&lt;span class="dv"&gt;0&lt;/span&gt;, Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64}.&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Starting from the sub-graphs of each term, we could then search for any non-smooth functions that have known closed-form proximal operators. In our case, we only consider the absolute value function.&lt;/p&gt;
&lt;div class="sourceCode" id="cb12"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb12-1" data-line-number="1"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; get_abs_between(input_node):&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-2" data-line-number="2"&gt;    &lt;span class="co"&gt;&amp;quot;&amp;quot;&amp;quot; Search for `abs` in the operations between our input and the&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-3" data-line-number="3"&gt;&lt;span class="co"&gt;    log-likelihood output node.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-4" data-line-number="4"&gt;&lt;span class="co"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-5" data-line-number="5"&gt;    term_ops &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;list&lt;/span&gt;(tt.gof.graph.ops([input_node],&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-6" data-line-number="6"&gt;[lasso_model.logpt]))&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-8" data-line-number="8"&gt;    &lt;span class="co"&gt;# Is there an absolute value in there?&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-9" data-line-number="9"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;filter&lt;/span&gt;(&lt;span class="kw"&gt;lambda&lt;/span&gt; x: x.op &lt;span class="kw"&gt;is&lt;/span&gt; tt.abs_, term_ops)&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-11" data-line-number="11"&gt;abs_res &lt;span class="op"&gt;=&lt;/span&gt; [(get_abs_between(in_), in_)&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-12" data-line-number="12"&gt;           &lt;span class="cf"&gt;for&lt;/span&gt; in_ &lt;span class="kw"&gt;in&lt;/span&gt; lasso_model.logpt.owner.inputs]&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-14" data-line-number="14"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; r_ &lt;span class="kw"&gt;in&lt;/span&gt; abs_res:&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-15" data-line-number="15"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; &lt;span class="bu"&gt;len&lt;/span&gt;(r_[&lt;span class="dv"&gt;0&lt;/span&gt;]) &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-16" data-line-number="16"&gt;        phi &lt;span class="op"&gt;=&lt;/span&gt; r_[&lt;span class="dv"&gt;1&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-17" data-line-number="17"&gt;    &lt;span class="cf"&gt;else&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-18" data-line-number="18"&gt;        logp &lt;span class="op"&gt;=&lt;/span&gt; r_[&lt;span class="dv"&gt;1&lt;/span&gt;]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb13"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb13-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; tt.printing.debugprint(logp)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-2" data-line-number="2"&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64} [&lt;span class="bu"&gt;id&lt;/span&gt; A] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-3" data-line-number="3"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64} [&lt;span class="bu"&gt;id&lt;/span&gt; B] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-4" data-line-number="4"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{switch,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; C] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-5" data-line-number="5"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; D] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-6" data-line-number="6"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;1&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; E]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-7" data-line-number="7"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{true_div,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; F] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-8" data-line-number="8"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; G] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-9" data-line-number="9"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; H] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-10" data-line-number="10"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; I] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-11" data-line-number="11"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="fl"&gt;1.0&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; J]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-12" data-line-number="12"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{&lt;span class="bu"&gt;pow&lt;/span&gt;,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; K] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-13" data-line-number="13"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{sub,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; L] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-14" data-line-number="14"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;y [&lt;span class="bu"&gt;id&lt;/span&gt; M]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-15" data-line-number="15"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;dot [&lt;span class="bu"&gt;id&lt;/span&gt; N] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-16" data-line-number="16"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;X [&lt;span class="bu"&gt;id&lt;/span&gt; O]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-17" data-line-number="17"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;beta [&lt;span class="bu"&gt;id&lt;/span&gt; P]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-18" data-line-number="18"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; Q] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-19" data-line-number="19"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; R]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-20" data-line-number="20"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; S] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-21" data-line-number="21"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{log,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; T] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-22" data-line-number="22"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="fl"&gt;0.159154943092&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; U]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-23" data-line-number="23"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; V] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-24" data-line-number="24"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="fl"&gt;2.0&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; W]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-25" data-line-number="25"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; X] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-26" data-line-number="26"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="op"&gt;-&lt;/span&gt;inf} [&lt;span class="bu"&gt;id&lt;/span&gt; Y]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-27" data-line-number="27"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; tt.printing.debugprint(phi)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-28" data-line-number="28"&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64} [&lt;span class="bu"&gt;id&lt;/span&gt; A] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-29" data-line-number="29"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Sum{acc_dtype&lt;span class="op"&gt;=&lt;/span&gt;float64} [&lt;span class="bu"&gt;id&lt;/span&gt; B] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-30" data-line-number="30"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{sub,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; C] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-31" data-line-number="31"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; D] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-32" data-line-number="32"&gt;     &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{neg,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; E] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-33" data-line-number="33"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{log,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; F] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-34" data-line-number="34"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; G]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-35" data-line-number="35"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{true_div,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; H] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-36" data-line-number="36"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{abs_,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; I] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-37" data-line-number="37"&gt;       &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{sub,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; J] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-38" data-line-number="38"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;beta [&lt;span class="bu"&gt;id&lt;/span&gt; K]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-39" data-line-number="39"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;   &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; L] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-40" data-line-number="40"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;0&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; M]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-41" data-line-number="41"&gt;       &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; N] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-42" data-line-number="42"&gt;         &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;1&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; O]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above approach is still too limiting; we need something more robust. For instance, our logic could fail on graphs that are expressed as &lt;span class="math inline"&gt;\(\eta (l + \phi) + 1\)&lt;/span&gt;–although a graph for the equivalent expression &lt;span class="math inline"&gt;\(\eta l + \eta \phi + \eta\)&lt;/span&gt; might succeed. These are types of weaknesses inherent to naive approaches like ours. Furthermore, sufficient logic that uses a similar approach is likely to result in complicated and less approachable code.&lt;/p&gt;
&lt;p&gt;The appropriate computational tools are found in the subjects of graph unification and term rewriting, as well as the areas of functional and logic programming. Luckily, Theano provides some basic unification capabilities through its &lt;code&gt;PatternSub&lt;/code&gt; class.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;PatternSub&lt;/code&gt; works within the context of Theano &lt;a href="http://deeplearning.net/software/theano/optimizations.html"&gt;graph optimization&lt;/a&gt;. Graph optimizations perform the common symbolic operations of reduction/simplification and rewriting. Consider the &lt;code&gt;phi&lt;/code&gt; variable; the print-outs show an unnecessary subtraction with &lt;span class="math inline"&gt;\(0\)&lt;/span&gt;. Clearly this step is unnecessary, so–in a basic way–we can see that the graph hasn’t been simplified, yet.&lt;/p&gt;
&lt;p&gt;Many standard algebraic simplifications are already present in Theano, and, by creating our own graph optimizations, we can provide the advanced functionality we’ve been alluding to.&lt;/p&gt;
&lt;div class="example" data-markdown="" data-title-name="[Algebraic Graph Optimization]"&gt;
&lt;p&gt;As a quick demonstration, we’ll make replacement patterns for multiplicative distribution across two forms of addition: &lt;code&gt;sum&lt;/code&gt; and &lt;code&gt;add&lt;/code&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb14"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb14-1" data-line-number="1"&gt;test_a_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.as_tensor_variable(&lt;span class="dv"&gt;5&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-2" data-line-number="2"&gt;test_b_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.as_tensor_variable(&lt;span class="dv"&gt;2&lt;/span&gt;, name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-3" data-line-number="3"&gt;test_c_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.as_tensor_variable(np.r_[&lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;], name&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-5" data-line-number="5"&gt;test_exprs_tt &lt;span class="op"&gt;=&lt;/span&gt; (test_a_tt &lt;span class="op"&gt;*&lt;/span&gt; test_b_tt,)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-6" data-line-number="6"&gt;test_exprs_tt &lt;span class="op"&gt;+=&lt;/span&gt; (test_a_tt &lt;span class="op"&gt;*&lt;/span&gt; (test_b_tt &lt;span class="op"&gt;+&lt;/span&gt; test_a_tt),)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-7" data-line-number="7"&gt;test_exprs_tt &lt;span class="op"&gt;+=&lt;/span&gt; (test_a_tt &lt;span class="op"&gt;*&lt;/span&gt; (test_c_tt &lt;span class="op"&gt;+&lt;/span&gt; test_a_tt),)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-8" data-line-number="8"&gt;test_exprs_tt &lt;span class="op"&gt;+=&lt;/span&gt; (test_a_tt &lt;span class="op"&gt;*&lt;/span&gt; (test_c_tt &lt;span class="op"&gt;+&lt;/span&gt; test_c_tt),)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-10" data-line-number="10"&gt;mul_dist_pat_tt &lt;span class="op"&gt;=&lt;/span&gt; (tt.gof.opt.PatternSub(&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-11" data-line-number="11"&gt;    (tt.mul, &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, (tt.&lt;span class="bu"&gt;sum&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;)),&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-12" data-line-number="12"&gt;    (tt.&lt;span class="bu"&gt;sum&lt;/span&gt;, (tt.mul, &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;), (tt.mul, &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-13" data-line-number="13"&gt;),)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-14" data-line-number="14"&gt;mul_dist_pat_tt &lt;span class="op"&gt;+=&lt;/span&gt; (tt.gof.opt.PatternSub(&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-15" data-line-number="15"&gt;    (tt.mul, &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, (tt.add, &lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;)),&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-16" data-line-number="16"&gt;    (tt.add, (tt.mul, &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;), (tt.mul, &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;z&amp;#39;&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-17" data-line-number="17"&gt;),)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Substitutions can be applied to an objective function until it is in a fully-reduced form: &lt;code&gt;EquilibriumOptimizer&lt;/code&gt; provides this functionality.&lt;/p&gt;
&lt;div class="sourceCode" id="cb15"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb15-1" data-line-number="1"&gt;test_sub_eqz_opt_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.gof.opt.EquilibriumOptimizer(&lt;/a&gt;
&lt;a class="sourceLine" id="cb15-2" data-line-number="2"&gt;    mul_dist_pat_tt, max_use_ratio&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb15-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb15-4" data-line-number="4"&gt;test_fgraph_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.gof.fg.FunctionGraph(&lt;/a&gt;
&lt;a class="sourceLine" id="cb15-5" data-line-number="5"&gt;    tt.gof.graph.inputs(test_exprs_tt), test_exprs_tt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb16"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb16-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; tt.printing.debugprint(test_fgraph_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-2" data-line-number="2"&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; A] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;5&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-3" data-line-number="3"&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-4" data-line-number="4"&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; C]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-5" data-line-number="5"&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; D] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;8&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-6" data-line-number="6"&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-7" data-line-number="7"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; E] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;4&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-8" data-line-number="8"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; C]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-9" data-line-number="9"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-10" data-line-number="10"&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; F] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;9&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-11" data-line-number="11"&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; G] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;3&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-12" data-line-number="12"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-13" data-line-number="13"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; H] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;7&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-14" data-line-number="14"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{[&lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt;]} [&lt;span class="bu"&gt;id&lt;/span&gt; I]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-15" data-line-number="15"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; J] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;2&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-16" data-line-number="16"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-17" data-line-number="17"&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; K] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;6&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-18" data-line-number="18"&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; L] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;1&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-19" data-line-number="19"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-20" data-line-number="20"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; M] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;0&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-21" data-line-number="21"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{[&lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt;]} [&lt;span class="bu"&gt;id&lt;/span&gt; I]&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-22" data-line-number="22"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{[&lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt;]} [&lt;span class="bu"&gt;id&lt;/span&gt; I]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, when we apply the optimization, the &lt;code&gt;FunctionGraph&lt;/code&gt; should contain the replacements.&lt;/p&gt;
&lt;div class="sourceCode" id="cb17"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb17-1" data-line-number="1"&gt;test_fgraph_opt &lt;span class="op"&gt;=&lt;/span&gt; test_sub_eqz_opt_tt.optimize(test_fgraph_tt)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb18"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb18-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; tt.printing.debugprint(test_fgraph_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-2" data-line-number="2"&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; A] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;5&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-3" data-line-number="3"&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-4" data-line-number="4"&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; C]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-5" data-line-number="5"&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; D] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;10&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-6" data-line-number="6"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; E] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;4&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-7" data-line-number="7"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-8" data-line-number="8"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;2&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; C]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-9" data-line-number="9"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; F] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;3&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-10" data-line-number="10"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-11" data-line-number="11"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-12" data-line-number="12"&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; G] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;12&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-13" data-line-number="13"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; H] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;9&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-14" data-line-number="14"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; I] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;2&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-15" data-line-number="15"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-16" data-line-number="16"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{[&lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt;]} [&lt;span class="bu"&gt;id&lt;/span&gt; J]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-17" data-line-number="17"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; K] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;8&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-18" data-line-number="18"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; I] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;2&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-19" data-line-number="19"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; L] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;1&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-20" data-line-number="20"&gt;     &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-21" data-line-number="21"&gt;Elemwise{add,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; M] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;11&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-22" data-line-number="22"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; N] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;7&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-23" data-line-number="23"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; O] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;0&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-24" data-line-number="24"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{&lt;span class="dv"&gt;5&lt;/span&gt;} [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-25" data-line-number="25"&gt; &lt;span class="op"&gt;|&lt;/span&gt; &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{[&lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt;]} [&lt;span class="bu"&gt;id&lt;/span&gt; J]&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-26" data-line-number="26"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Elemwise{mul,no_inplace} [&lt;span class="bu"&gt;id&lt;/span&gt; P] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;6&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-27" data-line-number="27"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;DimShuffle{x} [&lt;span class="bu"&gt;id&lt;/span&gt; O] &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;0&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb18-28" data-line-number="28"&gt;   &lt;span class="op"&gt;|&lt;/span&gt;TensorConstant{[&lt;span class="dv"&gt;1&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt;]} [&lt;span class="bu"&gt;id&lt;/span&gt; J]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Even more symbolic capabilities might be needed to [efficiently] achieve the functionality we desire. Standalone libraries like SymPy and &lt;a href="https://github.com/logpy/logpy/"&gt;LogPy&lt;/a&gt; can be adapted to Theano graphs and provide these capabilities–although direct implementation in Theano may be better.&lt;/p&gt;
&lt;p&gt;Finally, let’s briefly imagine how convexity could be determined symbolically. For differentiable terms, we could start with a simple second derivative test. Within Theano, a “second derivative” can be obtained using the &lt;code&gt;hessian&lt;/code&gt; function, and within &lt;code&gt;theano.sandbox.linalg&lt;/code&gt; are &lt;code&gt;Optimizer&lt;/code&gt; hints for matrix positivity and other properties relevant to determining convexity.&lt;/p&gt;
&lt;div class="remark" data-markdown="" data-title-name=""&gt;
&lt;p&gt;Other great examples of linear algebra themed optimizations are in &lt;code&gt;theano.sandbox.linalg&lt;/code&gt;: for instance, &lt;code&gt;no_transpose_symmetric&lt;/code&gt;. Some of these demonstrate exactly how straight-forward adding algebraic features can be.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Although our convexity testing idea is far too simple for some functions, the point is that the basic tools necessary for work in this direction are already in place. With the logic programming and symbolic libraries mentioned earlier, a robust implementation of the convex function calculus could be very much in reach.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="discussion" class="level1"&gt;
&lt;h1&gt;Discussion&lt;/h1&gt;
&lt;p&gt;We’ve sketched out some ideas and tools with which one could develop a robust estimation platform guided by the more abstract mathematical frameworks from which new and efficient methods are produced.&lt;/p&gt;
&lt;p&gt;Some key steps may require the integration of a fully featured symbolic algebra system. Along these lines, connections between Theano, SymPy and LogPy have been explored in &lt;span class="citation" data-cites="rocklin_mathematically_2013"&gt;Rocklin (2013)&lt;/span&gt;–as well as many other important aspects of the topics discussed here.&lt;/p&gt;
&lt;p&gt;Besides the automation of proximal algorithms themselves, there are areas of application involving very large and complex models–perhaps the ones arising in Deep Learning. How might we consider the operator splitting of ADMM within deeply layered or hierarchical models &lt;span class="citation" data-cites="polson_statistical_2015"&gt;(Polson, Willard, and Heidari 2015)&lt;/span&gt;? At which levels and on which terms should the splitting be performed? Beyond trying to solve the potentially unwieldy mathematics arising from such questions, by imbuing these symbolic tools with more mathematical awareness, we can at least experiment in these directions and quickly offer numerical solutions. This is–in part–the edge from which statistics hasn’t been benefiting and modern machine learning has.&lt;/p&gt;
&lt;p&gt;Before closing, a very related–and interesting–set of ideas is worth mentioning: the possibility of encoding more symbolic knowledge into probabilistic programming platforms like PyMC3. Using the same optimization mechanisms as the examples here, simple distributional relationships can be encoded. For instance, the convolution of normally distributed random variables:&lt;/p&gt;
&lt;div class="sourceCode" id="cb19"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb19-1" data-line-number="1"&gt;mu_X &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;mu_X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-2" data-line-number="2"&gt;mu_X.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;1.&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-3" data-line-number="3"&gt;sd_X &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;sd_X&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-4" data-line-number="4"&gt;sd_X.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;2.&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-6" data-line-number="6"&gt;mu_Y &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;mu_Y&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-7" data-line-number="7"&gt;mu_Y.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;1.&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-8" data-line-number="8"&gt;sd_Y &lt;span class="op"&gt;=&lt;/span&gt; tt.vector(&lt;span class="st"&gt;&amp;#39;sd_Y&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-9" data-line-number="9"&gt;sd_Y.tag.test_value &lt;span class="op"&gt;=&lt;/span&gt; np.array([&lt;span class="fl"&gt;0.5&lt;/span&gt;], dtype&lt;span class="op"&gt;=&lt;/span&gt;tt.config.floatX)&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-11" data-line-number="11"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model() &lt;span class="im"&gt;as&lt;/span&gt; conv_model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-12" data-line-number="12"&gt;    X_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;X&amp;#39;&lt;/span&gt;, mu_X, sd&lt;span class="op"&gt;=&lt;/span&gt;sd_X, shape&lt;span class="op"&gt;=&lt;/span&gt;(&lt;span class="dv"&gt;1&lt;/span&gt;,))&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-13" data-line-number="13"&gt;    Y_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;, mu_Y, sd&lt;span class="op"&gt;=&lt;/span&gt;sd_Y, shape&lt;span class="op"&gt;=&lt;/span&gt;(&lt;span class="dv"&gt;1&lt;/span&gt;,))&lt;/a&gt;
&lt;a class="sourceLine" id="cb19-14" data-line-number="14"&gt;    Z_rv &lt;span class="op"&gt;=&lt;/span&gt; X_rv &lt;span class="op"&gt;+&lt;/span&gt; Y_rv&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We create a Theano &lt;code&gt;Op&lt;/code&gt; to handle the convolution.&lt;/p&gt;
&lt;div class="sourceCode" id="cb20"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb20-1" data-line-number="1"&gt;&lt;span class="kw"&gt;class&lt;/span&gt; NormConvOp(tt.Op):&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-2" data-line-number="2"&gt;    __props__ &lt;span class="op"&gt;=&lt;/span&gt; ()&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-4" data-line-number="4"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; make_node(&lt;span class="va"&gt;self&lt;/span&gt;, &lt;span class="op"&gt;*&lt;/span&gt;inputs):&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-5" data-line-number="5"&gt;        name_new &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;str&lt;/span&gt;.join(&lt;span class="st"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;, [&lt;span class="bu"&gt;getattr&lt;/span&gt;(in_, &lt;span class="st"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;&amp;#39;&lt;/span&gt;) &lt;span class="cf"&gt;for&lt;/span&gt; in_ &lt;span class="kw"&gt;in&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-6" data-line-number="6"&gt;inputs])&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-7" data-line-number="7"&gt;        mu_new &lt;span class="op"&gt;=&lt;/span&gt; tt.add(&lt;span class="op"&gt;*&lt;/span&gt;[in_.distribution.mu &lt;span class="cf"&gt;for&lt;/span&gt; in_ &lt;span class="kw"&gt;in&lt;/span&gt; inputs])&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-8" data-line-number="8"&gt;        sd_new &lt;span class="op"&gt;=&lt;/span&gt; tt.sqrt(tt.add(&lt;span class="op"&gt;*&lt;/span&gt;[in_.distribution.sd&lt;span class="op"&gt;**&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt; &lt;span class="cf"&gt;for&lt;/span&gt; in_ &lt;span class="kw"&gt;in&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-9" data-line-number="9"&gt;inputs]))&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-10" data-line-number="10"&gt;        conv_rv &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(name_new, mu&lt;span class="op"&gt;=&lt;/span&gt;mu_new, sd&lt;span class="op"&gt;=&lt;/span&gt;sd_new,&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-11" data-line-number="11"&gt;                            &lt;span class="co"&gt;# Is this another place where&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-12" data-line-number="12"&gt;automatically&lt;span class="op"&gt;/&lt;/span&gt;Theano managed&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-13" data-line-number="13"&gt;                            &lt;span class="co"&gt;# shapes are really needed.  For now, we&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-14" data-line-number="14"&gt;hack it.&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-15" data-line-number="15"&gt;                            shape&lt;span class="op"&gt;=&lt;/span&gt;(&lt;span class="dv"&gt;1&lt;/span&gt;,))&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-17" data-line-number="17"&gt;        &lt;span class="cf"&gt;return&lt;/span&gt; tt.Apply(&lt;span class="va"&gt;self&lt;/span&gt;, inputs, [conv_rv])&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-19" data-line-number="19"&gt;    &lt;span class="kw"&gt;def&lt;/span&gt; perform(&lt;span class="va"&gt;self&lt;/span&gt;, node, inputs, output_storage):&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-20" data-line-number="20"&gt;        z &lt;span class="op"&gt;=&lt;/span&gt; output_storage[&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb20-21" data-line-number="21"&gt;        z[&lt;span class="dv"&gt;0&lt;/span&gt;] &lt;span class="op"&gt;=&lt;/span&gt; np.add(&lt;span class="op"&gt;*&lt;/span&gt;inputs)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, all that’s needed is a &lt;code&gt;PatternSub&lt;/code&gt; like before.&lt;/p&gt;
&lt;div class="sourceCode" id="cb21"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb21-1" data-line-number="1"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; is_normal_dist(x):&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-2" data-line-number="2"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; &lt;span class="bu"&gt;hasattr&lt;/span&gt;(x, &lt;span class="st"&gt;&amp;#39;distribution&amp;#39;&lt;/span&gt;) &lt;span class="kw"&gt;and&lt;/span&gt; &lt;span class="bu"&gt;isinstance&lt;/span&gt;(x.distribution,&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-3" data-line-number="3"&gt;pm.Normal)&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-5" data-line-number="5"&gt;norm_conv_pat_tt &lt;span class="op"&gt;=&lt;/span&gt; (tt.gof.opt.PatternSub(&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-6" data-line-number="6"&gt;    (tt.add,&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-7" data-line-number="7"&gt;     {&lt;span class="st"&gt;&amp;#39;pattern&amp;#39;&lt;/span&gt;: &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-8" data-line-number="8"&gt;      &lt;span class="st"&gt;&amp;#39;constraint&amp;#39;&lt;/span&gt;: &lt;span class="kw"&gt;lambda&lt;/span&gt; x: is_normal_dist(x)},&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-9" data-line-number="9"&gt;     {&lt;span class="st"&gt;&amp;#39;pattern&amp;#39;&lt;/span&gt;: &lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-10" data-line-number="10"&gt;      &lt;span class="st"&gt;&amp;#39;constraint&amp;#39;&lt;/span&gt;: &lt;span class="kw"&gt;lambda&lt;/span&gt; x: is_normal_dist(x)}&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-11" data-line-number="11"&gt;     ),&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-12" data-line-number="12"&gt;    (NormConvOp(), &lt;span class="st"&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;y&amp;#39;&lt;/span&gt;)),)&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-14" data-line-number="14"&gt;norm_conv_opt_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.gof.opt.EquilibriumOptimizer(norm_conv_pat_tt,&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-15" data-line-number="15"&gt;                                                   max_use_ratio&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-17" data-line-number="17"&gt;Z_fgraph_tt &lt;span class="op"&gt;=&lt;/span&gt; tt.gof.fg.FunctionGraph([X_rv, Y_rv], [Z_rv])&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-19" data-line-number="19"&gt;&lt;span class="co"&gt;# We lose the `FreeRV.distribution` attribute when cloning the graph&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-20" data-line-number="20"&gt;&lt;span class="co"&gt;# with `theano.gof.graph.clone_get_equiv` in `FunctionGraph`, so this&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-21" data-line-number="21"&gt;&lt;span class="co"&gt;# hackishly reattaches that information:&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-22" data-line-number="22"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; [&lt;span class="bu"&gt;setattr&lt;/span&gt;(g_in, &lt;span class="st"&gt;&amp;#39;distribution&amp;#39;&lt;/span&gt;, s_in.distribution)&lt;/a&gt;
&lt;a class="sourceLine" id="cb21-23" data-line-number="23"&gt;     &lt;span class="cf"&gt;for&lt;/span&gt; s_in, g_in &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;zip&lt;/span&gt;([X_rv, Y_rv], Z_fgraph_tt.inputs)]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb22"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb22-1" data-line-number="1"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; conv_model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb22-2" data-line-number="2"&gt;    _ &lt;span class="op"&gt;=&lt;/span&gt; norm_conv_opt_tt.optimize(Z_fgraph_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb22-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb22-4" data-line-number="4"&gt;norm_conv_var_dist &lt;span class="op"&gt;=&lt;/span&gt; Z_fgraph_tt.outputs[&lt;span class="dv"&gt;0&lt;/span&gt;].distribution&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The resulting graph:&lt;/p&gt;
&lt;div class="sourceCode" id="cb23"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb23-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; tt.printing.debugprint(Z_fgraph_tt)&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-2" data-line-number="2"&gt;NormConvOp [&lt;span class="bu"&gt;id&lt;/span&gt; A] &lt;span class="st"&gt;&amp;#39;X+Y&amp;#39;&lt;/span&gt;   &lt;span class="dv"&gt;0&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-3" data-line-number="3"&gt; &lt;span class="op"&gt;|&lt;/span&gt;X [&lt;span class="bu"&gt;id&lt;/span&gt; B]&lt;/a&gt;
&lt;a class="sourceLine" id="cb23-4" data-line-number="4"&gt; &lt;span class="op"&gt;|&lt;/span&gt;Y [&lt;span class="bu"&gt;id&lt;/span&gt; C]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the convolution’s parameters (for the test values):&lt;/p&gt;
&lt;div class="sourceCode" id="cb24"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb24-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;print&lt;/span&gt;(norm_conv_var_dist.mu.tag.test_value)&lt;/a&gt;
&lt;a class="sourceLine" id="cb24-2" data-line-number="2"&gt;[ &lt;span class="fl"&gt;2.&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb24-3" data-line-number="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="bu"&gt;print&lt;/span&gt;(norm_conv_var_dist.sd.tag.test_value)&lt;/a&gt;
&lt;a class="sourceLine" id="cb24-4" data-line-number="4"&gt;[ &lt;span class="fl"&gt;2.06155281&lt;/span&gt;]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;More sophisticated routines–like the example above–could implement parameter expansions, efficient re-parameterizations and equivalent scale mixture forms in an effort to optimize a graph for sampling or point evaluation. Objectives for these optimizations could be straightforward and computationally based (e.g. reducing the number of operations in computations of the log likelihood and other quantities) or more statistically focused (e.g. highly efficient sampling, improve mixing). These ideas are most definitely not new–one example is given by &lt;span class="citation" data-cites="mohasel_afshar_probabilistic_2016"&gt;Mohasel Afshar (2016)&lt;/span&gt; for symbolic Gibbs sampling, but we hope the examples given here make the point that the tools are readily available and quite accessible.&lt;/p&gt;
&lt;p&gt;We’ll end on a much more spacey consideration. Namely, that this is a context in which we can start experimenting rapidly with objectives over the space of estimation routines. This space is generated by–but not limited to–the variety of symbolic representations, re-parameterizations, etc., mentioned above. It does not necessarily require the complete estimation of a model at each step, nor even the numeric value of quantities like the gradient or Hessian. It may involve them, but not their evaluation; perhaps, instead, symbolic comparisons of competing gradients and Hessians arising from different representations. What we’re describing lies somewhere between the completely numeric assessments common today, and the entirely symbolic work found within the theorems and manipulations of the mathematics we use to derive methods.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="bibliography" class="level1 unnumbered"&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id="refs" class="references"&gt;
&lt;div id="ref-combettes_proximal_2011"&gt;
&lt;p&gt;Combettes, Patrick L, and Jean-Christophe Pesquet. 2011. “Proximal Splitting Methods in Signal Processing.” &lt;em&gt;Fixed-Point Algorithms for Inverse Problems in Science and Engineering&lt;/em&gt;, 185–212.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-donoho_compressed_2006"&gt;
&lt;p&gt;Donoho, David L. 2006. “Compressed Sensing.” &lt;em&gt;IEEE Transactions on Information Theory&lt;/em&gt; 52 (4): 1289–1306. &lt;a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1614066" class="uri"&gt;http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1614066&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-mohasel_afshar_probabilistic_2016"&gt;
&lt;p&gt;Mohasel Afshar, Hadi. 2016. “Probabilistic Inference in Piecewise Graphical Models.” &lt;a href="https://digitalcollections.anu.edu.au/handle/1885/107386" class="uri"&gt;https://digitalcollections.anu.edu.au/handle/1885/107386&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-parikh_proximal_2014"&gt;
&lt;p&gt;Parikh, Neal, and Stephen Boyd. 2014. “Proximal Algorithms.” &lt;em&gt;Foundations and Trends in Optimization&lt;/em&gt; 1 (3): 123–231. &lt;a href="https://doi.org/10.1561/2400000003" class="uri"&gt;https://doi.org/10.1561/2400000003&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-park_bayesian_2008"&gt;
&lt;p&gt;Park, Trevor, and George Casella. 2008. “The Bayesian Lasso.” &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 103 (482): 681–86. &lt;a href="http://amstat.tandfonline.com/doi/abs/10.1198/016214508000000337" class="uri"&gt;http://amstat.tandfonline.com/doi/abs/10.1198/016214508000000337&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-polson_proximal_2015"&gt;
&lt;p&gt;Polson, Nicholas G., James G. Scott, and Brandon T. Willard. 2015. “Proximal Algorithms in Statistics and Machine Learning.” &lt;em&gt;Statistical Science&lt;/em&gt; 30 (4): 559–81. &lt;a href="http://projecteuclid.org/euclid.ss/1449670858" class="uri"&gt;http://projecteuclid.org/euclid.ss/1449670858&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-polson_statistical_2015"&gt;
&lt;p&gt;Polson, Nicholas G., Brandon T. Willard, and Massoud Heidari. 2015. “A Statistical Theory of Deep Learning via Proximal Splitting.” &lt;em&gt;arXiv Preprint arXiv:1509.06061&lt;/em&gt;. &lt;a href="http://arxiv.org/abs/1509.06061" class="uri"&gt;http://arxiv.org/abs/1509.06061&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-rocklin_mathematically_2013"&gt;
&lt;p&gt;Rocklin, Matthew. 2013. “Mathematically Informed Linear Algebra Codes Through Term Rewriting.” PhD thesis, PhD Thesis, August. &lt;a href="http://people.cs.uchicago.edu/~mrocklin/storage/dissertation.pdf" class="uri"&gt;http://people.cs.uchicago.edu/~mrocklin/storage/dissertation.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-salvatier_probabilistic_2016"&gt;
&lt;p&gt;Salvatier, John, Thomas V. Wiecki, and Christopher Fonnesbeck. 2016. “Probabilistic Programming in Python Using PyMC3.” &lt;em&gt;PeerJ Computer Science&lt;/em&gt; 2 (April): e55. &lt;a href="https://peerj.com/articles/cs-55" class="uri"&gt;https://peerj.com/articles/cs-55&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-srivastava_dropout_2014"&gt;
&lt;p&gt;Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. “Dropout: A Simple Way to Prevent Neural Networks from Overfitting.” &lt;em&gt;The Journal of Machine Learning Research&lt;/em&gt; 15 (1): 1929–58. &lt;a href="http://dl.acm.org/citation.cfm?id=2670313" class="uri"&gt;http://dl.acm.org/citation.cfm?id=2670313&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content></entry><entry><title>Regarding Statistical Model Specification and Sample Results</title><link href="https://brandonwillard.github.io/regarding-statistical-model-specification-and-sample-results.html" rel="alternate"></link><published>2016-11-01T00:00:00-05:00</published><updated>2016-11-01T00:00:00-05:00</updated><author><name>Brandon Willard</name></author><id>tag:brandonwillard.github.io,2016-11-01:/regarding-statistical-model-specification-and-sample-results.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon Willard" /&gt;
  &lt;title&gt;Regarding Statistical Model Specification and Sample Results&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;style type="text/css"&gt;
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  &lt;/style&gt;
  &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;Regarding Statistical Model Specification and Sample Results&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2016–11–01&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;section id="introduction" class="level1"&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this post I want to address some concepts regarding statistical model specification within the Bayesian paradigm, motivation for its use, and the utility of sample results (e.g. empirical posterior distributions). This write-up isn’t intended to be thorough or self-contained, especially since numerous quality introductions already exist for Bayesian modeling and MCMC &lt;span class="citation" data-cites="gelman_bayesian_2013"&gt;(Gelman et al. 2013)&lt;/span&gt;. Instead, its purpose is to illustrate some specific points in the context of a simple, evolving problem that mirrors some real-life objectives. Also, what’s advocated here is in large part just &lt;em&gt;statistical&lt;/em&gt; modeling and not exclusively &lt;em&gt;Bayesian&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The generality, applicability and relative simplicity of the core concepts within Bayesian modeling are sadly overlooked in practice. Bayes is too often conflated with MCMC and its associated computational costs, or is seen as needlessly “mathy” and technical. I argue that there is an oft unacknowledged trade-off in the efforts of mathematical modeling, and that Bayesian modeling helps navigate that complexity. In doing so, one can save on expended efforts in the long run.&lt;/p&gt;
&lt;p&gt;When a model is [fully] specified in a statistical or Bayesian way, the modeler has at their disposal distributions for the unknown quantities of interest; these distributions are often the primary interest. The desired estimates are found “within” the distributions. For instance, as a distribution’s moments (e.g. mean, mode, variance, etc.), which may correspond to certain “best” estimates or measures of parameter uncertainty. The same goes for functions of these distributions (e.g. rolling sums and averages).&lt;/p&gt;
&lt;p&gt;Normally, modeling objectives are specified in terms of &lt;em&gt;point-estimates&lt;/em&gt; instead of distributions: like the aforementioned “best” parameter estimates. This situation is also covered by the Bayesian paradigm, especially when the corresponding distributions have a closed-form and are fully specified by a finite number of parameters. However, when this isn’t the case, point-estimates provide only part of the picture. It’s usually these missing parts that make model assessment and prediction largely separate and difficult endeavours down the road.&lt;/p&gt;
&lt;p&gt;Even so, modeling and estimation often proceeds without much statistical consideration or context, making these distributions–and the results they can provide–more and more inaccessible. In a situation where modeling started with common machine learning/statistical software and resulted in non-statistical extensions, the work needed for something like &lt;em&gt;uncertainty quantification or propagation&lt;/em&gt; broadly equates to retrofitting and/or defining the altered or missing statistical context of the problem. This sort of work necessarily requires a much rarer expertise, which is usually too difficult for outsiders to vet. Considerations like this might be reason enough to–at least minimally–maintain clear statistical assumptions throughout the life of a non-trivial project. The Bayesian approach can be a more accessible means of providing this type of statistical coherency.&lt;/p&gt;
&lt;p&gt;As a starting point, one can find quite a few non-Bayes models with Bayesian interpretations and counterparts. Even finding a Bayesian interpretation for an existing non-Bayes model can itself advance one’s understanding of the statistical assumptions and properties of the model. In some cases this understanding can inspire new forms of estimation or new non-Bayes variants of a model. Multiple examples arise from models defined by objective or loss functions with forms equivalent to the total log-likelihoods of Bayesian models. This, for instance, is one way that general point-wise estimates can be related to maximum a posteriori (MAP) estimates in the Bayesian context.&lt;/p&gt;
&lt;section id="notation" class="level3"&gt;
&lt;h3&gt;Notation&lt;/h3&gt;
&lt;p&gt;Before getting into the details, let’s cover some preliminaries regarding notation.&lt;/p&gt;
&lt;p&gt;The symbol &lt;span class="math inline"&gt;\(\sim\)&lt;/span&gt; is overloaded to mean a couple things. First, a statement like &lt;span class="math inline"&gt;\(X \sim \operatorname{P}\)&lt;/span&gt; means “&lt;span class="math inline"&gt;\(X\)&lt;/span&gt; is distributed according to &lt;span class="math inline"&gt;\(\operatorname{P}\)&lt;/span&gt;”, when &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; is understood to be a random variable (generally denoted by capital letter variables). Second, for a non-random variable &lt;span class="math inline"&gt;\(x\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(x \sim \operatorname{P}\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(x \sim X\)&lt;/span&gt; means “&lt;span class="math inline"&gt;\(x\)&lt;/span&gt; is a sample from distribution &lt;span class="math inline"&gt;\(\operatorname{P}\)&lt;/span&gt;”. When &lt;span class="math inline"&gt;\(\operatorname{P}\)&lt;/span&gt; is not meant to signify a distribution, but instead a generic function–like a probability density function &lt;span class="math inline"&gt;\(p(X=x) \equiv p(x)\)&lt;/span&gt;, then the distribution in question is [the] one arising from the function (interpreted as a probability density and/or measure)–when possible. See &lt;a href="https://en.wikipedia.org/wiki/Notation_in_probability_and_statistics"&gt;here&lt;/a&gt; for a similar notation. Also, whenever indices are dropped, the resulting symbol is assumed to be a stacked matrix containing each entry, e.g. &lt;span class="math display"&gt;\[\begin{equation*}
X^\top = \begin{pmatrix} X_1 &amp;amp; \dots &amp;amp; X_N \end{pmatrix} \;.
\end{equation*}\]&lt;/span&gt; When the indexed symbol is a vector, then it is customary to denote the row stacked matrix of each vector with the symbol’s capital letter. E.g., for [column] vectors &lt;span class="math inline"&gt;\(z_i\)&lt;/span&gt; over &lt;span class="math inline"&gt;\(i \in \{1, \dots, N\}\)&lt;/span&gt;, &lt;span class="math display"&gt;\[\begin{equation*}
Z = \begin{pmatrix} z_1 \\ \vdots \\ z_N \end{pmatrix} \;.
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="a-simple-model" class="level1"&gt;
&lt;h1&gt;A Simple Model&lt;/h1&gt;
&lt;p&gt;First, a simple normal-normal model &lt;span class="math display"&gt;\[\begin{equation}
Y_t \sim \operatorname{N}(x^\top_t \theta, \sigma^2), \quad
    \theta \sim \operatorname{N}(\mu, I \tau^2)
    \label{eq:normal-normal}
\end{equation}\]&lt;/span&gt; for an identity matrix &lt;span class="math inline"&gt;\(I\)&lt;/span&gt;, observed random variable &lt;span class="math inline"&gt;\(Y_t\)&lt;/span&gt; at time &lt;span class="math inline"&gt;\(t \in \{1, \dots, T\}\)&lt;/span&gt;, and known constant values (of matching dimensions) &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(\sigma\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(\mu\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\tau\)&lt;/span&gt;. The &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt; play the role of predictors, or features, and we’ll assume that the time dependencies arise primarily through them.&lt;/p&gt;
&lt;p&gt;In Bayes parlance, the model in Equation &lt;span class="math inline"&gt;\(\eqref{eq:normal-normal}\)&lt;/span&gt; gives &lt;span class="math inline"&gt;\(\theta\)&lt;/span&gt; a normal prior distribution, and the primary goal involves estimating the “posterior” distribution &lt;span class="math inline"&gt;\(p(\theta \mid y)\)&lt;/span&gt;–for a vector of observations &lt;span class="math inline"&gt;\(y\)&lt;/span&gt; under the assumption &lt;span class="math inline"&gt;\(y \sim Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This simple example has the well known closed-form posterior solution for &lt;span class="math inline"&gt;\(\theta\)&lt;/span&gt;, &lt;span class="math display"&gt;\[\begin{equation}
\left(\theta \mid y_t\right) \sim \operatorname{N}(m, C)
    \;.
    \label{eq:theta-posterior}
\end{equation}\]&lt;/span&gt; for &lt;span class="math display"&gt;\[\begin{equation*}
\begin{gathered}
  m = C \left(\mu \tau^{-2} + X^\top y\, \sigma^{-2}\right), \quad
  C = \left(\tau^{-2} + \operatorname{diag}(X^\top X) \sigma^{-2}\right)^{-1}
  \;.\end{gathered}
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Results like this are easily obtained for the classical pairings of “conjugate” distributions. Detailed &lt;a href="https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions"&gt;tables&lt;/a&gt; and &lt;a href="https://goo.gl/UCL3pc"&gt;tutorials&lt;/a&gt; for conjugate distributions can be found online or in any standard text.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="estimation-via-mcmc" class="level1"&gt;
&lt;h1&gt;Estimation (via MCMC)&lt;/h1&gt;
&lt;p&gt;From here on let’s assume we do not have the closed-form result in Equation &lt;span class="math inline"&gt;\(\eqref{eq:theta-posterior}\)&lt;/span&gt;. Instead, we’ll estimate the posterior numerically with &lt;a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"&gt;MCMC&lt;/a&gt;. Again, MCMC is covered to varying degrees of detail all over the place (e.g. &lt;a href="https://goo.gl/JNwfuo"&gt;here&lt;/a&gt;), so we’ll skip most of those details. Let’s say we’ve decided to use &lt;a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"&gt;Metropolis-Hastings&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For demonstration purposes, we produce a simulation of some data we might observe and for which we would consider applying the model in Equation &lt;span class="math inline"&gt;\(\eqref{eq:normal-normal}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; numpy &lt;span class="im"&gt;as&lt;/span&gt; np&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" data-line-number="2"&gt;&lt;span class="im"&gt;import&lt;/span&gt; scipy.stats &lt;span class="im"&gt;as&lt;/span&gt; scs&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" data-line-number="4"&gt;&lt;span class="co"&gt;# Unknown parameter&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" data-line-number="5"&gt;mu_true &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;1.5&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-7" data-line-number="7"&gt;&lt;span class="co"&gt;# [Assumed] known parameter&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-8" data-line-number="8"&gt;sigma2 &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;0.05&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-10" data-line-number="10"&gt;&lt;span class="co"&gt;# Prior parameters&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-11" data-line-number="11"&gt;tau2 &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;1e2&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-12" data-line-number="12"&gt;mu &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-14" data-line-number="14"&gt;&lt;span class="im"&gt;import&lt;/span&gt; pandas &lt;span class="im"&gt;as&lt;/span&gt; pd&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-16" data-line-number="16"&gt;start_datetime &lt;span class="op"&gt;=&lt;/span&gt; pd.tslib.Timestamp(pd.datetime.now())&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-17" data-line-number="17"&gt;sim_index &lt;span class="op"&gt;=&lt;/span&gt; pd.date_range(start&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;2016-01-01 12:00:00&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-18" data-line-number="18"&gt;                          end&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;2016-01-08 12:00:00&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-19" data-line-number="19"&gt;                          freq&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;H&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-20" data-line-number="20"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-21" data-line-number="21"&gt;&lt;span class="co"&gt;# Simulated observations&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-22" data-line-number="22"&gt;X &lt;span class="op"&gt;=&lt;/span&gt; np.sin(np.linspace(&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;2&lt;/span&gt;&lt;span class="op"&gt;*&lt;/span&gt;np.pi, np.alen(sim_index)))&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-23" data-line-number="23"&gt;y_obs &lt;span class="op"&gt;=&lt;/span&gt; scs.norm.rvs(loc&lt;span class="op"&gt;=&lt;/span&gt;X &lt;span class="op"&gt;*&lt;/span&gt; mu_true, scale&lt;span class="op"&gt;=&lt;/span&gt;np.sqrt(sigma2))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A Metropolis-Hastings sampler would perform a simple loop that accepts or rejects samples from a proposal distribution, &lt;span class="math inline"&gt;\(\theta_i \sim p(\theta_i \mid \theta_{i-1})\)&lt;/span&gt;, according to the probability &lt;span class="math display"&gt;\[\begin{equation*}
\min\left\{1,
  \frac{p(Y = y \mid X, \theta_i)}{p(Y = y \mid X, \theta_{i-1})}
  \frac{p(\theta_i \mid \theta_{i-1})}{p(\theta_{i-1} \mid \theta_i)}
  \right\}
  \;.
\end{equation*}\]&lt;/span&gt; Let’s say our proposal is a normal distribution with a mean equal to the previous sample and a variance given by &lt;span class="math inline"&gt;\(\lambda^2\)&lt;/span&gt;. The resulting sampling scheme is a random walk Metropolis-Hastings sampler, and since the proposal is a symmetric distribution, &lt;span class="math inline"&gt;\(\frac{p(\theta_i \mid \theta_{i-1})}{p(\theta_{i-1} \mid \theta_i)} = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In code, this could look like&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; functools &lt;span class="im"&gt;import&lt;/span&gt; partial&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-3" data-line-number="3"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; model_logpdf(theta_):&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-4" data-line-number="4"&gt;    res &lt;span class="op"&gt;=&lt;/span&gt; np.&lt;span class="bu"&gt;sum&lt;/span&gt;(scs.norm.logpdf(y_obs, loc&lt;span class="op"&gt;=&lt;/span&gt;X &lt;span class="op"&gt;*&lt;/span&gt; theta_,&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-5" data-line-number="5"&gt;                                 scale&lt;span class="op"&gt;=&lt;/span&gt;np.sqrt(sigma2)))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-6" data-line-number="6"&gt;    res &lt;span class="op"&gt;+=&lt;/span&gt; scs.norm.logpdf(theta_, loc&lt;span class="op"&gt;=&lt;/span&gt;mu,&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-7" data-line-number="7"&gt;                           scale&lt;span class="op"&gt;=&lt;/span&gt;np.sqrt(tau2))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-8" data-line-number="8"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; res&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-10" data-line-number="10"&gt;N_samples &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;2000&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-11" data-line-number="11"&gt;theta_samples &lt;span class="op"&gt;=&lt;/span&gt; []&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-12" data-line-number="12"&gt;lam &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;1.&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-13" data-line-number="13"&gt;current_sample &lt;span class="op"&gt;=&lt;/span&gt; np.random.normal(loc&lt;span class="op"&gt;=&lt;/span&gt;mu, scale&lt;span class="op"&gt;=&lt;/span&gt;lam)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-14" data-line-number="14"&gt;proposal_logpdf &lt;span class="op"&gt;=&lt;/span&gt; partial(scs.norm.logpdf, scale&lt;span class="op"&gt;=&lt;/span&gt;lam)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-16" data-line-number="16"&gt;&lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;xrange&lt;/span&gt;(N_samples):&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-17" data-line-number="17"&gt;    proposal_sample &lt;span class="op"&gt;=&lt;/span&gt; np.random.normal(loc&lt;span class="op"&gt;=&lt;/span&gt;current_sample,&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-18" data-line-number="18"&gt;                                       scale&lt;span class="op"&gt;=&lt;/span&gt;lam, size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-19" data-line-number="19"&gt;    l_ratio &lt;span class="op"&gt;=&lt;/span&gt; np.&lt;span class="bu"&gt;sum&lt;/span&gt;(model_logpdf(proposal_sample))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-20" data-line-number="20"&gt;    l_ratio &lt;span class="op"&gt;-=&lt;/span&gt; np.&lt;span class="bu"&gt;sum&lt;/span&gt;(model_logpdf(current_sample))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-21" data-line-number="21"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-22" data-line-number="22"&gt;    p_ratio &lt;span class="op"&gt;=&lt;/span&gt; np.&lt;span class="bu"&gt;sum&lt;/span&gt;(proposal_logpdf(current_sample,&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-23" data-line-number="23"&gt;                                     loc&lt;span class="op"&gt;=&lt;/span&gt;proposal_sample))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-24" data-line-number="24"&gt;    p_ratio &lt;span class="op"&gt;-=&lt;/span&gt; np.&lt;span class="bu"&gt;sum&lt;/span&gt;(proposal_logpdf(proposal_sample,&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-25" data-line-number="25"&gt;                                      loc&lt;span class="op"&gt;=&lt;/span&gt;current_sample))&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-26" data-line-number="26"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-27" data-line-number="27"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; np.log(np.random.uniform()) &lt;span class="op"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="bu"&gt;min&lt;/span&gt;(&lt;span class="dv"&gt;0&lt;/span&gt;, l_ratio &lt;span class="op"&gt;+&lt;/span&gt; p_ratio):&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-28" data-line-number="28"&gt;        current_sample &lt;span class="op"&gt;=&lt;/span&gt; proposal_sample&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-29" data-line-number="29"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb2-30" data-line-number="30"&gt;    theta_samples &lt;span class="op"&gt;+=&lt;/span&gt; [current_sample]&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The Metropolis-Hastings sampler does not rely on any prior information or Bayesian formulations. Although the prior is implicitly involved, via the total probability, the concepts behind the sampler itself are still valid without it. Basically, Metropolis-Hastings–like many other MCMC sampling routines–is not specifically Bayesian. It’s better to simply consider MCMC as just another estimation approach (or perhaps a type of stochastic optimization).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Gibbs_sampling"&gt;Gibbs sampling&lt;/a&gt; is arguably the other most ubiquitous MCMC technique. Since a model specified in a Bayesian way usually provides a clear joint distribution (or at least something proportional to it) and conditional probabilities, Gibbs sampling is well facilitated.&lt;/p&gt;
&lt;p&gt;The context of Bayesian modeling is, however, a good source of direction and motivation for improvements to a sampling procedure (and estimation in general). Under Bayesian assumptions, decompositions and reformulations for broad classes of distributions are often immediately available. Guiding generalities, like the &lt;a href="https://en.wikipedia.org/wiki/Rao%E2%80%93Blackwell_theorem"&gt;Rao-Blackwell&lt;/a&gt; theorem, are also applicable, and–more generally–the same principles, tools and results that guide the model creation and assessment process can also feed into the estimation process.&lt;/p&gt;
&lt;section id="the-situation-on-implementation" class="level2"&gt;
&lt;h2&gt;The Situation on Implementation&lt;/h2&gt;
&lt;p&gt;MCMC sampling schemes like the above are fairly general and easily abstracted, giving rise to some generic frameworks that put more focus on model specification and attempt to automate the choice of estimation (or implement one robust technique). Some of the more common frameworks are Bayesian in nature: &lt;a href="http://www.openbugs.net/w/FrontPage"&gt;OpenBUGS&lt;/a&gt;, &lt;a href="http://mcmc-jags.sourceforge.net/"&gt;JAGS&lt;/a&gt;, &lt;a href="http://mc-stan.org/"&gt;Stan&lt;/a&gt;, and &lt;a href="https://pymc-devs.github.io/pymc/"&gt;PyMC2&lt;/a&gt; / &lt;a href="https://pymc-devs.github.io/pymc3/"&gt;PyMC3&lt;/a&gt;. These libraries provide a sort of meta-language that facilitates the specification of a Bayesian model and mirrors the mathematical language of probability. They also implicitly implement the &lt;a href="https://en.wikipedia.org/wiki/Algebra_of_random_variables"&gt;algebra of random variables&lt;/a&gt; and automatically handle the mechanics of variable transforms.&lt;/p&gt;
&lt;p&gt;Our model, estimated with a Metropolis-Hastings sampler, can be expressed in PyMC3 with the following code:&lt;/p&gt;
&lt;div class="sourceCode" id="cb3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb3-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; pymc3 &lt;span class="im"&gt;as&lt;/span&gt; pm&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-2" data-line-number="2"&gt;&lt;span class="im"&gt;import&lt;/span&gt; theano&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-3" data-line-number="3"&gt;theano.config.mode &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;FAST_COMPILE&amp;#39;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-5" data-line-number="5"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model() &lt;span class="im"&gt;as&lt;/span&gt; model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-6" data-line-number="6"&gt;    &lt;span class="co"&gt;# Model definition&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-7" data-line-number="7"&gt;    theta &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;theta&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;mu, tau&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1.&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;tau2)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-8" data-line-number="8"&gt;    Y &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;X &lt;span class="op"&gt;*&lt;/span&gt; theta, tau&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1.&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;sigma2, observed&lt;span class="op"&gt;=&lt;/span&gt;y_obs)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-10" data-line-number="10"&gt;    &lt;span class="co"&gt;# Posterior sampling&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-11" data-line-number="11"&gt;    sample_steps &lt;span class="op"&gt;=&lt;/span&gt; pm.Metropolis()&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-12" data-line-number="12"&gt;    sample_traces &lt;span class="op"&gt;=&lt;/span&gt; pm.sample(&lt;span class="dv"&gt;2000&lt;/span&gt;, sample_steps)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre class="text"&gt;&lt;code&gt;Couldn&amp;#39;t import dot_parser, loading of dot files will not be possible.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As per the basic examples in the &lt;a href="https://goo.gl/WW3TO8"&gt;PyMC3 notebooks&lt;/a&gt;, the posterior samples are plotted below using the following code:&lt;/p&gt;
&lt;div class="sourceCode" id="cb5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb5-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class="im"&gt;as&lt;/span&gt; plt&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-3" data-line-number="3"&gt;plt.style.use(&lt;span class="st"&gt;&amp;#39;ggplot&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-4" data-line-number="4"&gt;plt.rc(&lt;span class="st"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;, usetex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-5" data-line-number="5"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb5-6" data-line-number="6"&gt;tp_axes &lt;span class="op"&gt;=&lt;/span&gt; pm.traceplot(sample_traces)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can also superimpose the true posterior density given by Equation &lt;span class="math inline"&gt;\(\eqref{eq:theta-posterior}\)&lt;/span&gt; with the following:&lt;/p&gt;
&lt;div class="sourceCode" id="cb6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb6-1" data-line-number="1"&gt;_ &lt;span class="op"&gt;=&lt;/span&gt; [a_.set_title(&lt;span class="vs"&gt;r&amp;#39;Posterior $(\theta \mid y)$ Samples&amp;#39;&lt;/span&gt;) &lt;span class="cf"&gt;for&lt;/span&gt; a_ &lt;span class="kw"&gt;in&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-2" data-line-number="2"&gt;tp_axes.ravel()]&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-4" data-line-number="4"&gt;freq_axis &lt;span class="op"&gt;=&lt;/span&gt; tp_axes[&lt;span class="dv"&gt;0&lt;/span&gt;][&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-5" data-line-number="5"&gt;freq_axis.set_xlabel(&lt;span class="vs"&gt;r&amp;#39;$\theta$&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-7" data-line-number="7"&gt;sample_axis &lt;span class="op"&gt;=&lt;/span&gt; tp_axes[&lt;span class="dv"&gt;0&lt;/span&gt;][&lt;span class="dv"&gt;1&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-8" data-line-number="8"&gt;sample_axis.set_xlabel(&lt;span class="vs"&gt;r&amp;#39;$i$&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-10" data-line-number="10"&gt;rhs &lt;span class="op"&gt;=&lt;/span&gt; np.dot(&lt;span class="fl"&gt;1.&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;tau2, mu) &lt;span class="op"&gt;+&lt;/span&gt; np.dot(X.T &lt;span class="op"&gt;/&lt;/span&gt; sigma2, y_obs)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-11" data-line-number="11"&gt;tau_post &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="fl"&gt;1.&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;tau2 &lt;span class="op"&gt;+&lt;/span&gt; np.dot(X.T &lt;span class="op"&gt;/&lt;/span&gt; sigma2, X)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-13" data-line-number="13"&gt;post_mean &lt;span class="op"&gt;=&lt;/span&gt; rhs&lt;span class="op"&gt;/&lt;/span&gt;tau_post&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-14" data-line-number="14"&gt;post_var_inv &lt;span class="op"&gt;=&lt;/span&gt; tau_post&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-16" data-line-number="16"&gt;post_pdf &lt;span class="op"&gt;=&lt;/span&gt; partial(scs.norm.pdf,&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-17" data-line-number="17"&gt;                   loc&lt;span class="op"&gt;=&lt;/span&gt;post_mean,&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-18" data-line-number="18"&gt;                   scale&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1.&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;np.sqrt(post_var_inv))&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-19" data-line-number="19"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-20" data-line-number="20"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-21" data-line-number="21"&gt;&lt;span class="kw"&gt;def&lt;/span&gt; add_function_plot(func, ax, num&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1e2&lt;/span&gt;, label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;None&lt;/span&gt;):&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-22" data-line-number="22"&gt;    post_range &lt;span class="op"&gt;=&lt;/span&gt; np.linspace(&lt;span class="op"&gt;*&lt;/span&gt;ax.get_xlim(),&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-23" data-line-number="23"&gt;                             num&lt;span class="op"&gt;=&lt;/span&gt;num, endpoint&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-24" data-line-number="24"&gt;    post_data &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;map&lt;/span&gt;(post_pdf, post_range)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-25" data-line-number="25"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-26" data-line-number="26"&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; ax.plot(post_range, post_data,&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-27" data-line-number="27"&gt;                   label&lt;span class="op"&gt;=&lt;/span&gt;label)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-28" data-line-number="28"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-29" data-line-number="29"&gt;&lt;span class="co"&gt;# Add true posterior pdf to the plot&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-30" data-line-number="30"&gt;add_function_plot(post_pdf, freq_axis,&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-31" data-line-number="31"&gt;                  label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="vs"&gt;r&amp;#39;Exact&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-32" data-line-number="32"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-33" data-line-number="33"&gt;&lt;span class="co"&gt;# Add manually produced MH samples to the plot&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-34" data-line-number="34"&gt;&lt;span class="im"&gt;import&lt;/span&gt; seaborn &lt;span class="im"&gt;as&lt;/span&gt; sns&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-35" data-line-number="35"&gt;sns.distplot(theta_samples[:&lt;span class="dv"&gt;2000&lt;/span&gt;], ax&lt;span class="op"&gt;=&lt;/span&gt;freq_axis, hist&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-36" data-line-number="36"&gt;                label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="vs"&gt;r&amp;#39;Manual MH&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-37" data-line-number="37"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-38" data-line-number="38"&gt;sample_axis.plot(theta_samples[:&lt;span class="dv"&gt;2000&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-39" data-line-number="39"&gt;                 label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="vs"&gt;r&amp;#39;Manual MH&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-40" data-line-number="40"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-41" data-line-number="41"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-42" data-line-number="42"&gt;freq_axis.legend()&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-43" data-line-number="43"&gt;sample_axis.legend()&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-44" data-line-number="44"&gt;plt.show()&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span id="fig:theta_post_plot"&gt;&lt;span id="fig:theta_post_plot_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{1}\label{fig:theta_post_plot}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;img src="https://brandonwillard.github.io/figures/regarding_sample_estimates_theta_post_plot_1.png" title="fig:" alt="Posterior samples" /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;section id="the-costs" class="level2"&gt;
&lt;h2&gt;The Costs&lt;/h2&gt;
&lt;p&gt;MCMC, and specifically the Metropolis-Hastings approach used above, can look very simple and universally applicable, but–of course–there’s a trade-off occurring somewhere. The trade-offs most often appear in relation to the complexity and cost of [intermediate] sampling steps and convergence rates. To over simplify, the standard &lt;span class="math inline"&gt;\(O(N^{-1/2})\)&lt;/span&gt; error rate–from the &lt;a href="https://en.wikipedia.org/wiki/Central_limit_theorem"&gt;Central Limit Theorem&lt;/a&gt;–is the MCMC baseline, which isn’t all that competitive with some of the standard deterministic optimization methods.&lt;/p&gt;
&lt;p&gt;Even for conceptually simple models, the proposal distribution (and its parameters) are not always easy to choose or cheap to tune. The upfront computational costs can be quite high for the more generic MCMC approaches, but there are almost always paths toward efficient samplers–in the context of a specific problem, at least.&lt;/p&gt;
&lt;p&gt;In practice, the generality and relative simplicity of the Bayes approach, combined with MCMC, can be somewhat misleading to newcomers. After some immediate success with simpler and/or scaled down problems, one is soon led to believe that the cost of direct computations and the effort and skill required to derive efficient methods is not worth the potential parsimony and extra information provided by sample results.&lt;/p&gt;
&lt;p&gt;The unfortunate outcome of this situation is sometimes an effective rejection of Bayes and MCMC altogether. Although the point hasn’t been illustrated here, MCMC isn’t the only option. &lt;strong&gt;Bayesian models are just as amenable to deterministic estimation as non-Bayesian ones&lt;/strong&gt;, and a wide array of efficient deterministic estimation techniques are available–albeit not so common in standard practice &lt;span class="citation" data-cites="polson_proximal_2015"&gt;(Polson, Scott, and Willard 2015)&lt;/span&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="predictions" class="level1"&gt;
&lt;h1&gt;Predictions&lt;/h1&gt;
&lt;p&gt;The sampling situation offered by MCMC (and Bayes) puts one in a nice situation to make extensive use of predictions &lt;em&gt;and&lt;/em&gt; obtain uncertainty measures (e.g. variances, credible intervals, etc.).&lt;/p&gt;
&lt;p&gt;In general, posterior predictive samples are fairly easy to obtain. Once you have posterior samples of &lt;span class="math inline"&gt;\(\theta\)&lt;/span&gt;, say &lt;span class="math inline"&gt;\(\{\theta_i\}_{i=0}^M\)&lt;/span&gt;, simply plug those into the sampling/observation distribution and sample &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt; values. Specifically, &lt;span class="math display"&gt;\[\begin{equation}
\{y_i \sim p(Y \mid X, \theta_i) : \theta_i \sim p(\theta_i \mid y)\}_{i=0}^M
  \label{eq:post_predict_samples}
\end{equation}\]&lt;/span&gt; is a posterior predictive sample from &lt;span class="math inline"&gt;\(p(Y \mid X, y)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The procedural interpretation of Equation &lt;span class="math inline"&gt;\(\eqref{eq:post_predict_samples}\)&lt;/span&gt; is:&lt;/p&gt;
&lt;ol type="1"&gt;
&lt;li&gt;&lt;p&gt;Sample &lt;span class="math inline"&gt;\(\theta_i \sim p(\theta_i \mid y)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sample &lt;span class="math inline"&gt;\(y_i \sim p(Y \mid X, \theta_i)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Assuming we’ve already produced a posterior sample, this is as simple as plugging those &lt;span class="math inline"&gt;\(\theta_i\)&lt;/span&gt; into the observation distribution Equation &lt;span class="math inline"&gt;\(\eqref{eq:normal-normal}\)&lt;/span&gt; and sampling. The cumulative effect of this process is equivalent to producing an estimate of the marginal &lt;span class="math display"&gt;\[\begin{equation*}
\int p(Y_t \mid x_t, \theta) p(\theta \mid y) d\theta = p(Y_t \mid x_t, y)
  \;.
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The posterior predictive sample in Equation &lt;span class="math inline"&gt;\(\eqref{eq:post_predict_samples}\)&lt;/span&gt; contains much of the information a modeler desires. Take the variance of this sample and one has a common measure of prediction error; produce quantiles of the sample and one has &lt;a href="https://en.wikipedia.org/wiki/Credible_interval"&gt;“credible”&lt;/a&gt; prediction intervals. The sample produced by mapping an arbitrary function to each posterior predictive sample is itself amenable to the aforementioned summaries, allowing one to easily produce errors for complicated uses of predicted quantities. We illustrate these use cases below.&lt;/p&gt;
&lt;p&gt;Using our previous simulation and PyMC3, the posterior predictive samples are obtained with&lt;/p&gt;
&lt;div class="sourceCode" id="cb7"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb7-1" data-line-number="1"&gt;ppc_samples &lt;span class="op"&gt;=&lt;/span&gt; pm.sample_ppc(sample_traces, model&lt;span class="op"&gt;=&lt;/span&gt;model)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and plotted with&lt;/p&gt;
&lt;div class="sourceCode" id="cb8"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb8-1" data-line-number="1"&gt;plt.clf()&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-2" data-line-number="2"&gt;ppc_hpd &lt;span class="op"&gt;=&lt;/span&gt; pm.hpd(ppc_samples[&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;], &lt;span class="fl"&gt;0.05&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-3" data-line-number="3"&gt;plt.fill_between(np.arange(np.alen(y_obs)),&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-4" data-line-number="4"&gt;                 ppc_hpd[:, &lt;span class="dv"&gt;0&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-5" data-line-number="5"&gt;                 ppc_hpd[:, &lt;span class="dv"&gt;1&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-6" data-line-number="6"&gt;                 label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="vs"&gt;r&amp;#39;$(Y \mid X, y)$ 95\&lt;/span&gt;&lt;span class="sc"&gt;% i&lt;/span&gt;&lt;span class="vs"&gt;nterval&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-7" data-line-number="7"&gt;                 alpha&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;0.5&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-8" data-line-number="8"&gt;plt.plot(y_obs, label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;$y$&amp;#39;&lt;/span&gt;, color&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-9" data-line-number="9"&gt;plt.plot(ppc_samples[&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;].mean(axis&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;0&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-10" data-line-number="10"&gt;         label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="vs"&gt;r&amp;#39;$E[Y \mid X, y]$&amp;#39;&lt;/span&gt;, alpha&lt;span class="op"&gt;=&lt;/span&gt;.&lt;span class="dv"&gt;7&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-11" data-line-number="11"&gt;plt.legend()&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-12" data-line-number="12"&gt;plt.show()&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span id="fig:hourly_ppc_plot"&gt;&lt;span id="fig:hourly_ppc_plot_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{2}\label{fig:hourly_ppc_plot}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;img src="https://brandonwillard.github.io/figures/regarding_sample_estimates_hourly_ppc_plot_1.png" title="fig:" alt="Posterior predictive samples" /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class="example" data-markdown="" data-title-name=""&gt;
&lt;p&gt;Let’s say we’re interested in daily, monthly, or yearly averages for &lt;span class="math inline"&gt;\(Y_t\)&lt;/span&gt; at a lower frequency–like minutes or hours. Similarly, we might want to consider functions of differences between the outputs of different models, &lt;span class="math inline"&gt;\(f(Y^{(j)} - Y^{(k)})\)&lt;/span&gt; for &lt;span class="math inline"&gt;\(j, k \in \{1, 2\}\)&lt;/span&gt;, or more generally &lt;span class="math inline"&gt;\(f(Y^{(j)}, Y^{(k)})\)&lt;/span&gt;. These quantities derived from simple manipulations of &lt;code&gt;ppc_hpd&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Next, we produce predictions for daily averages–along with [credible] intervals.&lt;/p&gt;
&lt;div class="sourceCode" id="cb9"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb9-1" data-line-number="1"&gt;y_obs_h &lt;span class="op"&gt;=&lt;/span&gt; pd.Series(y_obs, index&lt;span class="op"&gt;=&lt;/span&gt;sim_index)&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-3" data-line-number="3"&gt;ppc_samples_h &lt;span class="op"&gt;=&lt;/span&gt; pd.DataFrame(ppc_samples[&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;].T, index&lt;span class="op"&gt;=&lt;/span&gt;sim_index)&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-4" data-line-number="4"&gt;ppc_samples_h &lt;span class="op"&gt;=&lt;/span&gt; ppc_samples_h.stack()&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-5" data-line-number="5"&gt;ppc_samples_h &lt;span class="op"&gt;=&lt;/span&gt; ppc_samples_h[:,&lt;span class="dv"&gt;0&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-6" data-line-number="6"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-7" data-line-number="7"&gt;ppc_quantiles_d &lt;span class="op"&gt;=&lt;/span&gt; ppc_samples_h.resample(&lt;span class="st"&gt;&amp;#39;D&amp;#39;&lt;/span&gt;).&lt;span class="bu"&gt;apply&lt;/span&gt;(&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-8" data-line-number="8"&gt;    &lt;span class="kw"&gt;lambda&lt;/span&gt; x: x.quantile(q&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="fl"&gt;0.05&lt;/span&gt;, &lt;span class="fl"&gt;0.5&lt;/span&gt;, &lt;span class="fl"&gt;0.95&lt;/span&gt;]))&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-9" data-line-number="9"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-10" data-line-number="10"&gt;ppc_quantiles_d &lt;span class="op"&gt;=&lt;/span&gt; ppc_quantiles_d.unstack()&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-12" data-line-number="12"&gt;y_obs_d &lt;span class="op"&gt;=&lt;/span&gt; y_obs_h.resample(&lt;span class="st"&gt;&amp;#39;D&amp;#39;&lt;/span&gt;).mean()&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="sourceCode" id="cb10"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb10-1" data-line-number="1"&gt;plt.clf()&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-2" data-line-number="2"&gt;y_obs_d.plot(label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;$f(y)$&amp;#39;&lt;/span&gt;, color&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-3" data-line-number="3"&gt;plt.fill_between(ppc_quantiles_d.index,&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-4" data-line-number="4"&gt;                 ppc_quantiles_d[&lt;span class="fl"&gt;0.05&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-5" data-line-number="5"&gt;                 ppc_quantiles_d[&lt;span class="fl"&gt;0.95&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-6" data-line-number="6"&gt;                 label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="vs"&gt;r&amp;#39;$(f(Y) \mid X, y)$ 95\&lt;/span&gt;&lt;span class="sc"&gt;% i&lt;/span&gt;&lt;span class="vs"&gt;nterval&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-7" data-line-number="7"&gt;                 alpha&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;0.5&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-8" data-line-number="8"&gt;ppc_quantiles_d[&lt;span class="fl"&gt;0.5&lt;/span&gt;].plot(label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="vs"&gt;r&amp;#39;$E[f(Y) \mid X, y]$&amp;#39;&lt;/span&gt;, alpha&lt;span class="op"&gt;=&lt;/span&gt;.&lt;span class="dv"&gt;7&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-9" data-line-number="9"&gt;plt.legend()&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-10" data-line-number="10"&gt;plt.show()&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span id="fig:daily_ppc_plot"&gt;&lt;span id="fig:daily_ppc_plot_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{3}\label{fig:daily_ppc_plot}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;img src="https://brandonwillard.github.io/figures/regarding_sample_estimates_daily_ppc_plot_1.png" title="fig:" alt="Daily posterior predictive results from the hourly posterior." /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;section id="hierarchical-extensions" class="level1"&gt;
&lt;h1&gt;Hierarchical Extensions&lt;/h1&gt;
&lt;p&gt;Even though we only considered “in-sample” predictions in the previous section, out-of-sample and missing values are covered by exactly the same process (neatly simplified by PyMC3’s &lt;code&gt;sample_ppc&lt;/code&gt;). In our example we needed an exogenous variable &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt; in order to sample a point from the observation model &lt;span class="math inline"&gt;\((Y_t \mid x_t)\)&lt;/span&gt;. When the values in &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; cannot be obtained–e.g. future values of a non-deterministic quantity–clever, context specific imputations are usually proposed.&lt;/p&gt;
&lt;p&gt;Nearly every instance of such imputations gives rise to an implicit model. Going back to our preference for transparent statistical specification, it behooves us to formally specify the model. If we do so in a well-defined Bayes way, then we’re immediately provided the exact same conveniences as above.&lt;/p&gt;
&lt;div id="ex:X_temp" class="example" data-markdown="" data-title-name=""&gt;
&lt;p&gt;&lt;span id="ex:X_temp_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{2}\label{ex:X_temp}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If the &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; values in our sample now correspond to, say, temperature, and today is the last day in our time-indexed observations &lt;code&gt;y_obs&lt;/code&gt;, then predicting forward in time will require temperatures for the future.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;One answer to this situation is a model for &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt;. If we specify some &lt;span class="math inline"&gt;\(X_t \sim P\)&lt;/span&gt;, then we can apply the same principles above via the posterior predictive &lt;span class="math inline"&gt;\(p(X_t)\)&lt;/span&gt;. This posterior predictive will have no exogenous dependencies (unless we want it to), and its posterior can be estimated with our given &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; observations. All this occurs in exactly the same fashion as our model for &lt;span class="math inline"&gt;\(Y_t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In practice, one often sees the use of summary statistics from previous &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt; observations in intervals representative of the desired prediction period. For instance, in the context of Example &lt;span class="math inline"&gt;\(\ref{ex:X_temp}\)&lt;/span&gt;, the average temperatures in previous years over the months corresponding to the prediction interval (e.g. January-February averages through 2010 to 2016 as imputations for January-February 2017).&lt;/p&gt;
&lt;p&gt;This isn’t a bad idea, per se, but it is a needlessly indirect–and often insufficient–approach to defining a statistical model for &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;. It leaves out critical distributional details, the same details needed to determine how anything using our new &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt; estimates might be affected (through &lt;a href="https://en.wikipedia.org/wiki/Propagation_of_uncertainty"&gt;propagation of uncertainty&lt;/a&gt;). Eventually one comes around to specifying these details, but, in situations of sufficient complexity, this practice doesn’t produce a very clean, manageable or easily extensible model.&lt;/p&gt;
&lt;p&gt;The kinds of complicated models arising in these situations are both conceptually and technically difficult to use, and–as a result–it can be very hard to produce anything other than naive asymptotic approximations for errors and intervals. Sadly, these approximations are generally insufficient for all but the simplest scenarios.&lt;/p&gt;
&lt;p&gt;In contrast, we can model the &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt; values directly and have a very clear cut path toward out-of-sample predictions and their distributional properties. Even if we hold to the belief that the previous average values are a reasonable imputation, then a number of simple models can account for that assumption.&lt;/p&gt;
&lt;div id="ex:prior_extension" class="example" data-markdown="" data-title-name=""&gt;
&lt;p&gt;&lt;span id="ex:prior_extension_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{3}\label{ex:prior_extension}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s consider a normal regression model for &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt; with seasonal factors, i.e. &lt;span class="math display"&gt;\[\begin{equation}
X_t \sim \operatorname{N}(d(t)^\top \beta, I \sigma_x^2)
    \label{eq:exogenous_model}
\end{equation}\]&lt;/span&gt; where &lt;span class="math inline"&gt;\(d(t)\)&lt;/span&gt; is an indicator vector containing the seasonal factors and &lt;span class="math inline"&gt;\(I\)&lt;/span&gt; is an identity matrix.&lt;/p&gt;
&lt;p&gt;Keep in mind that we’ve stretched the notation a bit by letting &lt;span class="math inline"&gt;\(X_t\)&lt;/span&gt; be a random vector at time &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;, while &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; is still the stacked matrix of observed &lt;span class="math inline"&gt;\(x_t\)&lt;/span&gt; values. Now, we’re simply adding the assumption &lt;span class="math inline"&gt;\(x_t \sim X_t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s say that our new &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; vector has terms for each day of the week; this means the matrix of stacked &lt;span class="math inline"&gt;\(d(t)\)&lt;/span&gt; values, &lt;span class="math inline"&gt;\(D\)&lt;/span&gt;, is some classical factor design matrix with levels for each day. The product &lt;span class="math inline"&gt;\(d(t)^\top \beta\)&lt;/span&gt; is then some scalar mean for the day corresponding to &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A simple substitution of this model for our previously constant &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; matrix, results in a sort of hierarchical model, which we can now coherently marginalize and obtain the desired posterior predictive, &lt;span class="math inline"&gt;\(p(Y \mid y)\)&lt;/span&gt;. This time, the posterior predictive is independent of &lt;span class="math inline"&gt;\(X_t\)&lt;/span&gt;, so we can produce results for any &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The change in our complete model is relatively minimal. The model above for &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; results in the following marginal observation model: &lt;span class="math display"&gt;\[\begin{equation*}
\begin{aligned}
    \left(Y_t \mid \beta, \theta \right) &amp;amp;\propto
    \int p(Y_t \mid X_t, \theta) p(X_t \mid \beta) dX
    \\
    &amp;amp;\sim \operatorname{N}\left(
    d(t)^\top \beta \cdot \theta,
    \sigma^2 + \sigma_x^2 \cdot d(t)^\top \beta \beta^\top d(t) \right)
    \;.
  \end{aligned}
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The reduction in Example &lt;span class="math inline"&gt;\(\ref{ex:prior_extension}\)&lt;/span&gt; is quite reasonable and could be considered an entire re-definition of our initial observation model in Equation &lt;span class="math inline"&gt;\(\eqref{eq:normal-normal}\)&lt;/span&gt;. A change like this is a natural part of the standard model development cycle. However, this is not the only way to look at it. In the Bayesian setting we can keep the observation model fixed and iterate on the prior’s specification. The resulting marginal distribution could effectively be the same under both approaches (if desired), but the latter has the advantage of at least maintaining–conditionally–our earlier work.&lt;/p&gt;
&lt;div class="example" data-markdown="" data-title-name=""&gt;
&lt;p&gt;We haven’t given a prior to &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt;, but if we did, in the absence of conflicting assumptions, we might want the product &lt;span class="math inline"&gt;\(\beta \cdot \theta\)&lt;/span&gt; to simplified to a single unknown variables of its own, so that we’re not estimating two “entangled” variables. This idea might be inspired by an understanding of the classical &lt;a href="https://en.wikipedia.org/wiki/Parameter_identification_problem"&gt;identification&lt;/a&gt; issue arising from such products.&lt;/p&gt;
&lt;p&gt;With &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; constant, the form of our marginal observation model is basically unchanged from our initial under &lt;span class="math inline"&gt;\(x_t \to d(t)^\top \beta\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\sigma^2 \to \sigma^2 + \sigma_x^2 \cdot d(t)^\top \beta \beta^\top d(t)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Adherence to established models or industry standards is not uncommon. Outside of hierarchical model development, it can be very difficult to make these connections and coherently propagate statistical assumptions.&lt;/p&gt;
&lt;p&gt;This model development process expands in complexity and applicability through natural and compartmental extensions of existing terms. Simpler, “base” models are found as marginalizations of the new terms, and all the same estimation techniques apply.&lt;/p&gt;
&lt;p&gt;We’ll close with an illustration of the piecewise exogenous variable model described in Example &lt;span class="math inline"&gt;\(\ref{ex:prior_extension}\)&lt;/span&gt;. A few days are added to demonstrate out-of-sample predictions and the design matrix, &lt;span class="math inline"&gt;\(D\)&lt;/span&gt;, for Equation &lt;span class="math inline"&gt;\(\eqref{eq:exogenous_model}\)&lt;/span&gt; is produced using &lt;a href="https://patsy.readthedocs.io/en/latest/"&gt;Patsy&lt;/a&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb11"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb11-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; patsy&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-2" data-line-number="2"&gt;&lt;span class="im"&gt;import&lt;/span&gt; theano.tensor &lt;span class="im"&gt;as&lt;/span&gt; T&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-3" data-line-number="3"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-4" data-line-number="4"&gt;ext_sim_index &lt;span class="op"&gt;=&lt;/span&gt; pd.date_range(start&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;2016-01-01 12:00:00&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-5" data-line-number="5"&gt;                              end&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;2016-01-16 12:00:00&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-6" data-line-number="6"&gt;                              freq&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;H&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-8" data-line-number="8"&gt;y_obs_df &lt;span class="op"&gt;=&lt;/span&gt; pd.DataFrame(y_obs, index&lt;span class="op"&gt;=&lt;/span&gt;sim_index,&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-9" data-line-number="9"&gt;                        columns&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="vs"&gt;r&amp;#39;y&amp;#39;&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-11" data-line-number="11"&gt;&lt;span class="co"&gt;# The extra out-of-sample days are set to NaN&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-12" data-line-number="12"&gt;y_obs_df &lt;span class="op"&gt;=&lt;/span&gt; y_obs_df.reindex(ext_sim_index)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-14" data-line-number="14"&gt;&lt;span class="co"&gt;# Create some missing in-sample days&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-15" data-line-number="15"&gt;missing_days_idx &lt;span class="op"&gt;=&lt;/span&gt; np.random.randint(&lt;span class="dv"&gt;0&lt;/span&gt;, np.alen(y_obs), &lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-17" data-line-number="17"&gt;y_obs_df[missing_days_idx] &lt;span class="op"&gt;=&lt;/span&gt; np.nan&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-18" data-line-number="18"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-19" data-line-number="19"&gt;_, D_df &lt;span class="op"&gt;=&lt;/span&gt; patsy.dmatrices(&lt;span class="st"&gt;&amp;quot;y ~ C(y.index.weekday)&amp;quot;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-20" data-line-number="20"&gt;                          y_obs_df.notnull(),&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-21" data-line-number="21"&gt;                          return_type&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;dataframe&amp;#39;&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, with PyMC3 our model and its extension are easily expressed, and the missing observations will be sampled automatically.&lt;/p&gt;
&lt;div class="sourceCode" id="cb12"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb12-1" data-line-number="1"&gt;theano.config.mode &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;FAST_RUN&amp;quot;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-2" data-line-number="2"&gt;&lt;span class="kw"&gt;del&lt;/span&gt; model&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-3" data-line-number="3"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; pm.Model() &lt;span class="im"&gt;as&lt;/span&gt; model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-4" data-line-number="4"&gt;    theta &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;theta&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;mu, tau&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1.&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;tau2)&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-5" data-line-number="5"&gt;    beta &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;beta&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;0&lt;/span&gt;, sd&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1e1&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-6" data-line-number="6"&gt;                     shape&lt;span class="op"&gt;=&lt;/span&gt;(D_df.shape[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;],))&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-7" data-line-number="7"&gt;    mu_y &lt;span class="op"&gt;=&lt;/span&gt; T.transpose(T.dot(D_df, beta)) &lt;span class="op"&gt;*&lt;/span&gt; theta&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-9" data-line-number="9"&gt;    Y &lt;span class="op"&gt;=&lt;/span&gt; pm.Normal(&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;, mu&lt;span class="op"&gt;=&lt;/span&gt;mu_y, tau&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1.&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;sigma2,&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-10" data-line-number="10"&gt;                  observed&lt;span class="op"&gt;=&lt;/span&gt;y_obs_df.icol(&lt;span class="dv"&gt;0&lt;/span&gt;))&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-11" data-line-number="11"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-12" data-line-number="12"&gt;&lt;span class="cf"&gt;with&lt;/span&gt; model:&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-13" data-line-number="13"&gt;    sample_steps &lt;span class="op"&gt;=&lt;/span&gt; [pm.Metropolis([theta]),&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-14" data-line-number="14"&gt;                    pm.Metropolis([beta])]&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-15" data-line-number="15"&gt;    &lt;span class="cf"&gt;if&lt;/span&gt; Y.missing_values &lt;span class="kw"&gt;is&lt;/span&gt; &lt;span class="kw"&gt;not&lt;/span&gt; &lt;span class="va"&gt;None&lt;/span&gt;:&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-16" data-line-number="16"&gt;        sample_steps &lt;span class="op"&gt;+=&lt;/span&gt; [pm.Metropolis(Y.missing_values)]&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-17" data-line-number="17"&gt;    sample_traces &lt;span class="op"&gt;=&lt;/span&gt; pm.sample(&lt;span class="dv"&gt;2000&lt;/span&gt;, sample_steps)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The posterior predictive results are plotted below.&lt;/p&gt;
&lt;div class="sourceCode" id="cb13"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb13-1" data-line-number="1"&gt;ppc_samples &lt;span class="op"&gt;=&lt;/span&gt; pm.sample_ppc(sample_traces, model&lt;span class="op"&gt;=&lt;/span&gt;model)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-3" data-line-number="3"&gt;ppc_y_samples &lt;span class="op"&gt;=&lt;/span&gt; ppc_samples[&lt;span class="st"&gt;&amp;#39;Y&amp;#39;&lt;/span&gt;]&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-5" data-line-number="5"&gt;ppc_mean_df &lt;span class="op"&gt;=&lt;/span&gt; pd.DataFrame(ppc_y_samples.mean(axis&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;0&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-6" data-line-number="6"&gt;                           index&lt;span class="op"&gt;=&lt;/span&gt;ext_sim_index,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-7" data-line-number="7"&gt;                           columns&lt;span class="op"&gt;=&lt;/span&gt;[&lt;span class="vs"&gt;r&amp;#39;$E[Y \mid y]$&amp;#39;&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-8" data-line-number="8"&gt;ppc_hpd &lt;span class="op"&gt;=&lt;/span&gt; pd.DataFrame(pm.hpd(ppc_y_samples, &lt;span class="fl"&gt;0.05&lt;/span&gt;),&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-9" data-line-number="9"&gt;                       index&lt;span class="op"&gt;=&lt;/span&gt;ext_sim_index)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-11" data-line-number="11"&gt;y_obs_df.plot(color&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;, subplots&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;False&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-13" data-line-number="13"&gt;plt.vlines(y_obs_df.index[missing_days_idx], &lt;span class="op"&gt;*&lt;/span&gt;plt.axes().get_ybound(),&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-14" data-line-number="14"&gt;           linestyle&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;dashed&amp;#39;&lt;/span&gt;, alpha&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;0.1&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-15" data-line-number="15"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-16" data-line-number="16"&gt;plt.fill_between(y_obs_df.index,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-17" data-line-number="17"&gt;                 ppc_hpd[&lt;span class="dv"&gt;0&lt;/span&gt;].values,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-18" data-line-number="18"&gt;                 ppc_hpd[&lt;span class="dv"&gt;1&lt;/span&gt;].values,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-19" data-line-number="19"&gt;                 label&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="vs"&gt;r&amp;#39;$(Y \mid y)$ 95\&lt;/span&gt;&lt;span class="sc"&gt;% i&lt;/span&gt;&lt;span class="vs"&gt;nterval&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-20" data-line-number="20"&gt;                 alpha&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;0.5&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-21" data-line-number="21"&gt;ppc_mean_df.plot(ax&lt;span class="op"&gt;=&lt;/span&gt;plt.axes(), alpha&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;0.7&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-22" data-line-number="22"&gt;plt.legend()&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-23" data-line-number="23"&gt;plt.show()&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span id="fig:temp_ppc_plot"&gt;&lt;span id="fig:temp_ppc_plot_span" style="display:none;visibility:hidden"&gt;&lt;span class="math display"&gt;\[\begin{equation}\tag{4}\label{fig:temp_ppc_plot}\end{equation}\]&lt;/span&gt;&lt;/span&gt;&lt;img src="https://brandonwillard.github.io/figures/regarding_sample_estimates_temp_ppc_plot_1.png" title="fig:" alt="Posterior predictive results for the stochastic X model" /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;section id="bibliography" class="level1 unnumbered"&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id="refs" class="references"&gt;
&lt;div id="ref-gelman_bayesian_2013"&gt;
&lt;p&gt;Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. &lt;em&gt;Bayesian Data Analysis&lt;/em&gt;. CRC Press. &lt;a href="https://books.google.com/books?hl=en\&amp;amp;lr=\&amp;amp;id=eSHSBQAAQBAJ\&amp;amp;oi=fnd\&amp;amp;pg=PP1\&amp;amp;ots=Ak-k71u_75\&amp;amp;sig=d_812jhJtAQ_hZ5PLmee4GeQ0jQ" class="uri"&gt;https://books.google.com/books?hl=en\&amp;amp;lr=\&amp;amp;id=eSHSBQAAQBAJ\&amp;amp;oi=fnd\&amp;amp;pg=PP1\&amp;amp;ots=Ak-k71u_75\&amp;amp;sig=d_812jhJtAQ_hZ5PLmee4GeQ0jQ&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id="ref-polson_proximal_2015"&gt;
&lt;p&gt;Polson, Nicholas G., James G. Scott, and Brandon T. Willard. 2015. “Proximal Algorithms in Statistics and Machine Learning.” &lt;em&gt;Statistical Science&lt;/em&gt; 30 (4): 559–81. &lt;a href="http://projecteuclid.org/euclid.ss/1449670858" class="uri"&gt;http://projecteuclid.org/euclid.ss/1449670858&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content></entry><entry><title>SymPy Expression Tree Manipulation</title><link href="https://brandonwillard.github.io/sympy-expression-tree-manipulation.html" rel="alternate"></link><published>2016-10-27T00:00:00-05:00</published><updated>2016-10-27T00:00:00-05:00</updated><author><name>Brandon Willard</name></author><id>tag:brandonwillard.github.io,2016-10-27:/sympy-expression-tree-manipulation.html</id><summary type="html"></summary><content type="html">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;
&lt;head&gt;
  &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
  &lt;meta http-equiv="Content-Style-Type" content="text/css" /&gt;
  &lt;meta name="generator" content="pandoc" /&gt;
  &lt;meta name="author" content="Brandon Willard" /&gt;
  &lt;title&gt;SymPy Expression Tree Manipulation&lt;/title&gt;
  &lt;style type="text/css"&gt;code{white-space: pre;}&lt;/style&gt;
  &lt;style type="text/css"&gt;
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  &lt;/style&gt;
  &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;!--  --&gt;
&lt;!-- &lt;div id="header"&gt; --&gt;
&lt;!-- &lt;h1 class="title"&gt;SymPy Expression Tree Manipulation&lt;/h1&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h2 class="author"&gt;Brandon Willard&lt;/h2&gt; --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;h3 class="date"&gt;2016–10–27&lt;/h3&gt; --&gt;
&lt;!--  --&gt;
&lt;!-- &lt;/div&gt; --&gt;
&lt;!--  --&gt;
&lt;p&gt;I’ve been working on some extensions to our special function computations in &lt;a href="https://arxiv.org/abs/1605.04796"&gt;Prediction risk for global-local shrinkage regression&lt;/a&gt; and decided to employ &lt;a href="https://github.com/sympy/sympy"&gt;SymPy&lt;/a&gt; as much as possible. Out of this came an &lt;a href="https://bitbucket.org/bayes-horseshoe-plus/hsplus-python-pkg/src/master/hsplus/horn_symbolic.py"&gt;implementation&lt;/a&gt; of a bivariate confluent hypergeometric function: the &lt;a href="https://en.wikipedia.org/wiki/Humbert_series"&gt;Humbert&lt;/a&gt; &lt;span class="math inline"&gt;\(\Phi_1\)&lt;/span&gt;. This, and some numeric implementations, are available in a &lt;a href="https://bitbucket.org/bayes-horseshoe-plus/hsplus-python-pkg"&gt;Python package&lt;/a&gt; and an &lt;a href="https://bitbucket.org/bayes-horseshoe-plus/hsplus-r-pkg"&gt;R package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the course of this work there are expectations that appear as ratios of &lt;span class="math inline"&gt;\(\Phi_1\)&lt;/span&gt; functions, so it’s helpful to have a symbolic replacement routine to identify them. &lt;a href="http://docs.sympy.org/dev/modules/core.html#sympy.core.basic.Basic.match"&gt;Pattern matching&lt;/a&gt;, &lt;a href="http://docs.sympy.org/dev/modules/core.html#sympy.core.basic.Basic.find"&gt;finding&lt;/a&gt;, substitution and &lt;a href="http://docs.sympy.org/dev/modules/core.html#sympy.core.basic.Basic.replace"&gt;replacement&lt;/a&gt; are fairly standard in SymPy, so nothing special there; however, when you want something specific, it can get rather tricky.&lt;/p&gt;
&lt;p&gt;Personally, I’ve found the approach offered by the &lt;a href="https://github.com/sympy/sympy/tree/master/sympy/strategies"&gt;&lt;code&gt;sympy.strategies&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/sympy/sympy/tree/master/sympy/unify"&gt;&lt;code&gt;sympy.unify&lt;/code&gt;&lt;/a&gt; frameworks the most appealing. See the original discussion &lt;a href="https://groups.google.com/d/msg/sympy/fspCavhbd9I/vrzUitvgiuYJ"&gt;here&lt;/a&gt;. The reason for their appeal is mostly due to their organization of the processes behind expression tree traversal and manipulation. It’s much easier to see how a very specific and non-trivial simplification or replacement could be accomplished and iteratively improved. These points are made very well in the posts &lt;a href="http://matthewrocklin.com/blog/tags.html#SymPy-ref"&gt;here&lt;/a&gt;, so check them out.&lt;/p&gt;
&lt;p&gt;Let’s say we want to write a function &lt;code&gt;as_expectations&lt;/code&gt; that takes a &lt;code&gt;sympy.Expr&lt;/code&gt; and replaces ratios of &lt;span class="math inline"&gt;\(\Phi_1\)&lt;/span&gt; functions according to the following pattern: &lt;span class="math display"&gt;\[\begin{equation}
E[X^n] = \frac{\Phi_1(\alpha, \beta, \gamma + n; x, y)}{\Phi_1(\alpha, \beta, \gamma; x, y)}
\;.
\label{eq:expectation}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As an example, let’s set up a situation in which &lt;code&gt;as_expectations&lt;/code&gt; would be used, and, from there, attempt to construct our function. Naturally, this will involve a test expression with terms that we know match Equation &lt;span class="math inline"&gt;\(\eqref{eq:expectation}\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb1-1" data-line-number="1"&gt;&lt;span class="im"&gt;import&lt;/span&gt; sympy &lt;span class="im"&gt;as&lt;/span&gt; sp&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-3" data-line-number="3"&gt;&lt;span class="im"&gt;from&lt;/span&gt; hsplus.horn_symbolic &lt;span class="im"&gt;import&lt;/span&gt; HornPhi1&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-5" data-line-number="5"&gt;a, b, g, z_1, z_2 &lt;span class="op"&gt;=&lt;/span&gt; sp.symbols(&lt;span class="st"&gt;&amp;#39;a, b, g, z_1, z_2&amp;#39;&lt;/span&gt;, real&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-6" data-line-number="6"&gt;phi1_1 &lt;span class="op"&gt;=&lt;/span&gt; HornPhi1((a, b), (g,), z_1, z_2)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-7" data-line-number="7"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-8" data-line-number="8"&gt;n &lt;span class="op"&gt;=&lt;/span&gt; sp.Dummy(&lt;span class="st"&gt;&amp;#39;n&amp;#39;&lt;/span&gt;, integer&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;, positive&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-9" data-line-number="9"&gt;i &lt;span class="op"&gt;=&lt;/span&gt; sp.Dummy(&lt;span class="st"&gt;&amp;#39;i&amp;#39;&lt;/span&gt;, integer&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;, nonnegative&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-10" data-line-number="10"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-11" data-line-number="11"&gt;phi1_2 &lt;span class="op"&gt;=&lt;/span&gt; HornPhi1((a, b), (g &lt;span class="op"&gt;+&lt;/span&gt; n,), z_1, z_2)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-12" data-line-number="12"&gt;phi1_3 &lt;span class="op"&gt;=&lt;/span&gt; HornPhi1((a, b), (g &lt;span class="op"&gt;+&lt;/span&gt; n &lt;span class="op"&gt;-&lt;/span&gt; i,), z_1, z_2)&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-13" data-line-number="13"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-14" data-line-number="14"&gt;r_1 &lt;span class="op"&gt;=&lt;/span&gt; phi1_2&lt;span class="op"&gt;/&lt;/span&gt;phi1_1&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-15" data-line-number="15"&gt;r_2 &lt;span class="op"&gt;=&lt;/span&gt; phi1_3&lt;span class="op"&gt;/&lt;/span&gt;phi1_1&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-17" data-line-number="17"&gt;expr &lt;span class="op"&gt;=&lt;/span&gt; a &lt;span class="op"&gt;*&lt;/span&gt; r_1 &lt;span class="op"&gt;-&lt;/span&gt; b &lt;span class="op"&gt;*&lt;/span&gt; r_1 &lt;span class="op"&gt;/&lt;/span&gt; g &lt;span class="op"&gt;+&lt;/span&gt; sp.Sum(z_1&lt;span class="op"&gt;/&lt;/span&gt;z_2 &lt;span class="op"&gt;*&lt;/span&gt; r_2 &lt;span class="op"&gt;-&lt;/span&gt; &lt;span class="dv"&gt;3&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt; r_2, (i, &lt;span class="dv"&gt;0&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb1-18" data-line-number="18"&gt;n))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our test expression &lt;code&gt;expr&lt;/code&gt; looks like this&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb2-1" data-line-number="1"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(sp.latex(expr, mode&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;, itex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
\frac{a \operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad n + g,
\quad z_{1}, \quad z_{2}\right
)\right)}}{\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad g,
\quad z_{1}, \quad z_{2}\right )\right)}} + \sum_{i=0}^{n}
\left(\frac{z_{1} \operatorname{\Phi_1}{\left(\left ( a, \quad b,
\quad - i + n + g, \quad z_{1}, \quad z_{2}\right )\right)}}{z_{2}
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad g, \quad z_{1},
\quad z_{2}\right )\right)}} - \frac{3
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad - i + n + g,
\quad z_{1}, \quad z_{2}\right
)\right)}}{\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad g,
\quad z_{1}, \quad z_{2}\right )\right)}}\right) - \frac{b
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad n + g, \quad
z_{1}, \quad z_{2}\right )\right)}}{g
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad g, \quad z_{1},
\quad z_{2}\right )\right)}}
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The ratios &lt;code&gt;r_1&lt;/code&gt; and &lt;code&gt;r_2&lt;/code&gt; should both be replaced by a symbol for &lt;span class="math inline"&gt;\(E[X^m]\)&lt;/span&gt;, for &lt;span class="math inline"&gt;\(m = n\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(m = n - i\)&lt;/span&gt; when &lt;span class="math inline"&gt;\(i &amp;lt; n\)&lt;/span&gt; respectively. We could allow &lt;span class="math inline"&gt;\(E[X^0]\)&lt;/span&gt;, I suppose, but–for a more interesting discussion–let’s not.&lt;/p&gt;
&lt;p&gt;We start by creating a SymPy pattern that expresses the mathematical form of &lt;span class="math inline"&gt;\(E[X^m]\)&lt;/span&gt; in Equation &lt;span class="math inline"&gt;\(\eqref{eq:expectation}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="sourceCode" id="cb3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb3-1" data-line-number="1"&gt;pnames &lt;span class="op"&gt;=&lt;/span&gt; (&lt;span class="st"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;g&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;z_1&amp;#39;&lt;/span&gt;, &lt;span class="st"&gt;&amp;#39;z_2&amp;#39;&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-2" data-line-number="2"&gt;phi1_wild_args_n &lt;span class="op"&gt;=&lt;/span&gt; sp.symbols(&lt;span class="st"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;.join(n_ &lt;span class="op"&gt;+&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;_w&amp;#39;&lt;/span&gt; &lt;span class="cf"&gt;for&lt;/span&gt; n_ &lt;span class="kw"&gt;in&lt;/span&gt; pnames),&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-3" data-line-number="3"&gt;                              cls&lt;span class="op"&gt;=&lt;/span&gt;sp.Wild, real&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-4" data-line-number="4"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-5" data-line-number="5"&gt;n_w &lt;span class="op"&gt;=&lt;/span&gt; sp.Wild(&lt;span class="st"&gt;&amp;#39;n_w&amp;#39;&lt;/span&gt;,&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-6" data-line-number="6"&gt;              properties&lt;span class="op"&gt;=&lt;/span&gt;(&lt;span class="kw"&gt;lambda&lt;/span&gt; x: x.is_integer &lt;span class="kw"&gt;and&lt;/span&gt; x.is_positive,),&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-7" data-line-number="7"&gt;              exclude&lt;span class="op"&gt;=&lt;/span&gt;(phi1_wild_args_n[&lt;span class="dv"&gt;2&lt;/span&gt;],))&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-8" data-line-number="8"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-9" data-line-number="9"&gt;phi1_wild_d &lt;span class="op"&gt;=&lt;/span&gt; HornPhi1(phi1_wild_args_n[&lt;span class="dv"&gt;0&lt;/span&gt;:&lt;span class="dv"&gt;2&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-10" data-line-number="10"&gt;                       phi1_wild_args_n[&lt;span class="dv"&gt;2&lt;/span&gt;:&lt;span class="dv"&gt;3&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-11" data-line-number="11"&gt;                       &lt;span class="op"&gt;*&lt;/span&gt;phi1_wild_args_n[&lt;span class="dv"&gt;3&lt;/span&gt;:&lt;span class="dv"&gt;5&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-12" data-line-number="12"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-13" data-line-number="13"&gt;phi1_wild_n &lt;span class="op"&gt;=&lt;/span&gt; HornPhi1(phi1_wild_args_n[&lt;span class="dv"&gt;0&lt;/span&gt;:&lt;span class="dv"&gt;2&lt;/span&gt;],&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-14" data-line-number="14"&gt;                       (phi1_wild_args_n[&lt;span class="dv"&gt;2&lt;/span&gt;] &lt;span class="op"&gt;+&lt;/span&gt; n_w,),&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-15" data-line-number="15"&gt;                       &lt;span class="op"&gt;*&lt;/span&gt;phi1_wild_args_n[&lt;span class="dv"&gt;3&lt;/span&gt;:&lt;span class="dv"&gt;5&lt;/span&gt;])&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-16" data-line-number="16"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-17" data-line-number="17"&gt;C_w &lt;span class="op"&gt;=&lt;/span&gt; sp.Wild(&lt;span class="st"&gt;&amp;#39;C_w&amp;#39;&lt;/span&gt;, exclude&lt;span class="op"&gt;=&lt;/span&gt;[sp.S.Zero])&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-18" data-line-number="18"&gt;E_pattern &lt;span class="op"&gt;=&lt;/span&gt; phi1_wild_n &lt;span class="op"&gt;/&lt;/span&gt; phi1_wild_d&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-19" data-line-number="19"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb3-20" data-line-number="20"&gt;E_fn &lt;span class="op"&gt;=&lt;/span&gt; sp.Function(&lt;span class="st"&gt;&amp;quot;E&amp;quot;&lt;/span&gt;, real&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When we find an &lt;span class="math inline"&gt;\(E[X^m]\)&lt;/span&gt; we’ll replace it with the symbolic function &lt;code&gt;E_fn&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If we focus on only one of the terms (one we know matches &lt;code&gt;E_pattern&lt;/code&gt;), &lt;code&gt;r_1&lt;/code&gt;, we should find that our pattern suffices:&lt;/p&gt;
&lt;div class="sourceCode" id="cb4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb4-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; r_1.match(E_pattern)&lt;/a&gt;
&lt;a class="sourceLine" id="cb4-2" data-line-number="2"&gt;{n_w_: _n, z_2_w_: z_2, z_1_w_: z_1, a_w_: a, g_w_: g, b_w_: b}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, building up to the complexity of &lt;code&gt;expr&lt;/code&gt;, we see that a simple product doesn’t:&lt;/p&gt;
&lt;div class="sourceCode" id="cb5"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb5-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; (a &lt;span class="op"&gt;*&lt;/span&gt; r_1).match(E_pattern)&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, the product has introduced some problems that arise from associativity. Here are the details for the root expression tree:&lt;/p&gt;
&lt;div class="sourceCode" id="cb6"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb6-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; (a &lt;span class="op"&gt;*&lt;/span&gt; r_1).func&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-2" data-line-number="2"&gt;&lt;span class="op"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kw"&gt;class&lt;/span&gt; &lt;span class="st"&gt;&amp;#39;sympy.core.mul.Mul&amp;#39;&lt;/span&gt;&lt;span class="op"&gt;&amp;gt;&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-3" data-line-number="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; (a &lt;span class="op"&gt;*&lt;/span&gt; r_1).args&lt;/a&gt;
&lt;a class="sourceLine" id="cb6-4" data-line-number="4"&gt;(a, &lt;span class="dv"&gt;1&lt;/span&gt;&lt;span class="op"&gt;/&lt;/span&gt;HornPhi1(a, b, g, z_1, z_2), HornPhi1(a, b, _n &lt;span class="op"&gt;+&lt;/span&gt; g, z_1, z_2))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The root operation is multiplication and the operation’s arguments are all terms in the product/division.&lt;/p&gt;
&lt;p&gt;Any complete search for matches to &lt;code&gt;E_pattern&lt;/code&gt; would have to consider all possible combinations of terms in &lt;code&gt;(a * r_1).args&lt;/code&gt;, i.e. all possible groupings that arise due to associativity. The simple inclusion of another &lt;code&gt;Wild&lt;/code&gt; term causes the match to succeed, since SymPy’s basic pattern matching does account for associativity in this case.&lt;/p&gt;
&lt;p&gt;Here are a few explicit ways to make the match work:&lt;/p&gt;
&lt;div class="sourceCode" id="cb7"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb7-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; (a &lt;span class="op"&gt;*&lt;/span&gt; r_1).match(C_w &lt;span class="op"&gt;*&lt;/span&gt; E_pattern)&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-2" data-line-number="2"&gt;{a_w_: a, n_w_: _n, g_w_: g, z_2_w_: z_2, C_w_: a, b_w_: b, z_1_w_:&lt;/a&gt;
&lt;a class="sourceLine" id="cb7-3" data-line-number="3"&gt;z_1}&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or as a replacement:&lt;/p&gt;
&lt;div class="sourceCode" id="cb8"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb8-1" data-line-number="1"&gt;res &lt;span class="op"&gt;=&lt;/span&gt; (a &lt;span class="op"&gt;*&lt;/span&gt; r_1).replace(C_w &lt;span class="op"&gt;*&lt;/span&gt; E_pattern, C_w &lt;span class="op"&gt;*&lt;/span&gt; E_fn(n_w,&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-2" data-line-number="2"&gt;&lt;span class="op"&gt;*&lt;/span&gt;phi1_wild_args_n))&lt;/a&gt;
&lt;a class="sourceLine" id="cb8-3" data-line-number="3"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(sp.latex(res, mode&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;, itex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
a E{\left (n,a,b,g,z_{1},z_{2} \right )}
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and via &lt;code&gt;rewriterule&lt;/code&gt;:&lt;/p&gt;
&lt;div class="sourceCode" id="cb9"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb9-1" data-line-number="1"&gt;&lt;span class="im"&gt;from&lt;/span&gt; sympy.unify.rewrite &lt;span class="im"&gt;import&lt;/span&gt; rewriterule&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-2" data-line-number="2"&gt;rl &lt;span class="op"&gt;=&lt;/span&gt; rewriterule(C_w &lt;span class="op"&gt;*&lt;/span&gt; E_pattern,&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-3" data-line-number="3"&gt;                 C_w &lt;span class="op"&gt;*&lt;/span&gt; E_fn(n_w, &lt;span class="op"&gt;*&lt;/span&gt;phi1_wild_args_n),&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-4" data-line-number="4"&gt;                 phi1_wild_args_n &lt;span class="op"&gt;+&lt;/span&gt; (n_w, C_w))&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-5" data-line-number="5"&gt;res &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;list&lt;/span&gt;(rl(a &lt;span class="op"&gt;*&lt;/span&gt; r_1))&lt;/a&gt;
&lt;a class="sourceLine" id="cb9-6" data-line-number="6"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(sp.latex(res, mode&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;, itex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
\left [ a E{\left (n,a,b,g,z_{1},z_{2} \right )}\right ]
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The advantage in using &lt;code&gt;rewriterule&lt;/code&gt; is that multiple matches will be returned. If we add another &lt;span class="math inline"&gt;\(\Phi_1\)&lt;/span&gt; in the numerator, so there are multiple possible &lt;span class="math inline"&gt;\(E[X^m]\)&lt;/span&gt;, we get&lt;/p&gt;
&lt;div class="sourceCode" id="cb10"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb10-1" data-line-number="1"&gt;phi1_4 &lt;span class="op"&gt;=&lt;/span&gt; HornPhi1((a, b), (g &lt;span class="op"&gt;+&lt;/span&gt; n &lt;span class="op"&gt;+&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;,), z_1, z_2)&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-2" data-line-number="2"&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-3" data-line-number="3"&gt;res &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="bu"&gt;list&lt;/span&gt;(rl(a &lt;span class="op"&gt;*&lt;/span&gt; r_1 &lt;span class="op"&gt;*&lt;/span&gt; phi1_4))&lt;/a&gt;
&lt;a class="sourceLine" id="cb10-4" data-line-number="4"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(sp.latex(res, mode&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;, itex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
\left [ a \operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad n +
g, \quad z_{1}, \quad z_{2}\right )\right)} E{\left (n +
1,a,b,g,z_{1},z_{2} \right )}, \quad a
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad n + g, \quad
z_{1}, \quad z_{2}\right )\right)} E{\left (n + 1,a,b,g,z_{1},z_{2}
\right )}, \quad a \operatorname{\Phi_1}{\left(\left ( a, \quad b,
\quad n + g + 1, \quad z_{1}, \quad z_{2}\right )\right)} E{\left
(n,a,b,g,z_{1},z_{2} \right )}, \quad a
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad n + g, \quad
z_{1}, \quad z_{2}\right )\right)} E{\left (n + 1,a,b,g,z_{1},z_{2}
\right )}, \quad a \operatorname{\Phi_1}{\left(\left ( a, \quad b,
\quad n + g, \quad z_{1}, \quad z_{2}\right )\right)} E{\left (n +
1,a,b,g,z_{1},z_{2} \right )}, \quad a
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad n + g + 1, \quad
z_{1}, \quad z_{2}\right )\right)} E{\left (n,a,b,g,z_{1},z_{2} \right
)}\right ]
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;FYI: the associativity of terms inside the function arguments is causing the seemingly duplicate results.&lt;/p&gt;
&lt;p&gt;Naive use of &lt;code&gt;Expr.replace&lt;/code&gt; doesn’t give all results; instead, it does something likely unexpected:&lt;/p&gt;
&lt;div class="sourceCode" id="cb11"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb11-1" data-line-number="1"&gt;res &lt;span class="op"&gt;=&lt;/span&gt; (a &lt;span class="op"&gt;*&lt;/span&gt; r_1 &lt;span class="op"&gt;*&lt;/span&gt; phi1_4).replace(C_w &lt;span class="op"&gt;*&lt;/span&gt; E_pattern,&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-2" data-line-number="2"&gt;                                 C_w &lt;span class="op"&gt;*&lt;/span&gt; E_fn(n_w, &lt;span class="op"&gt;*&lt;/span&gt;phi1_wild_args_n))&lt;/a&gt;
&lt;a class="sourceLine" id="cb11-3" data-line-number="3"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(sp.latex(res, mode&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;, itex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
a E{\left (n,a,b,g,z_{1},z_{2} \right )} E{\left (n +
1,a,b,g,z_{1},z_{2} \right )} \operatorname{\Phi_1}{\left(\left ( a,
\quad b, \quad g, \quad z_{1}, \quad z_{2}\right )\right)}
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Returning to our more complicated &lt;code&gt;expr&lt;/code&gt;…Just because we can match products doesn’t mean we’re finished, since we still need a good way to traverse the entire expression tree and match the sub-trees. More importantly, adding the multiplicative &lt;code&gt;Wild&lt;/code&gt; term &lt;code&gt;C_w&lt;/code&gt; is more of a hack than a direct solution, since we don’t want the matched contents of &lt;code&gt;C_w&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Although &lt;code&gt;Expr.replace/xreplace&lt;/code&gt; will match sub-expressions, we found above that it produces some odd results. Those results persist when applied to more complicated expressions:&lt;/p&gt;
&lt;div class="sourceCode" id="cb12"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb12-1" data-line-number="1"&gt;res &lt;span class="op"&gt;=&lt;/span&gt; expr.replace(C_w &lt;span class="op"&gt;*&lt;/span&gt; E_pattern, C_w &lt;span class="op"&gt;*&lt;/span&gt; E_fn(n_w,&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-2" data-line-number="2"&gt;&lt;span class="op"&gt;*&lt;/span&gt;phi1_wild_args_n))&lt;/a&gt;
&lt;a class="sourceLine" id="cb12-3" data-line-number="3"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(sp.latex(res, mode&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;, itex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
a E{\left (n,a,b,g,z_{1},z_{2} \right )} - \frac{b}{g} E{\left
(n,a,b,g,z_{1},z_{2} \right )} + \sum_{i=0}^{n} \left(\frac{z_{1}
E{\left (n,a,b,- i + g,z_{1},z_{2} \right )}
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad - i + g, \quad
z_{1}, \quad z_{2}\right )\right)}}{z_{2}
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad g, \quad z_{1},
\quad z_{2}\right )\right)}} - \frac{3 E{\left (n,a,b,- i +
g,z_{1},z_{2} \right )} \operatorname{\Phi_1}{\left(\left ( a, \quad
b, \quad - i + g, \quad z_{1}, \quad z_{2}\right
)\right)}}{\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad g,
\quad z_{1}, \quad z_{2}\right )\right)}}\right)
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Again, it looks like the matching was a little too liberal and introduced extra &lt;code&gt;E&lt;/code&gt; and &lt;code&gt;HornPhi1&lt;/code&gt; terms. This is to be expected from the &lt;code&gt;Wild&lt;/code&gt; matching in SymPy; it needs us to specify what &lt;em&gt;not&lt;/em&gt; to match, as well. Our “fix” that introduced &lt;code&gt;C_w&lt;/code&gt; is the exact source of the problem, but we can tell it not to match &lt;code&gt;HornPhi1&lt;/code&gt; terms and get better results:&lt;/p&gt;
&lt;div class="sourceCode" id="cb13"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb13-1" data-line-number="1"&gt;C_w &lt;span class="op"&gt;=&lt;/span&gt; sp.Wild(&lt;span class="st"&gt;&amp;#39;C_w&amp;#39;&lt;/span&gt;, exclude&lt;span class="op"&gt;=&lt;/span&gt;[sp.S.Zero, HornPhi1])&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-2" data-line-number="2"&gt;res &lt;span class="op"&gt;=&lt;/span&gt; expr.replace(C_w &lt;span class="op"&gt;*&lt;/span&gt; E_pattern, C_w &lt;span class="op"&gt;*&lt;/span&gt; E_fn(n_w,&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-3" data-line-number="3"&gt;&lt;span class="op"&gt;*&lt;/span&gt;phi1_wild_args_n))&lt;/a&gt;
&lt;a class="sourceLine" id="cb13-4" data-line-number="4"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(sp.latex(res, mode&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;, itex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
a E{\left (n,a,b,g,z_{1},z_{2} \right )} - \frac{b}{g} E{\left
(n,a,b,g,z_{1},z_{2} \right )} + \sum_{i=0}^{n} \left(\frac{z_{1}
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad - i + n + g,
\quad z_{1}, \quad z_{2}\right )\right)}}{z_{2}
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad g, \quad z_{1},
\quad z_{2}\right )\right)}} - \frac{3
\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad - i + n + g,
\quad z_{1}, \quad z_{2}\right
)\right)}}{\operatorname{\Phi_1}{\left(\left ( a, \quad b, \quad g,
\quad z_{1}, \quad z_{2}\right )\right)}}\right)
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We’ve stopped it from introducing those superfluous &lt;code&gt;E&lt;/code&gt; terms, but we’re still not getting replacements for the &lt;code&gt;HornPhi1&lt;/code&gt; ratios in the sums. Let’s single out those terms and see what’s going on:&lt;/p&gt;
&lt;div class="sourceCode" id="cb14"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb14-1" data-line-number="1"&gt;res &lt;span class="op"&gt;=&lt;/span&gt; r_2.find(C_w &lt;span class="op"&gt;*&lt;/span&gt; E_pattern)&lt;/a&gt;
&lt;a class="sourceLine" id="cb14-2" data-line-number="2"&gt;&lt;span class="bu"&gt;print&lt;/span&gt;(sp.latex(res, mode&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="st"&gt;&amp;#39;equation*&amp;#39;&lt;/span&gt;, itex&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;))&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[\begin{equation*}
\left\{\right\}
\end{equation*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The constrained integer &lt;code&gt;Wild&lt;/code&gt; term, &lt;code&gt;n_w&lt;/code&gt;, probably isn’t matching. Given the form of our pattern, &lt;code&gt;n_w&lt;/code&gt; should match &lt;code&gt;n - i&lt;/code&gt;, but &lt;code&gt;n - i&lt;/code&gt; isn’t strictly positive, as required:&lt;/p&gt;
&lt;div class="sourceCode" id="cb15"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb15-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; (n &lt;span class="op"&gt;-&lt;/span&gt; i).is_positive &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="va"&gt;True&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb15-2" data-line-number="2"&gt;&lt;span class="va"&gt;False&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb15-3" data-line-number="3"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; sp.ask(sp.Q.positive(n &lt;span class="op"&gt;-&lt;/span&gt; i)) &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="va"&gt;True&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb15-4" data-line-number="4"&gt;&lt;span class="va"&gt;False&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since &lt;span class="math inline"&gt;\(n &amp;gt; 0\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(i &amp;gt;= 0\)&lt;/span&gt;, the only missing piece is that &lt;span class="math inline"&gt;\(n &amp;gt; i\)&lt;/span&gt;. The most relevant mechanism in SymPy to assess this information is the &lt;a href="http://docs.sympy.org/dev/modules/assumptions/index.html"&gt;&lt;code&gt;sympy.assumptions&lt;/code&gt;&lt;/a&gt; interface. We could add and retrieve the assumption &lt;code&gt;sympy.Q.is_true(n &amp;gt; i)&lt;/code&gt; via &lt;code&gt;sympy.assume.global_assumptions&lt;/code&gt;, or perform these operations inside of a Python &lt;code&gt;with&lt;/code&gt; block, etc. This context management, via &lt;code&gt;sympy.assumptions.assume.AssumptionsContext&lt;/code&gt;, would have to be performed manually, since I am not aware of any such mechanism offered by &lt;code&gt;Sum&lt;/code&gt; and/or &lt;code&gt;Basic.replace&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Unfortunately, these ideas sound good, but aren’t implemented:&lt;/p&gt;
&lt;div class="sourceCode" id="cb16"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;a class="sourceLine" id="cb16-1" data-line-number="1"&gt;&lt;span class="op"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; sp.ask(sp.Q.positive(n &lt;span class="op"&gt;-&lt;/span&gt; i), sp.Q.is_true(n &lt;span class="op"&gt;&amp;gt;&lt;/span&gt; i)) &lt;span class="op"&gt;==&lt;/span&gt; &lt;span class="va"&gt;True&lt;/span&gt;&lt;/a&gt;
&lt;a class="sourceLine" id="cb16-2" data-line-number="2"&gt;&lt;span class="va"&gt;False&lt;/span&gt;&lt;/a&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See the documentation for &lt;code&gt;sympy.assumptions.ask.ask&lt;/code&gt;; it explicitely states that inequalities aren’t handled, yet.&lt;/p&gt;
&lt;p&gt;We could probably perform a manual reworking of &lt;code&gt;sympy.Q.is_true(n &amp;gt; i)&lt;/code&gt; to &lt;code&gt;sympy.Q.is_true(n - i &amp;gt; 0)&lt;/code&gt;, which is of course equivalent to &lt;code&gt;sympy.Q.positive(n - i)&lt;/code&gt;: the result we want.&lt;/p&gt;
&lt;p&gt;If one were to provide this functionality, there’s still the question of how the relevant &lt;code&gt;AssumptionsContext&lt;/code&gt;s would be created and passed around/nested during the subexpression replacements. There is no apparent means of adding this sort of functionality through the &lt;code&gt;Basic.replace&lt;/code&gt; interface, so this path looks less appealing. However, nesting &lt;code&gt;with&lt;/code&gt; blocks from strategies in &lt;code&gt;sympy.strategies&lt;/code&gt; does seem quite possible. For example, in &lt;code&gt;sympy.strategies.traverse.sall&lt;/code&gt;, one could possibly wrap the &lt;code&gt;return&lt;/code&gt; statement after the &lt;code&gt;map(rule, ...)&lt;/code&gt; call in a &lt;code&gt;with sympy.assuming(...):&lt;/code&gt; block that contains the assumptions for any variables arising as, say, the index of a &lt;code&gt;Sum&lt;/code&gt;–like in our case. In this scenario, code in the subexpressions would be able to ask questions like &lt;code&gt;sympy.Q.is_true(n &amp;gt; i)&lt;/code&gt; without altering the global assumptions context or the objects involved.&lt;/p&gt;
&lt;p&gt;Anyway, that’s all I wanted to cover here. Perhaps later I’ll post a hack for the assumptions approach, but–at the very least–I’ll try to follow up with a more direct solution that uses &lt;code&gt;sympy.strategies&lt;/code&gt;.&lt;/p&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</content></entry></feed>