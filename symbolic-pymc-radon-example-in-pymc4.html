<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Symbolic PyMC Radon Example in PyMC4 - Brandon T. Willard</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="https://brandonwillard.github.io/symbolic-pymc-radon-example-in-pymc4.html">

        <meta name="author" content="Brandon T. Willard" />
        <meta name="keywords" content="pymc4,tensorflow,symbolic computation,python,symbolic-pymc" />

        <meta property="og:site_name" content="Brandon T. Willard" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Symbolic PyMC Radon Example in PyMC4"/>
        <meta property="og:url" content="https://brandonwillard.github.io/symbolic-pymc-radon-example-in-pymc4.html"/>
        <meta property="og:description" content=""/>
        <meta property="article:published_time" content="2019-09-08" />
            <meta property="article:section" content="articles" />
            <meta property="article:tag" content="pymc4" />
            <meta property="article:tag" content="tensorflow" />
            <meta property="article:tag" content="symbolic computation" />
            <meta property="article:tag" content="python" />
            <meta property="article:tag" content="symbolic-pymc" />
            <meta property="article:author" content="Brandon T. Willard" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="https://brandonwillard.github.io/theme/css/bootstrap.readable.min.css" type="text/css"/>
    <link href="https://brandonwillard.github.io/theme/css/font-awesome.min.css" rel="stylesheet">
    <link href="https://brandonwillard.github.io/theme/css/academicons.min.css" rel="stylesheet">

    <link href="https://brandonwillard.github.io/theme/css/pygments/vim.css" rel="stylesheet">
    <link rel="stylesheet" href="https://brandonwillard.github.io/theme/css/style.css" type="text/css"/>
        <link href="https://brandonwillard.github.io/extra/custom.css" rel="stylesheet">

        <link href="https://brandonwillard.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Brandon T. Willard ATOM Feed"/>

        <link href="https://brandonwillard.github.io/feeds/all.rss.xml" type="application/rss+xml" rel="alternate"
              title="Brandon T. Willard RSS Feed"/>


        <link href="https://brandonwillard.github.io/feeds/articles.atom.xml" type="application/atom+xml" rel="alternate"
              title="Brandon T. Willard articles ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="https://brandonwillard.github.io/" class="navbar-brand">
Brandon T. Willard            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="https://brandonwillard.github.io/pages/about.html">
                             About
                          </a></li>
                         <li><a href="https://brandonwillard.github.io/pages/projects.html">
                             Projects
                          </a></li>
                         <li><a href="https://brandonwillard.github.io/pages/publications.html">
                             Publications
                          </a></li>
                        <li class="active">
                            <a href="https://brandonwillard.github.io/category/articles.html">Articles</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<!-- Banner -->
<!-- End Banner -->

<!-- Content Container -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="https://brandonwillard.github.io/symbolic-pymc-radon-example-in-pymc4.html"
                       rel="bookmark"
                       title="Permalink to Symbolic PyMC Radon Example in PyMC4">
                        Symbolic PyMC Radon Example in PyMC4
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2019-09-08T00:00:00-05:00"> Sun 08 September 2019</time>
    </span>
          <span class="label label-default">Modified</span>
            <span class="modified">
                <i class="fa fa-calendar"></i><time datetime="2019-10-21T00:00:00-05:00"> Mon 21 October 2019</time>
            </span>





<span class="label label-default">Tags</span>
	<a href="https://brandonwillard.github.io/tag/pymc4.html">pymc4</a>
        /
	<a href="https://brandonwillard.github.io/tag/tensorflow.html">tensorflow</a>
        /
	<a href="https://brandonwillard.github.io/tag/symbolic-computation.html">symbolic computation</a>
        /
	<a href="https://brandonwillard.github.io/tag/python.html">python</a>
        /
	<a href="https://brandonwillard.github.io/tag/symbolic-pymc.html">symbolic-pymc</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Brandon T. Willard" />
  <title>Symbolic PyMC Radon Example in PyMC4</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<!--  -->
<!-- <div id="header"> -->
<!-- <h1 class="title">Symbolic PyMC Radon Example in PyMC4</h1> -->
<!--  -->
<!--  -->
<!-- <h2 class="author">Brandon T. Willard</h2> -->
<!--  -->
<!--  -->
<!-- <h3 class="date">2019–09–08</h3> -->
<!--  -->
<!-- </div> -->
<!--  -->
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p><a href="https://github.com/pymc-devs/symbolic-pymc">Symbolic PyMC</a> is a library that provides tools for symbolic manipulation of Tensor library models in TensorFlow and Theano. Over time, we plan to add tools that are somewhat specialized toward Bayesian model manipulation and the mathematical identities relevant to model manipulation for MCMC.</p>
<p>The main approach taken by Symbolic PyMC is relational/logic programming powered by a <a href="http://minikanren.org/">miniKanren</a> implementation in pure Python based on <a href="https://github.com/pymc-devs/kanren"><code>kanren</code></a>.</p>
<p>As an example of Symbolic PyMC’s usage, we will create a model “optimizer” that approximates the re-centering and re-scaling commonly demonstrated with the radon dataset. This example already exists for Theano in PyMC3 and can be found in the <a href="https://github.com/pymc-devs/symbolic-pymc#automatic-re-centering-and-re-scaling">project README</a>. Here, we will operate on TensorFlow graphs via PyMC4 and approximate the same optimization using a very different approach targeted toward the log-likelihood graph.</p>
<p>To get started, we download the radon dataset and define the un-centered model in Listings <a href="#org15f2d13">1</a>, <a href="#org84a4bd7">2</a>, and <a href="#orgf0b697c">3</a>.</p>
<figure id="org15f2d13">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="im">import</span> pandas <span class="im">as</span> pd</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="im">import</span> tensorflow <span class="im">as</span> tf</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="im">import</span> pymc4 <span class="im">as</span> pm</a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="im">import</span> arviz <span class="im">as</span> az</a></code></pre></div>
<figcaption>
Listing 1
</figcaption>
</figure>
<figure id="org84a4bd7">
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1">data <span class="op">=</span> pd.read_csv(<span class="st">&#39;https://github.com/pymc-devs/pymc3/raw/master/pymc3/examples/data/radon.csv&#39;</span>)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2-3" data-line-number="3">county_names <span class="op">=</span> data.county.unique()</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">county_idx <span class="op">=</span> data[<span class="st">&#39;county_code&#39;</span>].values.astype(np.int32)</a></code></pre></div>
<figcaption>
Listing 2
</figcaption>
</figure>
<figure id="orgf0b697c">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="at">@pm.model</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">def</span> hierarchical_model(data, county_idx):</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">    <span class="co"># Hyperpriors</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4">    mu_a <span class="op">=</span> <span class="cf">yield</span> pm.Normal(<span class="st">&#39;mu_alpha&#39;</span>, mu<span class="op">=</span><span class="fl">0.</span>, sigma<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">    sigma_a <span class="op">=</span> <span class="cf">yield</span> pm.HalfCauchy(<span class="st">&#39;sigma_alpha&#39;</span>, beta<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-6" data-line-number="6">    mu_b <span class="op">=</span> <span class="cf">yield</span> pm.Normal(<span class="st">&#39;mu_beta&#39;</span>, mu<span class="op">=</span><span class="fl">0.</span>, sigma<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-7" data-line-number="7">    sigma_b <span class="op">=</span> <span class="cf">yield</span> pm.HalfCauchy(<span class="st">&#39;sigma_beta&#39;</span>, beta<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-8" data-line-number="8"></a>
<a class="sourceLine" id="cb3-9" data-line-number="9">    <span class="co"># Intercept for each county, distributed around group mean mu_a</span></a>
<a class="sourceLine" id="cb3-10" data-line-number="10">    a <span class="op">=</span> <span class="cf">yield</span> pm.Normal(<span class="st">&#39;alpha&#39;</span>, mu<span class="op">=</span>mu_a, sigma<span class="op">=</span>sigma_a, plate<span class="op">=</span><span class="bu">len</span>(data.county.unique()))</a>
<a class="sourceLine" id="cb3-11" data-line-number="11">    <span class="co"># Intercept for each county, distributed around group mean mu_a</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12">    b <span class="op">=</span> <span class="cf">yield</span> pm.Normal(<span class="st">&#39;beta&#39;</span>, mu<span class="op">=</span>mu_b, sigma<span class="op">=</span>sigma_b, plate<span class="op">=</span><span class="bu">len</span>(data.county.unique()))</a>
<a class="sourceLine" id="cb3-13" data-line-number="13"></a>
<a class="sourceLine" id="cb3-14" data-line-number="14">    <span class="co"># Model error</span></a>
<a class="sourceLine" id="cb3-15" data-line-number="15">    eps <span class="op">=</span> <span class="cf">yield</span> pm.HalfCauchy(<span class="st">&#39;eps&#39;</span>, beta<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-16" data-line-number="16"></a>
<a class="sourceLine" id="cb3-17" data-line-number="17">    <span class="co"># Expected value</span></a>
<a class="sourceLine" id="cb3-18" data-line-number="18">    <span class="co">#radon_est = a[county_idx] + b[county_idx] * data.floor.values</span></a>
<a class="sourceLine" id="cb3-19" data-line-number="19">    radon_est <span class="op">=</span> tf.gather(a, county_idx) <span class="op">+</span> tf.gather(</a>
<a class="sourceLine" id="cb3-20" data-line-number="20">        b, county_idx) <span class="op">*</span> data.floor.values</a>
<a class="sourceLine" id="cb3-21" data-line-number="21"></a>
<a class="sourceLine" id="cb3-22" data-line-number="22">    <span class="co"># Data likelihood</span></a>
<a class="sourceLine" id="cb3-23" data-line-number="23">    y_like <span class="op">=</span> <span class="cf">yield</span> pm.Normal(<span class="st">&#39;y_like&#39;</span>, mu<span class="op">=</span>radon_est, sigma<span class="op">=</span>eps, observed<span class="op">=</span>data.log_radon)</a>
<a class="sourceLine" id="cb3-24" data-line-number="24"></a>
<a class="sourceLine" id="cb3-25" data-line-number="25"></a>
<a class="sourceLine" id="cb3-26" data-line-number="26">init_num_chains <span class="op">=</span> <span class="dv">50</span></a>
<a class="sourceLine" id="cb3-27" data-line-number="27">model <span class="op">=</span> hierarchical_model(data, county_idx)</a></code></pre></div>
<figcaption>
Listing 3
</figcaption>
</figure>
<p>In Listing <a href="#org76f5220">5</a>, we estimates the model using the sample routine from the <a href="https://github.com/pymc-devs/pymc4/blob/master/notebooks/radon_hierarchical.ipynb">PyMC4 Radon example Notebook</a> in Listing <a href="#org9df08c0">4</a>. The same plots are reproduce here in Figures <a href="#org2d6c05e">6</a> and <a href="#orgef38802">7</a>.</p>
<figure id="org9df08c0">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">def</span> sample(model, init_num_chains<span class="op">=</span><span class="dv">50</span>, num_samples<span class="op">=</span><span class="dv">500</span>, burn_in<span class="op">=</span><span class="dv">500</span>):</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">    init_num_chains <span class="op">=</span> <span class="dv">50</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3">    pm4_trace, _ <span class="op">=</span> pm.inference.sampling.sample(</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">        model, num_chains<span class="op">=</span>init_num_chains, num_samples<span class="op">=</span><span class="dv">10</span>, burn_in<span class="op">=</span><span class="dv">10</span>, step_size<span class="op">=</span><span class="fl">1.</span>, xla<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb4-5" data-line-number="5">    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</a>
<a class="sourceLine" id="cb4-6" data-line-number="6">        step_size_ <span class="op">=</span> []</a>
<a class="sourceLine" id="cb4-7" data-line-number="7">        <span class="cf">for</span> _, x <span class="kw">in</span> pm4_trace.items():</a>
<a class="sourceLine" id="cb4-8" data-line-number="8">            std <span class="op">=</span> tf.math.reduce_std(x, axis<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>])</a>
<a class="sourceLine" id="cb4-9" data-line-number="9">            step_size_.append(</a>
<a class="sourceLine" id="cb4-10" data-line-number="10">                std[tf.newaxis, ...] <span class="op">*</span> tf.ones([init_num_chains] <span class="op">+</span> std.shape, dtype<span class="op">=</span>std.dtype))</a>
<a class="sourceLine" id="cb4-11" data-line-number="11">        pm4_trace, _ <span class="op">=</span> pm.inference.sampling.sample(</a>
<a class="sourceLine" id="cb4-12" data-line-number="12">            model, num_chains<span class="op">=</span>init_num_chains, num_samples<span class="op">=</span><span class="dv">10</span> <span class="op">+</span> <span class="dv">10</span><span class="op">*</span>i, burn_in<span class="op">=</span><span class="dv">10</span> <span class="op">+</span> <span class="dv">10</span><span class="op">*</span>i,</a>
<a class="sourceLine" id="cb4-13" data-line-number="13">            step_size<span class="op">=</span>step_size_, xla<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb4-14" data-line-number="14"></a>
<a class="sourceLine" id="cb4-15" data-line-number="15">    num_chains <span class="op">=</span> <span class="dv">5</span></a>
<a class="sourceLine" id="cb4-16" data-line-number="16">    step_size_ <span class="op">=</span> []</a>
<a class="sourceLine" id="cb4-17" data-line-number="17">    <span class="cf">for</span> _, x <span class="kw">in</span> pm4_trace.items():</a>
<a class="sourceLine" id="cb4-18" data-line-number="18">        std <span class="op">=</span> tf.math.reduce_std(x, axis<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>])</a>
<a class="sourceLine" id="cb4-19" data-line-number="19">        step_size_.append(</a>
<a class="sourceLine" id="cb4-20" data-line-number="20">            std[tf.newaxis, ...] <span class="op">*</span> tf.ones([num_chains]<span class="op">+</span>std.shape, dtype<span class="op">=</span>std.dtype))</a>
<a class="sourceLine" id="cb4-21" data-line-number="21"></a>
<a class="sourceLine" id="cb4-22" data-line-number="22">    pm4_trace, sample_stat <span class="op">=</span> pm.inference.sampling.sample(</a>
<a class="sourceLine" id="cb4-23" data-line-number="23">        model, num_chains<span class="op">=</span>num_chains, num_samples<span class="op">=</span>num_samples, burn_in<span class="op">=</span>burn_in,</a>
<a class="sourceLine" id="cb4-24" data-line-number="24">        step_size<span class="op">=</span>step_size_, xla<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb4-25" data-line-number="25"></a>
<a class="sourceLine" id="cb4-26" data-line-number="26">    az_trace <span class="op">=</span> pm.inference.utils.trace_to_arviz(pm4_trace, sample_stat)</a>
<a class="sourceLine" id="cb4-27" data-line-number="27"></a>
<a class="sourceLine" id="cb4-28" data-line-number="28">    <span class="cf">return</span> az_trace</a></code></pre></div>
<figcaption>
Listing 4
</figcaption>
</figure>
<figure id="org76f5220">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1">az_trace <span class="op">=</span> sample(model)</a></code></pre></div>
<figcaption>
Listing 5
</figcaption>
</figure>
<figure>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"></a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="im">import</span> seaborn <span class="im">as</span> sns</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"></a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="im">from</span> matplotlib <span class="im">import</span> rcParams</a>
<a class="sourceLine" id="cb6-6" data-line-number="6"></a>
<a class="sourceLine" id="cb6-7" data-line-number="7"></a>
<a class="sourceLine" id="cb6-8" data-line-number="8">rcParams[<span class="st">&#39;figure.figsize&#39;</span>] <span class="op">=</span> (<span class="fl">11.7</span>, <span class="fl">8.27</span>)</a>
<a class="sourceLine" id="cb6-9" data-line-number="9"></a>
<a class="sourceLine" id="cb6-10" data-line-number="10"><span class="co"># plt.rc(&#39;text&#39;, usetex=True)</span></a>
<a class="sourceLine" id="cb6-11" data-line-number="11">sns.set_style(<span class="st">&quot;whitegrid&quot;</span>)</a>
<a class="sourceLine" id="cb6-12" data-line-number="12">sns.set_context(<span class="st">&quot;paper&quot;</span>)</a></code></pre></div>
</figure>
<figure>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" data-line-number="1">_ <span class="op">=</span> az.plot_energy(az_trace)</a></code></pre></div>
</figure>
<figure id="fig:pymc4-radon-plot-energy" class="plot">
<img src="https://brandonwillard.github.io/figures/pymc4-radon-plot-energy.png" alt="" />
<figcaption>
</figcaption>
</figure>
<figure id="fig:pymc4-radon-plot-trace" class="plot">
<img src="https://brandonwillard.github.io/figures/pymc4-radon-plot-trace.png" alt="" />
<figcaption>
</figcaption>
</figure>
</section>
<section id="applying-an-optimization" class="level1">
<h1>Applying an Optimization</h1>
<p>In order to apply our optimization, we need to do some work to obtain a graph of the log-likelihood function generated by the model in Listing <a href="#orgf0b697c">3</a>. With the graph in-hand, we can perform the re-centering and re-scaling transform–in log-space this time–and obtain a new log-likelihood graph from which better samples can be generated.</p>
<p>This exercise introduces the TensorFlow function-graph elements that mirror Theano’s <code>tt.function</code> and <code>FunctionGraph</code>s: <code>tensorflow.python.framework.func_graph.FuncGraph</code>. <code>FuncGraph</code> is a subclass of the regular <code>Graph</code> objects upon which implicitly <code>symbolic_pymc</code> operates. Just as with Theano’s <code>FunctionGraph</code>s, <code>FuncGraph</code> simply specializes a graph by specifying inputs and outputs from elements (i.e. tensors) within a graph.</p>
</section>
<section id="log-likelihood-funcgraphs" class="level1">
<h1>Log-likelihood <code>FuncGraph</code>s</h1>
<p>In Listing <a href="#orgc606190">8</a>, we build the log-likelihood function for our model and a corresponding list of initial values for the parameters.</p>
<figure id="orgc606190">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" data-line-number="1">state <span class="op">=</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2">observed <span class="op">=</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3"></a>
<a class="sourceLine" id="cb8-4" data-line-number="4">logpfn, init <span class="op">=</span> pm.inference.sampling.build_logp_function(model,</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">                                                         state<span class="op">=</span>state,</a>
<a class="sourceLine" id="cb8-6" data-line-number="6">                                                         observed<span class="op">=</span>observed)</a></code></pre></div>
<figcaption>
Listing 8
</figcaption>
</figure>
<p>From here we need <code>FuncGraph</code>s for each input to <code>logpfn</code>. Since <code>logpfn</code> is a <code>tensorflow.python.eager.def_function.Function</code> instance, every time it’s called with a specific tensor it may create a new function-object with it’s own <code>FuncGraph</code>. In other words, it dynamically generates function objects based on the inputs it’s given.</p>
<p>This specialization process can be performed manually using <code>logpfn.get_concrete_function(*args)</code>, which necessarily produces a <code>tensorflow.python.eager.function.ConcreteFunction</code> with the desired <code>FuncGraph</code>. Listing <a href="#org966cccf">9</a> creates and extracts these two objects.</p>
<figure id="org966cccf">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb9-1" data-line-number="1">logpfn_cf <span class="op">=</span> logpfn.get_concrete_function(<span class="op">*</span>init.values())</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">logpfn_fg <span class="op">=</span> logpfn_cf.graph</a></code></pre></div>
<figcaption>
Listing 9
</figcaption>
</figure>
<p>The outputs are now available in graph form as <code>logpfn_fg.outputs</code>. The inputs aren’t mapped in this particular function-graph output. I believe there’s a way to generate those as TF placeholders.</p>
<figure>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="im">from</span> tensorflow.python.eager.context <span class="im">import</span> graph_mode</a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="im">from</span> tensorflow.python.framework.ops <span class="im">import</span> disable_tensor_equality</a>
<a class="sourceLine" id="cb10-3" data-line-number="3"></a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="im">from</span> symbolic_pymc.tensorflow.printing <span class="im">import</span> tf_dprint</a>
<a class="sourceLine" id="cb10-5" data-line-number="5"></a>
<a class="sourceLine" id="cb10-6" data-line-number="6"></a>
<a class="sourceLine" id="cb10-7" data-line-number="7">disable_tensor_equality()</a></code></pre></div>
</figure>
</section>
<section id="the-log-space-transform" class="level1">
<h1>The Log-space Transform</h1>
<p>Consider the following two equivalent hierarchical models,</p>
<p><span class="math display">\[\begin{equation}
  \begin{gathered}
    Y = X + \epsilon, \quad
    \epsilon \sim \operatorname{N}\left(0, \sigma^2\right)
    \\
    X \sim \operatorname{N}\left(\mu, \tau^2\right)
  \end{gathered}
\label{eq:model-1}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  \begin{gathered}
    Y = \mu + \tau \cdot \tilde{X} + \epsilon, \quad
    \epsilon \sim \operatorname{N}\left(0, \sigma^2\right)
    \\
    \tilde{X} \sim \operatorname{N}\left(0, 1\right)
  \;.
  \end{gathered}
\label{eq:model-2}
\end{equation}\]</span></p>
<p>Models <span class="math inline">\(\eqref{eq:model-1}\)</span> and <span class="math inline">\(\eqref{eq:model-2}\)</span> are represented in (log) measure space, respectively, as follows:</p>
<p><span class="math display">\[\begin{align}
    \log p(Y, X) &amp;= \log P(Y\mid X) + \log P(X)
    \nonumber
    \\
    &amp;= C - \frac{1}{2} \left(\frac{y}{\sigma} - \frac{x}{\sigma}\right)^2 -
       \frac{1}{2} \left(\frac{x}{\tau} - \frac{\mu}{\tau}\right)^2
    \label{eq:log-model-1}
    \\
    &amp;= \tilde{C} - \frac{1}{2} \left(\frac{y}{\sigma} - \frac{\mu - \tau \cdot \tilde{x}}{\sigma}\right)^2 - \frac{1}{2} \tilde{x}^2
  \label{eq:log-model-2}
  \;.
\end{align}\]</span></p>
<p>Via term rewriting, Equation <span class="math inline">\(\eqref{eq:log-model-2}\)</span> is produced–in part–by applying the replacement rule <span class="math inline">\(x \to \mu + \tau \cdot \tilde{x}\)</span> to Equation <span class="math inline">\(\eqref{eq:log-model-1}\)</span>, i.e.</p>
<p><span class="math display">\[\begin{align*}
\tilde{C} - \frac{1}{2} \left(\frac{y}{\sigma} - \frac{\mu + \tau \cdot \tilde{x}}{\sigma}\right)^2 -
  \frac{1}{2} \left(\frac{\mu + \tau \cdot \tilde{x}}{\tau} - \frac{\mu}{\tau}\right)^2
\;.
\end{align*}\]</span></p>
<p>For consistency, the transform must also be applied to the <span class="math inline">\(dx\)</span> term where/when-ever it is considered.</p>
<p>After a few algebraic simplifications, one obtains the exact form of Equation <span class="math inline">\(\eqref{eq:log-model-2}\)</span>.</p>
</section>
<section id="creating-the-minikanren-goals" class="level1">
<h1>Creating the miniKanren Goals</h1>
<p><code>symbolic-pymc</code> is designed to use miniKanren as a means of specifying mathematical relations. The degree to which an implementation of a mathematical relation upholds its known characteristics is–of course–always up to the developer, and, for the needs of PPLs like PyMC4, we can’t reasonably expect or provide capabilities at the level of automatic theorem proving or every state-of-the-art symbolic math routines (yet) in a single library.</p>
<p>Even so, we <strong>do</strong> expect that some capabilities from within those more advanced areas of symbolic computing will eventually be required–or necessary–and we want to build on a foundation that allows them to be integrated and/or simply expressed. We believe that miniKanren is a great foundation for such work, since it operates primarily with the core elements shared by many advanced areas concerned with symbolic computation. It also maintains an elegant simplicity and is amenable to developer intervention at nearly all levels–without the need for internal rewrites.</p>
<p>User-level development in miniKanren occurs within its DSL, which is a succinct relational/logic programming paradigm that–in our case–is entirely written in Python. This DSL provides primitive <strong>goals</strong> that can be composed and eventually evaluated with a <code>run</code> function. We refer the reader to any one of the many great introductions to miniKanren available at <a href="http://minikanren.org" class="uri">http://minikanren.org</a>, or, for the specific Python package used here, <a href="https://github.com/logpy/logpy/blob/master/doc/basic.md">this simple introduction</a>.</p>
<p>For the matter at hand, we need to create goals that can identify the elements needed to construct the substitution described above and then perform it.</p>
<p>The first step is to understand the exact forms of the TF graphs involved, and the best way to do that is to construct the relevant objects and build “patterns” that will “match” them. Patterns are built with <code>symbolic-pymc</code> meta objects obtained from the <code>mt</code> helper “namespace”. Wherever we want to leave room for variation/ambiguity, we use a “logic variable” instead of an explicit TF (meta) object. Logic variables are created with <code>var()</code> and can optionally be given a string “name” argument that identifies them globally as a singleton-like object.</p>
<section id="inspecting-the-tf-graphs" class="level2">
<h2>Inspecting the TF Graphs</h2>
<p>In our case, the log-density returned by PyMC4–via the TensorFlow Probability library (TFP)– uses <code>tf.math.squared_difference</code> to construct the “squared error” term in the exponential of a normal distribution. This term contains everything we need to construct the substitution as a pair of TF graph objects.</p>
<p>Listing <a href="#orgc47d26d">11</a> shows the graph produced by a normal distribution in TFP.</p>
<figure id="orgc47d26d">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="im">import</span> tensorflow_probability <span class="im">as</span> tfp</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"></a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="im">from</span> tensorflow.python.eager.context <span class="im">import</span> graph_mode</a>
<a class="sourceLine" id="cb11-4" data-line-number="4"><span class="im">from</span> tensorflow.python.framework.ops <span class="im">import</span> disable_tensor_equality</a>
<a class="sourceLine" id="cb11-5" data-line-number="5"></a>
<a class="sourceLine" id="cb11-6" data-line-number="6"><span class="im">from</span> symbolic_pymc.tensorflow.printing <span class="im">import</span> tf_dprint</a>
<a class="sourceLine" id="cb11-7" data-line-number="7"></a>
<a class="sourceLine" id="cb11-8" data-line-number="8"></a>
<a class="sourceLine" id="cb11-9" data-line-number="9">disable_tensor_equality()</a>
<a class="sourceLine" id="cb11-10" data-line-number="10"></a>
<a class="sourceLine" id="cb11-11" data-line-number="11"><span class="cf">with</span> graph_mode(), tf.Graph().as_default() <span class="im">as</span> test_graph:</a>
<a class="sourceLine" id="cb11-12" data-line-number="12">    mu_tf <span class="op">=</span> tf.compat.v1.placeholder(tf.float32, name<span class="op">=</span><span class="st">&#39;mu&#39;</span>,</a>
<a class="sourceLine" id="cb11-13" data-line-number="13">                                     shape<span class="op">=</span>tf.TensorShape([<span class="va">None</span>]))</a>
<a class="sourceLine" id="cb11-14" data-line-number="14">    tau_tf <span class="op">=</span> tf.compat.v1.placeholder(tf.float32, name<span class="op">=</span><span class="st">&#39;tau&#39;</span>,</a>
<a class="sourceLine" id="cb11-15" data-line-number="15">                                      shape<span class="op">=</span>tf.TensorShape([<span class="va">None</span>]))</a>
<a class="sourceLine" id="cb11-16" data-line-number="16"></a>
<a class="sourceLine" id="cb11-17" data-line-number="17">    normal_tfp <span class="op">=</span> tfp.distributions.normal.Normal(mu_tf, tau_tf)</a>
<a class="sourceLine" id="cb11-18" data-line-number="18"></a>
<a class="sourceLine" id="cb11-19" data-line-number="19">    value_tf <span class="op">=</span> tf.compat.v1.placeholder(tf.float32, name<span class="op">=</span><span class="st">&#39;value&#39;</span>,</a>
<a class="sourceLine" id="cb11-20" data-line-number="20">                                        shape<span class="op">=</span>tf.TensorShape([<span class="va">None</span>]))</a>
<a class="sourceLine" id="cb11-21" data-line-number="21"></a>
<a class="sourceLine" id="cb11-22" data-line-number="22">    normal_log_lik <span class="op">=</span> normal_tfp.log_prob(value_tf)</a></code></pre></div>
<figcaption>
Listing 11
</figcaption>
</figure>
<figure>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb12-1" data-line-number="1">tf_dprint(normal_log_lik)</a></code></pre></div>
</figure>
<figure>
<pre class="text"><code>Tensor(Sub):0,  shape=[None]    &quot;Normal_1/log_prob/sub:0&quot;
|  Tensor(Mul):0,   shape=[None]    &quot;Normal_1/log_prob/mul:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;Normal_1/log_prob/mul/x:0&quot;
|  |  |  -0.5
|  |  Tensor(SquaredDifference):0,  shape=[None]    &quot;Normal_1/log_prob/SquaredDifference:0&quot;
|  |  |  Tensor(RealDiv):0, shape=[None]    &quot;Normal_1/log_prob/truediv:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;value:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;tau:0&quot;
|  |  |  Tensor(RealDiv):0, shape=[None]    &quot;Normal_1/log_prob/truediv_1:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;mu:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;tau:0&quot;
|  Tensor(AddV2):0, shape=[None]    &quot;Normal_1/log_prob/add:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;Normal_1/log_prob/add/x:0&quot;
|  |  |  0.9189385
|  |  Tensor(Log):0,    shape=[None]    &quot;Normal_1/log_prob/Log:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[None]    &quot;tau:0&quot;

</code></pre>
</figure>
<p>Instead of looking for the entire log-likelihood graph for a distribution, we can focus on only the <code>SquaredDifference</code> operators, since they contain all the relevant terms for our transformation.</p>
<p>More specifically, if we can identify “chains” of such terms, i.e. <code>SquaredDifference(y, x)</code> and <code>SquaredDifference(x, mu)</code>, then we might be able to assume that the corresponding subgraph was formed from such a hierarchical normal model.</p>
<p>Listing <a href="#orgacfcea8">14</a> shows the <code>SquaredDifference</code> sub-graphs in the log-likelihood graph for our radon model. It demonstrates two instances of said <code>SquaredDifference</code> “chains”: they involve tensors named <code>values_5</code> and <code>values_1</code>.</p>
<figure id="orgacfcea8">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb14-1" data-line-number="1">square_diff_outs <span class="op">=</span> [o.outputs[<span class="dv">0</span>] <span class="cf">for</span> o <span class="kw">in</span> logpfn_fg.get_operations()</a>
<a class="sourceLine" id="cb14-2" data-line-number="2">                    <span class="cf">if</span> o.<span class="bu">type</span> <span class="op">==</span> <span class="st">&#39;SquaredDifference&#39;</span> <span class="kw">or</span> o.<span class="bu">type</span>.startswith(<span class="st">&#39;Gather&#39;</span>)]</a>
<a class="sourceLine" id="cb14-3" data-line-number="3"></a>
<a class="sourceLine" id="cb14-4" data-line-number="4"><span class="cf">for</span> t <span class="kw">in</span> square_diff_outs:</a>
<a class="sourceLine" id="cb14-5" data-line-number="5">    tf_dprint(t)</a></code></pre></div>
<figcaption>
Listing 14
</figcaption>
</figure>
<figure>
<pre class="text"><code>Tensor(GatherV2):0, shape=[919] &quot;GatherV2:0&quot;
|  Tensor(Placeholder):0,   shape=[85]  &quot;values_3:0&quot;
|  Tensor(Const):0, shape=[919] &quot;GatherV2/indices:0&quot;
|  |  [ 0  0  0 ... 83 84 84]
|  Tensor(Const):0, shape=[]    &quot;GatherV2/axis:0&quot;
|  |  0
Tensor(GatherV2):0, shape=[919] &quot;GatherV2_1:0&quot;
|  Tensor(Placeholder):0,   shape=[85]  &quot;values_2:0&quot;
|  Tensor(Const):0, shape=[919] &quot;GatherV2_1/indices:0&quot;
|  |  [ 0  0  0 ... 83 84 84]
|  Tensor(Const):0, shape=[]    &quot;GatherV2_1/axis:0&quot;
|  |  0
Tensor(SquaredDifference):0,    shape=[]    &quot;Normal_5/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,   shape=[]    &quot;Normal_5/log_prob/truediv:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_1:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;Normal/scale:0&quot;
|  |  |  1.
|  Tensor(RealDiv):0,   shape=[]    &quot;Normal_5/log_prob/truediv_1:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;Normal/loc:0&quot;
|  |  |  0.
|  |  Tensor(Const):0,  shape=[]    &quot;Normal/scale:0&quot;
|  |  |  1.
Tensor(SquaredDifference):0,    shape=[]    &quot;Normal_1_1/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,   shape=[]    &quot;Normal_1_1/log_prob/truediv:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_4:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;Normal_1/scale:0&quot;
|  |  |  1.
|  Tensor(RealDiv):0,   shape=[]    &quot;Normal_1_1/log_prob/truediv_1:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;Normal_1/loc:0&quot;
|  |  |  0.
|  |  Tensor(Const):0,  shape=[]    &quot;Normal_1/scale:0&quot;
|  |  |  1.
Tensor(SquaredDifference):0,    shape=[85]  &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,   shape=[85]  &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv:0&quot;
|  |  Tensor(Transpose):0,  shape=[85]  &quot;SampleNormal_2_1/log_prob/transpose:0&quot;
|  |  |  Tensor(Reshape):0, shape=[85]  &quot;SampleNormal_2_1/log_prob/Reshape:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[85]  &quot;values_3:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[1]   &quot;SampleNormal_2_1/log_prob/Reshape/shape:0&quot;
|  |  |  |  |  [85]
|  |  |  Tensor(Const):0,   shape=[1]   &quot;SampleNormal_2_1/log_prob/transpose/perm:0&quot;
|  |  |  |  [0]
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &quot;values_0:0&quot;
|  Tensor(RealDiv):0,   shape=[]    &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv_1:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_1:0&quot;
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_1/forward/Exp:0&quot;
|  |  |  ...
Tensor(SquaredDifference):0,    shape=[85]  &quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,   shape=[85]  &quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv:0&quot;
|  |  Tensor(Transpose):0,  shape=[85]  &quot;SampleNormal_3_1/log_prob/transpose:0&quot;
|  |  |  Tensor(Reshape):0, shape=[85]  &quot;SampleNormal_3_1/log_prob/Reshape:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[85]  &quot;values_2:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[1]   &quot;SampleNormal_3_1/log_prob/Reshape/shape:0&quot;
|  |  |  |  |  [85]
|  |  |  Tensor(Const):0,   shape=[1]   &quot;SampleNormal_3_1/log_prob/transpose/perm:0&quot;
|  |  |  |  [0]
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &quot;values_5:0&quot;
|  Tensor(RealDiv):0,   shape=[]    &quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/truediv_1:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_4:0&quot;
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  ...
Tensor(SquaredDifference):0,    shape=[919] &quot;Normal_4_1/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,   shape=[919] &quot;Normal_4_1/log_prob/truediv:0&quot;
|  |  Tensor(Const):0,  shape=[919] &quot;Normal_4_1/log_prob/value:0&quot;
|  |  |  [0.8329091 0.8329091 1.0986123 ... 1.6292405 1.3350011 1.0986123]
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_3_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &quot;values_6:0&quot;
|  Tensor(RealDiv):0,   shape=[919] &quot;Normal_4_1/log_prob/truediv_1:0&quot;
|  |  Tensor(AddV2):0,  shape=[919] &quot;add:0&quot;
|  |  |  Tensor(GatherV2):0,    shape=[919] &quot;GatherV2:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[85]  &quot;values_3:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[919] &quot;GatherV2/indices:0&quot;
|  |  |  |  |  [ 0  0  0 ... 83 84 84]
|  |  |  |  Tensor(Const):0,    shape=[]    &quot;GatherV2/axis:0&quot;
|  |  |  |  |  0
|  |  |  Tensor(Mul):0, shape=[919] &quot;mul:0&quot;
|  |  |  |  Tensor(GatherV2):0, shape=[919] &quot;GatherV2_1:0&quot;
|  |  |  |  |  Tensor(Placeholder):0,   shape=[85]  &quot;values_2:0&quot;
|  |  |  |  |  Tensor(Const):0, shape=[919] &quot;GatherV2_1/indices:0&quot;
|  |  |  |  |  |  [ 0  0  0 ... 83 84 84]
|  |  |  |  |  Tensor(Const):0, shape=[]    &quot;GatherV2_1/axis:0&quot;
|  |  |  |  |  |  0
|  |  |  |  Tensor(Const):0,    shape=[919] &quot;mul/y:0&quot;
|  |  |  |  |  [1. 0. 0. ... 0. 0. 0.]
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_3_1/forward/Exp:0&quot;
|  |  |  ...

</code></pre>
</figure>
<p>The names in the TFP graph are not based on the PyMC4 model objects, so, to make the graph output slightly more interpretable, Listing <a href="#orgc9910cb">16</a> attempts to re-association the labels.</p>
<figure id="orgc9910cb">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="im">from</span> pprint <span class="im">import</span> pprint</a>
<a class="sourceLine" id="cb16-2" data-line-number="2"></a>
<a class="sourceLine" id="cb16-3" data-line-number="3">tfp_names_to_pymc <span class="op">=</span> {i.name: k <span class="cf">for</span> i, k <span class="kw">in</span> <span class="bu">zip</span>(logpfn_cf.structured_input_signature[<span class="dv">0</span>], init.keys())}</a>
<a class="sourceLine" id="cb16-4" data-line-number="4"></a>
<a class="sourceLine" id="cb16-5" data-line-number="5">pprint(tfp_names_to_pymc)</a></code></pre></div>
<figcaption>
Listing 16
</figcaption>
</figure>
<figure>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb17-1" data-line-number="1">{<span class="st">&#39;values_0&#39;</span>: <span class="st">&#39;hierarchical_model/__log_sigma_alpha&#39;</span>,</a>
<a class="sourceLine" id="cb17-2" data-line-number="2"> <span class="st">&#39;values_1&#39;</span>: <span class="st">&#39;hierarchical_model/mu_alpha&#39;</span>,</a>
<a class="sourceLine" id="cb17-3" data-line-number="3"> <span class="st">&#39;values_2&#39;</span>: <span class="st">&#39;hierarchical_model/beta&#39;</span>,</a>
<a class="sourceLine" id="cb17-4" data-line-number="4"> <span class="st">&#39;values_3&#39;</span>: <span class="st">&#39;hierarchical_model/alpha&#39;</span>,</a>
<a class="sourceLine" id="cb17-5" data-line-number="5"> <span class="st">&#39;values_4&#39;</span>: <span class="st">&#39;hierarchical_model/mu_beta&#39;</span>,</a>
<a class="sourceLine" id="cb17-6" data-line-number="6"> <span class="st">&#39;values_5&#39;</span>: <span class="st">&#39;hierarchical_model/__log_sigma_beta&#39;</span>,</a>
<a class="sourceLine" id="cb17-7" data-line-number="7"> <span class="st">&#39;values_6&#39;</span>: <span class="st">&#39;hierarchical_model/__log_eps&#39;</span>}</a>
<a class="sourceLine" id="cb17-8" data-line-number="8"></a></code></pre></div>
</figure>
</section>
<section id="graph-normalization" class="level2">
<h2>Graph Normalization</h2>
<p>In general, we don’t want our “patterns” to be “brittle”, e.g. rely on explicit–yet variable–term orderings in commutative operators (e.g. a pattern that exclusively targets <code>mt.add(x_lv, y_lv)</code> and won’t match the equivalent <code>mt.add(y_lv, x_lv)</code>).</p>
<p>The <code>grappler</code> library in TensorFlow provides a subset of graph pruning/optimization steps. Ideally, a library like <code>grappler</code> would provide full-fledged graph normalization/canonicalization upon which we could base the subgraphs used in our relations.</p>
<div class="remark" data-markdown="">
<p>While <code>grappler</code> does appear to provide some minimal algebraic normalizations, the extent to which these are performed and their breadth of relevant operator coverage isn’t clear; however, the normalizations that it does provide are worth using, so we’ll make use of them throughout.</p>
</div>
<p>Listing <a href="#org0c58115">18</a> provides a simple means of applying <code>grappler</code>.</p>
<figure id="org0c58115">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="im">from</span> tensorflow.core.protobuf <span class="im">import</span> config_pb2</a>
<a class="sourceLine" id="cb18-2" data-line-number="2"></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="im">from</span> tensorflow.python.framework <span class="im">import</span> ops</a>
<a class="sourceLine" id="cb18-4" data-line-number="4"><span class="im">from</span> tensorflow.python.framework <span class="im">import</span> importer</a>
<a class="sourceLine" id="cb18-5" data-line-number="5"><span class="im">from</span> tensorflow.python.framework <span class="im">import</span> meta_graph</a>
<a class="sourceLine" id="cb18-6" data-line-number="6"></a>
<a class="sourceLine" id="cb18-7" data-line-number="7"><span class="im">from</span> tensorflow.python.grappler <span class="im">import</span> cluster</a>
<a class="sourceLine" id="cb18-8" data-line-number="8"><span class="im">from</span> tensorflow.python.grappler <span class="im">import</span> tf_optimizer</a>
<a class="sourceLine" id="cb18-9" data-line-number="9"></a>
<a class="sourceLine" id="cb18-10" data-line-number="10"></a>
<a class="sourceLine" id="cb18-11" data-line-number="11"><span class="cf">try</span>:</a>
<a class="sourceLine" id="cb18-12" data-line-number="12">    gcluster <span class="op">=</span> cluster.Cluster()</a>
<a class="sourceLine" id="cb18-13" data-line-number="13"><span class="cf">except</span> tf.errors.UnavailableError:</a>
<a class="sourceLine" id="cb18-14" data-line-number="14">    <span class="cf">pass</span></a>
<a class="sourceLine" id="cb18-15" data-line-number="15"></a>
<a class="sourceLine" id="cb18-16" data-line-number="16">config <span class="op">=</span> config_pb2.ConfigProto()</a>
<a class="sourceLine" id="cb18-17" data-line-number="17"></a>
<a class="sourceLine" id="cb18-18" data-line-number="18"></a>
<a class="sourceLine" id="cb18-19" data-line-number="19"><span class="kw">def</span> normalize_tf_graph(graph_output, graph_inputs<span class="op">=</span>[]):</a>
<a class="sourceLine" id="cb18-20" data-line-number="20">    <span class="co">&quot;&quot;&quot;Use grappler to normalize a graph.</span></a>
<a class="sourceLine" id="cb18-21" data-line-number="21"></a>
<a class="sourceLine" id="cb18-22" data-line-number="22"><span class="co">    Arguments</span></a>
<a class="sourceLine" id="cb18-23" data-line-number="23"><span class="co">    =========</span></a>
<a class="sourceLine" id="cb18-24" data-line-number="24"><span class="co">    graph_output: Tensor</span></a>
<a class="sourceLine" id="cb18-25" data-line-number="25"><span class="co">      A tensor we want to consider as &quot;output&quot; of a FuncGraph.</span></a>
<a class="sourceLine" id="cb18-26" data-line-number="26"><span class="co">    graph_inputs: list of Tensor (optional)</span></a>
<a class="sourceLine" id="cb18-27" data-line-number="27"><span class="co">      Any tensors that correspond to inputs for the given output node.</span></a>
<a class="sourceLine" id="cb18-28" data-line-number="28"></a>
<a class="sourceLine" id="cb18-29" data-line-number="29"><span class="co">    Returns</span></a>
<a class="sourceLine" id="cb18-30" data-line-number="30"><span class="co">    =======</span></a>
<a class="sourceLine" id="cb18-31" data-line-number="31"><span class="co">    The simplified graph.</span></a>
<a class="sourceLine" id="cb18-32" data-line-number="32"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb18-33" data-line-number="33">    train_op <span class="op">=</span> graph_output.graph.get_collection_ref(ops.GraphKeys.TRAIN_OP)</a>
<a class="sourceLine" id="cb18-34" data-line-number="34">    train_op.clear()</a>
<a class="sourceLine" id="cb18-35" data-line-number="35">    train_op.extend([graph_output] <span class="op">+</span> graph_inputs)</a>
<a class="sourceLine" id="cb18-36" data-line-number="36"></a>
<a class="sourceLine" id="cb18-37" data-line-number="37">    <span class="co"># if graph_inputs is not None:</span></a>
<a class="sourceLine" id="cb18-38" data-line-number="38">    <span class="co">#     # ops.GraphKeys.MODEL_VARIABLES?</span></a>
<a class="sourceLine" id="cb18-39" data-line-number="39">    <span class="co">#     train_vars = graph_output.graph.get_collection_ref(ops.GraphKeys.TRAINABLE_VARIABLES),</span></a>
<a class="sourceLine" id="cb18-40" data-line-number="40">    <span class="co">#     train_vars.clear()</span></a>
<a class="sourceLine" id="cb18-41" data-line-number="41">    <span class="co">#     train_vars.extend(graph_inputs)</span></a>
<a class="sourceLine" id="cb18-42" data-line-number="42"></a>
<a class="sourceLine" id="cb18-43" data-line-number="43">    metagraph <span class="op">=</span> meta_graph.create_meta_graph_def(graph<span class="op">=</span>graph_output.graph)</a>
<a class="sourceLine" id="cb18-44" data-line-number="44"></a>
<a class="sourceLine" id="cb18-45" data-line-number="45">    optimized_graphdef <span class="op">=</span> tf_optimizer.OptimizeGraph(</a>
<a class="sourceLine" id="cb18-46" data-line-number="46">        config, metagraph, verbose<span class="op">=</span><span class="va">True</span>, cluster<span class="op">=</span>gcluster)</a>
<a class="sourceLine" id="cb18-47" data-line-number="47"></a>
<a class="sourceLine" id="cb18-48" data-line-number="48">    optimized_graph <span class="op">=</span> ops.Graph()</a>
<a class="sourceLine" id="cb18-49" data-line-number="49">    <span class="cf">with</span> optimized_graph.as_default():</a>
<a class="sourceLine" id="cb18-50" data-line-number="50">        importer.import_graph_def(optimized_graphdef, name<span class="op">=</span><span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb18-51" data-line-number="51"></a>
<a class="sourceLine" id="cb18-52" data-line-number="52">    opt_graph_output <span class="op">=</span> optimized_graph.get_tensor_by_name(graph_output.name)</a>
<a class="sourceLine" id="cb18-53" data-line-number="53"></a>
<a class="sourceLine" id="cb18-54" data-line-number="54">    <span class="cf">return</span> opt_graph_output</a></code></pre></div>
<figcaption>
Listing 18
</figcaption>
</figure>
<p>In Listing <a href="#org0c58115">18</a> we run <code>grappler</code> on the log-likelihood graph for a normal random variable from Listing <a href="#orgc47d26d">11</a>.</p>
<figure>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb19-1" data-line-number="1">normal_log_lik_opt <span class="op">=</span> normalize_tf_graph(normal_log_lik)</a></code></pre></div>
</figure>
<p>Listing <a href="#org04c54ca">20</a> compares the computed outputs for the original and normalized graphs–given identical inputs.</p>
<figure id="org04c54ca">
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb20-1" data-line-number="1">res_unopt <span class="op">=</span> normal_log_lik.<span class="bu">eval</span>({<span class="st">&#39;mu:0&#39;</span>: np.r_[<span class="dv">3</span>], <span class="st">&#39;tau:0&#39;</span>: np.r_[<span class="dv">1</span>], <span class="st">&#39;value:0&#39;</span>: np.r_[<span class="dv">1</span>]},</a>
<a class="sourceLine" id="cb20-2" data-line-number="2">                                 session<span class="op">=</span>tf.compat.v1.Session(graph<span class="op">=</span>normal_log_lik.graph))</a>
<a class="sourceLine" id="cb20-3" data-line-number="3"></a>
<a class="sourceLine" id="cb20-4" data-line-number="4">res_opt <span class="op">=</span> normal_log_lik_opt.<span class="bu">eval</span>({<span class="st">&#39;mu:0&#39;</span>: np.r_[<span class="dv">3</span>], <span class="st">&#39;tau:0&#39;</span>: np.r_[<span class="dv">1</span>], <span class="st">&#39;value:0&#39;</span>: np.r_[<span class="dv">1</span>]},</a>
<a class="sourceLine" id="cb20-5" data-line-number="5">                                  session<span class="op">=</span>tf.compat.v1.Session(graph<span class="op">=</span>normal_log_lik_opt.graph))</a>
<a class="sourceLine" id="cb20-6" data-line-number="6"></a>
<a class="sourceLine" id="cb20-7" data-line-number="7"><span class="co"># They should be equal, naturally</span></a>
<a class="sourceLine" id="cb20-8" data-line-number="8"><span class="cf">assert</span> np.array_equal(res_unopt, res_opt)</a>
<a class="sourceLine" id="cb20-9" data-line-number="9"></a>
<a class="sourceLine" id="cb20-10" data-line-number="10">_ <span class="op">=</span> [res_unopt, res_opt]</a></code></pre></div>
<figcaption>
Listing 20
</figcaption>
</figure>
<figure>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb21-1" data-line-number="1">[array([<span class="op">-</span><span class="fl">2.9189386</span>], dtype<span class="op">=</span>float32), array([<span class="op">-</span><span class="fl">2.9189386</span>], dtype<span class="op">=</span>float32)]</a></code></pre></div>
</figure>
<figure id="orge1da777">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb22-1" data-line-number="1">tf_dprint(normal_log_lik_opt)</a></code></pre></div>
<figcaption>
Listing 22
</figcaption>
</figure>
<figure>
<pre class="text"><code>Tensor(Sub):0,  shape=[None]    &quot;Normal_1/log_prob/sub:0&quot;
|  Tensor(Mul):0,   shape=[None]    &quot;Normal_1/log_prob/mul:0&quot;
|  |  Tensor(SquaredDifference):0,  shape=[None]    &quot;Normal_1/log_prob/SquaredDifference:0&quot;
|  |  |  Tensor(RealDiv):0, shape=[None]    &quot;Normal_1/log_prob/truediv:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;value:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;tau:0&quot;
|  |  |  Tensor(RealDiv):0, shape=[None]    &quot;Normal_1/log_prob/truediv_1:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;mu:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;tau:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;Normal_1/log_prob/mul/x:0&quot;
|  |  |  -0.5
|  Tensor(AddV2):0, shape=[None]    &quot;Normal_1/log_prob/add:0&quot;
|  |  Tensor(Log):0,    shape=[None]    &quot;Normal_1/log_prob/Log:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[None]    &quot;tau:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;Normal_1/log_prob/add/x:0&quot;
|  |  |  0.9189385

</code></pre>
</figure>
<p>From the output of Listing <a href="#orge1da777">22</a>, we can see that <code>grappler</code> has performed some constant folding and has reordered the inputs in <code>&quot;add_1_1&quot;</code>–among other things.</p>
</section>
<section id="minikanren-transform-relations" class="level2">
<h2>miniKanren Transform Relations</h2>
<p>In Listing <a href="#org0ad3a96">24</a>, we create miniKanren functions that identify the aforementioned <code>SquaredDifference</code> “chains” and perform the re-centering/scaling substitutions.</p>
<figure id="org0ad3a96">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="im">from</span> itertools <span class="im">import</span> chain</a>
<a class="sourceLine" id="cb24-2" data-line-number="2"><span class="im">from</span> functools <span class="im">import</span> partial</a>
<a class="sourceLine" id="cb24-3" data-line-number="3"></a>
<a class="sourceLine" id="cb24-4" data-line-number="4"><span class="im">from</span> unification <span class="im">import</span> var, reify, unify</a>
<a class="sourceLine" id="cb24-5" data-line-number="5"></a>
<a class="sourceLine" id="cb24-6" data-line-number="6"><span class="im">from</span> kanren <span class="im">import</span> run, eq, lall, conde</a>
<a class="sourceLine" id="cb24-7" data-line-number="7"><span class="im">from</span> kanren.goals <span class="im">import</span> not_equalo</a>
<a class="sourceLine" id="cb24-8" data-line-number="8"><span class="im">from</span> kanren.core <span class="im">import</span> goaleval</a>
<a class="sourceLine" id="cb24-9" data-line-number="9"></a>
<a class="sourceLine" id="cb24-10" data-line-number="10"><span class="im">from</span> symbolic_pymc.tensorflow.meta <span class="im">import</span> mt</a>
<a class="sourceLine" id="cb24-11" data-line-number="11"><span class="im">from</span> symbolic_pymc.relations <span class="im">import</span> buildo</a>
<a class="sourceLine" id="cb24-12" data-line-number="12"><span class="im">from</span> symbolic_pymc.relations.graph <span class="im">import</span> graph_applyo, reduceo</a>
<a class="sourceLine" id="cb24-13" data-line-number="13"><span class="im">from</span> symbolic_pymc.etuple <span class="im">import</span> ExpressionTuple, etuple</a>
<a class="sourceLine" id="cb24-14" data-line-number="14"></a>
<a class="sourceLine" id="cb24-15" data-line-number="15"></a>
<a class="sourceLine" id="cb24-16" data-line-number="16"><span class="kw">def</span> onceo(goal):</a>
<a class="sourceLine" id="cb24-17" data-line-number="17">    <span class="co">&quot;&quot;&quot;A non-relational operator that yields only the first result from a relation.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb24-18" data-line-number="18">    <span class="kw">def</span> onceo_goal(s):</a>
<a class="sourceLine" id="cb24-19" data-line-number="19">        <span class="kw">nonlocal</span> goal</a>
<a class="sourceLine" id="cb24-20" data-line-number="20">        g <span class="op">=</span> reify(goal, s)</a>
<a class="sourceLine" id="cb24-21" data-line-number="21">        g_stream <span class="op">=</span> goaleval(g)(s)</a>
<a class="sourceLine" id="cb24-22" data-line-number="22">        s <span class="op">=</span> <span class="bu">next</span>(g_stream)</a>
<a class="sourceLine" id="cb24-23" data-line-number="23">        <span class="cf">yield</span> s</a>
<a class="sourceLine" id="cb24-24" data-line-number="24"></a>
<a class="sourceLine" id="cb24-25" data-line-number="25">    <span class="cf">return</span> onceo_goal</a>
<a class="sourceLine" id="cb24-26" data-line-number="26"></a>
<a class="sourceLine" id="cb24-27" data-line-number="27"></a>
<a class="sourceLine" id="cb24-28" data-line-number="28"><span class="kw">def</span> tf_graph_applyo(relation, a, b):</a>
<a class="sourceLine" id="cb24-29" data-line-number="29">    <span class="co">&quot;&quot;&quot;Construct a `graph_applyo` goal that evaluates a relation only at tensor nodes in a meta graph.</span></a>
<a class="sourceLine" id="cb24-30" data-line-number="30"></a>
<a class="sourceLine" id="cb24-31" data-line-number="31"><span class="co">    Parameters</span></a>
<a class="sourceLine" id="cb24-32" data-line-number="32"><span class="co">    ----------</span></a>
<a class="sourceLine" id="cb24-33" data-line-number="33"><span class="co">    relation: function</span></a>
<a class="sourceLine" id="cb24-34" data-line-number="34"><span class="co">      A binary relation/goal constructor function</span></a>
<a class="sourceLine" id="cb24-35" data-line-number="35"><span class="co">    a: lvar, meta graph, or etuple</span></a>
<a class="sourceLine" id="cb24-36" data-line-number="36"><span class="co">      The left-hand side of the relation.</span></a>
<a class="sourceLine" id="cb24-37" data-line-number="37"><span class="co">    b: lvar, meta graph, or etuple</span></a>
<a class="sourceLine" id="cb24-38" data-line-number="38"><span class="co">      The right-hand side of the relation</span></a>
<a class="sourceLine" id="cb24-39" data-line-number="39"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb24-40" data-line-number="40"></a>
<a class="sourceLine" id="cb24-41" data-line-number="41">    <span class="kw">def</span> _expand_some_nodes(node):</a>
<a class="sourceLine" id="cb24-42" data-line-number="42">        <span class="cf">if</span> <span class="bu">isinstance</span>(node, mt.Tensor) <span class="kw">and</span> node.op <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</a>
<a class="sourceLine" id="cb24-43" data-line-number="43">            <span class="cf">return</span> etuple(node.operator, <span class="op">*</span>node.inputs, eval_obj<span class="op">=</span>node)</a>
<a class="sourceLine" id="cb24-44" data-line-number="44">        <span class="cf">return</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb24-45" data-line-number="45"></a>
<a class="sourceLine" id="cb24-46" data-line-number="46">    gapplyo <span class="op">=</span> partial(graph_applyo, relation, preprocess_graph<span class="op">=</span>_expand_some_nodes)</a>
<a class="sourceLine" id="cb24-47" data-line-number="47">    <span class="cf">return</span> gapplyo(a, b)</a>
<a class="sourceLine" id="cb24-48" data-line-number="48"></a>
<a class="sourceLine" id="cb24-49" data-line-number="49"></a>
<a class="sourceLine" id="cb24-50" data-line-number="50"><span class="kw">def</span> tfp_normal_log_prob(loc, scale):</a>
<a class="sourceLine" id="cb24-51" data-line-number="51">    log_unnormalized <span class="op">=</span> <span class="fl">-0.5</span> <span class="op">*</span> tf.math.squared_difference(</a>
<a class="sourceLine" id="cb24-52" data-line-number="52">        x <span class="op">/</span> scale, loc <span class="op">/</span> scale)</a>
<a class="sourceLine" id="cb24-53" data-line-number="53">    log_normalization <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> np.log(<span class="fl">2.</span> <span class="op">*</span> np.pi) <span class="op">+</span> tf.math.log(scale)</a>
<a class="sourceLine" id="cb24-54" data-line-number="54">    <span class="cf">return</span> log_unnormalized <span class="op">-</span> log_normalization</a></code></pre></div>
<figcaption>
Listing 24
</figcaption>
</figure>
<figure>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="kw">def</span> shift_squared_subso(in_graph, out_subs):</a>
<a class="sourceLine" id="cb25-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;Construct a goal that produces transforms for chains like (y + x)**2, (x + z)**2.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb25-3" data-line-number="3"></a>
<a class="sourceLine" id="cb25-4" data-line-number="4">    Y_lv, X_lv, mu_X_lv <span class="op">=</span> var(), var(), var()</a>
<a class="sourceLine" id="cb25-5" data-line-number="5">    scale_Y_lv <span class="op">=</span> var()</a>
<a class="sourceLine" id="cb25-6" data-line-number="6"></a>
<a class="sourceLine" id="cb25-7" data-line-number="7">    X_form_lv <span class="op">=</span> mt.Placeholder(dtype<span class="op">=</span>var(), shape<span class="op">=</span>var(), name<span class="op">=</span>var())</a>
<a class="sourceLine" id="cb25-8" data-line-number="8">    <span class="co"># The actual base object&#39;s placeholder might have `_user_specified_name` as</span></a>
<a class="sourceLine" id="cb25-9" data-line-number="9">    <span class="co"># an extra `op.node_def.attr`, so let&#39;s just make the entire NodeDef a</span></a>
<a class="sourceLine" id="cb25-10" data-line-number="10">    <span class="co"># logic variable.</span></a>
<a class="sourceLine" id="cb25-11" data-line-number="11">    X_form_lv.op.node_def <span class="op">=</span> var()</a>
<a class="sourceLine" id="cb25-12" data-line-number="12"></a>
<a class="sourceLine" id="cb25-13" data-line-number="13">    mu_Y_lv <span class="op">=</span> mt.realdiv(X_lv, scale_Y_lv, name<span class="op">=</span>var())</a>
<a class="sourceLine" id="cb25-14" data-line-number="14"></a>
<a class="sourceLine" id="cb25-15" data-line-number="15">    <span class="co"># Y_T_reshaped_lv = mt.Transpose(mt.reshape(Y_lv, var(), name=var()), var())</span></a>
<a class="sourceLine" id="cb25-16" data-line-number="16">    Y_reshaped_lv <span class="op">=</span> mt.reshape(Y_lv, var(), name<span class="op">=</span>var())</a>
<a class="sourceLine" id="cb25-17" data-line-number="17"></a>
<a class="sourceLine" id="cb25-18" data-line-number="18">    sqr_diff_Y_lv <span class="op">=</span> mt.SquaredDifference(</a>
<a class="sourceLine" id="cb25-19" data-line-number="19">        mt.realdiv(Y_reshaped_lv,</a>
<a class="sourceLine" id="cb25-20" data-line-number="20">                   scale_Y_lv,</a>
<a class="sourceLine" id="cb25-21" data-line-number="21">                   name<span class="op">=</span>var()),</a>
<a class="sourceLine" id="cb25-22" data-line-number="22">        mu_Y_lv,</a>
<a class="sourceLine" id="cb25-23" data-line-number="23">        name<span class="op">=</span>var())</a>
<a class="sourceLine" id="cb25-24" data-line-number="24"></a>
<a class="sourceLine" id="cb25-25" data-line-number="25">    <span class="kw">def</span> Y_sqrdiffo(in_g, out_g):</a>
<a class="sourceLine" id="cb25-26" data-line-number="26">        <span class="cf">return</span> lall(eq(in_g, sqr_diff_Y_lv),</a>
<a class="sourceLine" id="cb25-27" data-line-number="27">                    <span class="co"># This just makes sure that we&#39;re only considering X&#39;s</span></a>
<a class="sourceLine" id="cb25-28" data-line-number="28">                    <span class="co"># that are Placeholders.</span></a>
<a class="sourceLine" id="cb25-29" data-line-number="29">                    eq(X_lv, X_form_lv))</a>
<a class="sourceLine" id="cb25-30" data-line-number="30"></a>
<a class="sourceLine" id="cb25-31" data-line-number="31">    scale_X_lv <span class="op">=</span> var()</a>
<a class="sourceLine" id="cb25-32" data-line-number="32">    sqr_diff_X_lv <span class="op">=</span> mt.SquaredDifference(</a>
<a class="sourceLine" id="cb25-33" data-line-number="33">        <span class="co"># Mul is only used because RealDiv with 1 is changed by grappler</span></a>
<a class="sourceLine" id="cb25-34" data-line-number="34">        <span class="co"># mt.realdiv(X_lv, X_denom_lv, name=var()),</span></a>
<a class="sourceLine" id="cb25-35" data-line-number="35">        mt.mul(scale_X_lv, X_lv, name<span class="op">=</span>var()),</a>
<a class="sourceLine" id="cb25-36" data-line-number="36">        mu_X_lv,</a>
<a class="sourceLine" id="cb25-37" data-line-number="37">        name<span class="op">=</span>var())</a>
<a class="sourceLine" id="cb25-38" data-line-number="38"></a>
<a class="sourceLine" id="cb25-39" data-line-number="39">    <span class="kw">def</span> X_sqrdiffo(in_g, out_g):</a>
<a class="sourceLine" id="cb25-40" data-line-number="40">        <span class="cf">return</span> eq(in_g, sqr_diff_X_lv)</a>
<a class="sourceLine" id="cb25-41" data-line-number="41"></a>
<a class="sourceLine" id="cb25-42" data-line-number="42">    Y_new_mt <span class="op">=</span> mt.addv2(X_lv, mt.mul(scale_Y_lv, Y_lv))</a>
<a class="sourceLine" id="cb25-43" data-line-number="43">    Y_log_scale <span class="op">=</span> mt.log(scale_Y_lv, name<span class="op">=</span>var())</a>
<a class="sourceLine" id="cb25-44" data-line-number="44"></a>
<a class="sourceLine" id="cb25-45" data-line-number="45">    res <span class="op">=</span> lall(</a>
<a class="sourceLine" id="cb25-46" data-line-number="46">        <span class="co"># The first (y - x/a)**2 (anywhere in the graph)</span></a>
<a class="sourceLine" id="cb25-47" data-line-number="47">        tf_graph_applyo(Y_sqrdiffo, in_graph, in_graph),</a>
<a class="sourceLine" id="cb25-48" data-line-number="48"></a>
<a class="sourceLine" id="cb25-49" data-line-number="49">        <span class="co"># The corresponding (x/b - z)**2 (also anywhere else in the graph)</span></a>
<a class="sourceLine" id="cb25-50" data-line-number="50">        tf_graph_applyo(X_sqrdiffo, in_graph, in_graph),</a>
<a class="sourceLine" id="cb25-51" data-line-number="51"></a>
<a class="sourceLine" id="cb25-52" data-line-number="52">        <span class="co"># Find the log-scale factor (at this point, we might as well match an</span></a>
<a class="sourceLine" id="cb25-53" data-line-number="53">        <span class="co"># entire normal log-likelihood!)</span></a>
<a class="sourceLine" id="cb25-54" data-line-number="54">        tf_graph_applyo(<span class="kw">lambda</span> x, y: eq(x, Y_log_scale), in_graph, in_graph),</a>
<a class="sourceLine" id="cb25-55" data-line-number="55"></a>
<a class="sourceLine" id="cb25-56" data-line-number="56">        <span class="co"># Not sure if we need this, but we definitely don&#39;t want X == Y</span></a>
<a class="sourceLine" id="cb25-57" data-line-number="57">        (not_equalo, [Y_lv, X_lv], <span class="va">True</span>),</a>
<a class="sourceLine" id="cb25-58" data-line-number="58"></a>
<a class="sourceLine" id="cb25-59" data-line-number="59">        <span class="co"># Create replacement rule pairs</span></a>
<a class="sourceLine" id="cb25-60" data-line-number="60">        eq(out_subs, [[Y_lv, Y_new_mt],</a>
<a class="sourceLine" id="cb25-61" data-line-number="61">                      [Y_log_scale, <span class="fl">0.0</span>]]))</a>
<a class="sourceLine" id="cb25-62" data-line-number="62"></a>
<a class="sourceLine" id="cb25-63" data-line-number="63">    <span class="cf">return</span> res</a></code></pre></div>
</figure>
<figure>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb26-1" data-line-number="1"><span class="kw">def</span> shift_squared_terms(in_obj, graph_inputs<span class="op">=</span>[]):</a>
<a class="sourceLine" id="cb26-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;Re-center/scale SquaredDifference terms corresponding to hierarchical normals.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb26-3" data-line-number="3"></a>
<a class="sourceLine" id="cb26-4" data-line-number="4">    <span class="co"># Normalize and convert to a meta graph</span></a>
<a class="sourceLine" id="cb26-5" data-line-number="5">    in_obj <span class="op">=</span> mt(normalize_tf_graph(in_obj, graph_inputs<span class="op">=</span>graph_inputs))</a>
<a class="sourceLine" id="cb26-6" data-line-number="6"></a>
<a class="sourceLine" id="cb26-7" data-line-number="7">    <span class="co"># This run returns all the substitutions found in the graph</span></a>
<a class="sourceLine" id="cb26-8" data-line-number="8">    subs_lv <span class="op">=</span> var()</a>
<a class="sourceLine" id="cb26-9" data-line-number="9">    subs_res <span class="op">=</span> run(<span class="dv">0</span>, subs_lv, shift_squared_subso(in_obj, subs_lv))</a>
<a class="sourceLine" id="cb26-10" data-line-number="10"></a>
<a class="sourceLine" id="cb26-11" data-line-number="11">    <span class="cf">if</span> <span class="kw">not</span> subs_res:</a>
<a class="sourceLine" id="cb26-12" data-line-number="12">        <span class="bu">print</span>(<span class="st">&quot;Failed to find the required forms within the graph.&quot;</span>)</a>
<a class="sourceLine" id="cb26-13" data-line-number="13">        <span class="cf">return</span></a>
<a class="sourceLine" id="cb26-14" data-line-number="14"></a>
<a class="sourceLine" id="cb26-15" data-line-number="15">    <span class="co"># </span><span class="al">NOTE</span><span class="co">: We&#39;re only going to apply the first transformation pair for now.</span></a>
<a class="sourceLine" id="cb26-16" data-line-number="16">    subs_res <span class="op">=</span> [subs_res[<span class="dv">0</span>]]</a>
<a class="sourceLine" id="cb26-17" data-line-number="17"></a>
<a class="sourceLine" id="cb26-18" data-line-number="18">    <span class="kw">def</span> subs_replaceo(in_g, out_g):</a>
<a class="sourceLine" id="cb26-19" data-line-number="19">        <span class="co">&quot;&quot;&quot;Create a goal that applies substitutions to a graph.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb26-20" data-line-number="20">        <span class="kw">def</span> _subs_replaceo(in_g, out_g):</a>
<a class="sourceLine" id="cb26-21" data-line-number="21">            <span class="kw">nonlocal</span> subs_res</a>
<a class="sourceLine" id="cb26-22" data-line-number="22">            <span class="co"># Each result is a pair of replacement pairs:</span></a>
<a class="sourceLine" id="cb26-23" data-line-number="23">            <span class="co">#   the first pair is the re-center/scale transform,</span></a>
<a class="sourceLine" id="cb26-24" data-line-number="24">            <span class="co">#   the second pair is the cancellation of the log differential scale term.</span></a>
<a class="sourceLine" id="cb26-25" data-line-number="25">            subs_goals <span class="op">=</span> [[eq(in_g, x), eq(out_g, y)]</a>
<a class="sourceLine" id="cb26-26" data-line-number="26">                          <span class="cf">for</span> x, y <span class="kw">in</span> chain.from_iterable(subs_res)]</a>
<a class="sourceLine" id="cb26-27" data-line-number="27">            x_g <span class="op">=</span> conde(<span class="op">*</span>subs_goals)</a>
<a class="sourceLine" id="cb26-28" data-line-number="28">            <span class="cf">return</span> x_g</a>
<a class="sourceLine" id="cb26-29" data-line-number="29"></a>
<a class="sourceLine" id="cb26-30" data-line-number="30">        g <span class="op">=</span> onceo(tf_graph_applyo(_subs_replaceo, in_g, out_g))</a>
<a class="sourceLine" id="cb26-31" data-line-number="31">        <span class="cf">return</span> g</a>
<a class="sourceLine" id="cb26-32" data-line-number="32"></a>
<a class="sourceLine" id="cb26-33" data-line-number="33">    <span class="co"># Apply each substitution once</span></a>
<a class="sourceLine" id="cb26-34" data-line-number="34">    out_graph_lv <span class="op">=</span> var()</a>
<a class="sourceLine" id="cb26-35" data-line-number="35">    res <span class="op">=</span> run(<span class="dv">1</span>, out_graph_lv, reduceo(subs_replaceo, in_obj, out_graph_lv))</a>
<a class="sourceLine" id="cb26-36" data-line-number="36"></a>
<a class="sourceLine" id="cb26-37" data-line-number="37">    <span class="cf">if</span> res:</a>
<a class="sourceLine" id="cb26-38" data-line-number="38"></a>
<a class="sourceLine" id="cb26-39" data-line-number="39">        <span class="kw">def</span> reify_res(graph_res):</a>
<a class="sourceLine" id="cb26-40" data-line-number="40">            <span class="co">&quot;&quot;&quot;Reconstruct and/or reify meta object results.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb26-41" data-line-number="41">            from_etuple <span class="op">=</span> graph_res.eval_obj <span class="cf">if</span> <span class="bu">isinstance</span>(graph_res, ExpressionTuple) <span class="cf">else</span> graph_res</a>
<a class="sourceLine" id="cb26-42" data-line-number="42">            <span class="cf">if</span> <span class="bu">hasattr</span>(from_etuple, <span class="st">&#39;reify&#39;</span>):</a>
<a class="sourceLine" id="cb26-43" data-line-number="43">                <span class="cf">return</span> from_etuple.reify()</a>
<a class="sourceLine" id="cb26-44" data-line-number="44">            <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb26-45" data-line-number="45">                <span class="cf">return</span> from_etuple</a>
<a class="sourceLine" id="cb26-46" data-line-number="46"></a>
<a class="sourceLine" id="cb26-47" data-line-number="47">        res <span class="op">=</span> [reify_res(r) <span class="cf">for</span> r <span class="kw">in</span> res]</a>
<a class="sourceLine" id="cb26-48" data-line-number="48"></a>
<a class="sourceLine" id="cb26-49" data-line-number="49">    <span class="cf">if</span> <span class="bu">len</span>(res) <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> <span class="bu">isinstance</span>(res[<span class="dv">0</span>], tf.Tensor):</a>
<a class="sourceLine" id="cb26-50" data-line-number="50">        graph_res <span class="op">=</span> res[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb26-51" data-line-number="51">        <span class="cf">return</span> normalize_tf_graph(graph_res, graph_inputs<span class="op">=</span>graph_inputs), subs_res</a></code></pre></div>
</figure>
<p>As a test, we will run our miniKanren relations on the log-likelihood graph for a normal-normal hierarchical model in Listing <a href="#org29e93d9">27</a>.</p>
<figure id="org29e93d9">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="cf">with</span> graph_mode(), tf.Graph().as_default() <span class="im">as</span> demo_graph:</a>
<a class="sourceLine" id="cb27-2" data-line-number="2">    X_tfp <span class="op">=</span> tfp.distributions.normal.Normal(<span class="fl">0.0</span>, <span class="fl">1.0</span>, name<span class="op">=</span><span class="st">&#39;X&#39;</span>)</a>
<a class="sourceLine" id="cb27-3" data-line-number="3"></a>
<a class="sourceLine" id="cb27-4" data-line-number="4">    x_tf <span class="op">=</span> tf.compat.v1.placeholder(tf.float32, name<span class="op">=</span><span class="st">&#39;value_x&#39;</span>,</a>
<a class="sourceLine" id="cb27-5" data-line-number="5">                                    shape<span class="op">=</span>tf.TensorShape([<span class="va">None</span>]))</a>
<a class="sourceLine" id="cb27-6" data-line-number="6"></a>
<a class="sourceLine" id="cb27-7" data-line-number="7">    tau_tf <span class="op">=</span> tf.compat.v1.placeholder(tf.float32, name<span class="op">=</span><span class="st">&#39;tau&#39;</span>,</a>
<a class="sourceLine" id="cb27-8" data-line-number="8">                                      shape<span class="op">=</span>tf.TensorShape([<span class="va">None</span>]))</a>
<a class="sourceLine" id="cb27-9" data-line-number="9"></a>
<a class="sourceLine" id="cb27-10" data-line-number="10">    Y_tfp <span class="op">=</span> tfp.distributions.normal.Normal(x_tf, tau_tf, name<span class="op">=</span><span class="st">&#39;Y&#39;</span>)</a>
<a class="sourceLine" id="cb27-11" data-line-number="11"></a>
<a class="sourceLine" id="cb27-12" data-line-number="12">    y_tf <span class="op">=</span> tf.compat.v1.placeholder(tf.float32, name<span class="op">=</span><span class="st">&#39;value_y&#39;</span>,</a>
<a class="sourceLine" id="cb27-13" data-line-number="13">                                    shape<span class="op">=</span>tf.TensorShape([<span class="va">None</span>]))</a>
<a class="sourceLine" id="cb27-14" data-line-number="14"></a>
<a class="sourceLine" id="cb27-15" data-line-number="15">    y_T_reshaped <span class="op">=</span> tf.transpose(tf.reshape(y_tf, []))</a>
<a class="sourceLine" id="cb27-16" data-line-number="16"></a>
<a class="sourceLine" id="cb27-17" data-line-number="17">    hier_norm_lik <span class="op">=</span> tf.math.log(y_tf) <span class="op">+</span> Y_tfp.log_prob(y_T_reshaped) <span class="op">+</span> X_tfp.log_prob(x_tf)</a>
<a class="sourceLine" id="cb27-18" data-line-number="18">    hier_norm_lik <span class="op">=</span> normalize_tf_graph(hier_norm_lik)</a></code></pre></div>
<figcaption>
Listing 27
</figcaption>
</figure>
<p>Listing <a href="#org59b1e29">28</a> shows the form that a graph representing a hierarchical normal-normal model will generally take in TFP.</p>
<figure id="org59b1e29">
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb28-1" data-line-number="1">tf_dprint(hier_norm_lik)</a></code></pre></div>
<figcaption>
Listing 28
</figcaption>
</figure>
<figure>
<pre class="text"><code>Tensor(AddV2):0,    shape=[None]    &quot;add_1:0&quot;
|  Tensor(Sub):0,   shape=[None]    &quot;X_1/log_prob/sub:0&quot;
|  |  Tensor(Mul):0,    shape=[None]    &quot;X_1/log_prob/mul:0&quot;
|  |  |  Tensor(SquaredDifference):0,   shape=[None]    &quot;X_1/log_prob/SquaredDifference:0&quot;
|  |  |  |  Tensor(Mul):0,  shape=[None]    &quot;X_1/log_prob/truediv:0&quot;
|  |  |  |  |  Tensor(Const):0, shape=[]    &quot;ConstantFolding/X_1/log_prob/truediv_recip:0&quot;
|  |  |  |  |  |  1.
|  |  |  |  |  Tensor(Placeholder):0,   shape=[None]    &quot;value_x:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &quot;X_1/log_prob/truediv_1:0&quot;
|  |  |  |  |  0.
|  |  |  Tensor(Const):0,   shape=[]    &quot;Y_1/log_prob/mul/x:0&quot;
|  |  |  |  -0.5
|  |  Tensor(Const):0,  shape=[]    &quot;Y_1/log_prob/add/x:0&quot;
|  |  |  0.9189385
|  Tensor(AddV2):0, shape=[None]    &quot;add:0&quot;
|  |  Tensor(Log):0,    shape=[None]    &quot;Log:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[None]    &quot;value_y:0&quot;
|  |  Tensor(Sub):0,    shape=[None]    &quot;Y_1/log_prob/sub:0&quot;
|  |  |  Tensor(Mul):0, shape=[None]    &quot;Y_1/log_prob/mul:0&quot;
|  |  |  |  Tensor(SquaredDifference):0,    shape=[None]    &quot;Y_1/log_prob/SquaredDifference:0&quot;
|  |  |  |  |  Tensor(RealDiv):0,   shape=[None]    &quot;Y_1/log_prob/truediv:0&quot;
|  |  |  |  |  |  Tensor(Reshape):0,    shape=[]    &quot;Reshape:0&quot;
|  |  |  |  |  |  |  Tensor(Placeholder):0, shape=[None]    &quot;value_y:0&quot;
|  |  |  |  |  |  |  Tensor(Const):0,   shape=[0]   &quot;Reshape/shape:0&quot;
|  |  |  |  |  |  |  |  []
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &quot;tau:0&quot;
|  |  |  |  |  Tensor(RealDiv):0,   shape=[None]    &quot;Y_1/log_prob/truediv_1:0&quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &quot;value_x:0&quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &quot;tau:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &quot;Y_1/log_prob/mul/x:0&quot;
|  |  |  |  |  -0.5
|  |  |  Tensor(AddV2):0,   shape=[None]    &quot;Y_1/log_prob/add:0&quot;
|  |  |  |  Tensor(Log):0,  shape=[None]    &quot;Y_1/log_prob/Log:0&quot;
|  |  |  |  |  Tensor(Placeholder):0,   shape=[None]    &quot;tau:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &quot;Y_1/log_prob/add/x:0&quot;
|  |  |  |  |  0.9189385

</code></pre>
</figure>
<p>Listing <a href="#orgf81b6e5">30</a> runs our transformation and Listing <a href="#orga761bbe">33</a> prints the resulting graph.</p>
<figure id="orgf81b6e5">
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="cf">with</span> graph_mode(), demo_graph.as_default():</a>
<a class="sourceLine" id="cb30-2" data-line-number="2">    test_output_res, test_remaps <span class="op">=</span> shift_squared_terms(hier_norm_lik, graph_inputs<span class="op">=</span>[x_tf, y_tf])</a></code></pre></div>
<figcaption>
Listing 30
</figcaption>
</figure>
<figure>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb31-1" data-line-number="1"><span class="cf">for</span> rm <span class="kw">in</span> test_remaps:</a>
<a class="sourceLine" id="cb31-2" data-line-number="2">    <span class="cf">for</span> r <span class="kw">in</span> rm:</a>
<a class="sourceLine" id="cb31-3" data-line-number="3">      tf_dprint(r[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb31-4" data-line-number="4">      <span class="bu">print</span>(<span class="st">&quot;-&gt;&quot;</span>)</a>
<a class="sourceLine" id="cb31-5" data-line-number="5">      tf_dprint(r[<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb31-6" data-line-number="6">      <span class="bu">print</span>(<span class="st">&quot;------&quot;</span>)</a></code></pre></div>
</figure>
<figure>
<pre class="text"><code>Tensor(Placeholder):0,  shape=[None]    &quot;value_y:0&quot;
-&gt;
Tensor(AddV2):0,    shape=[None]    &quot;AddV2:0&quot;
|  Tensor(Placeholder):0,   shape=[None]    &quot;value_x:0&quot;
|  Tensor(Mul):0,   shape=[None]    &quot;Mul:0&quot;
|  |  Tensor(Placeholder):0,    shape=[None]    &quot;tau:0&quot;
|  |  Tensor(Placeholder):0,    shape=[None]    &quot;value_y:0&quot;
------
Tensor(Log):0,  shape=~_12312   &quot;Y_1/log_prob/Log:0&quot;
|  Tensor(Placeholder):0,   shape=[None]    &quot;tau:0&quot;
-&gt;
0.0
------

</code></pre>
</figure>
<figure id="orga761bbe">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb33-1" data-line-number="1">tf_dprint(test_output_res)</a></code></pre></div>
<figcaption>
Listing 33
</figcaption>
</figure>
<figure>
<pre class="text"><code>Tensor(AddV2):0,    shape=[None]    &quot;add_1_1:0&quot;
|  Tensor(Sub):0,   shape=[None]    &quot;X_1/log_prob/sub:0&quot;
|  |  Tensor(Mul):0,    shape=[None]    &quot;X_1/log_prob/mul:0&quot;
|  |  |  Tensor(SquaredDifference):0,   shape=[None]    &quot;X_1/log_prob/SquaredDifference:0&quot;
|  |  |  |  Tensor(Mul):0,  shape=[None]    &quot;X_1/log_prob/truediv:0&quot;
|  |  |  |  |  Tensor(Const):0, shape=[]    &quot;ConstantFolding/X_1/log_prob/truediv_recip:0&quot;
|  |  |  |  |  |  1.
|  |  |  |  |  Tensor(Placeholder):0,   shape=[None]    &quot;value_x:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &quot;X_1/log_prob/truediv_1:0&quot;
|  |  |  |  |  0.
|  |  |  Tensor(Const):0,   shape=[]    &quot;Y_1/log_prob/mul/x:0&quot;
|  |  |  |  -0.5
|  |  Tensor(Const):0,  shape=[]    &quot;Y_1/log_prob/add/x:0&quot;
|  |  |  0.9189385
|  Tensor(AddV2):0, shape=[None]    &quot;add_2:0&quot;
|  |  Tensor(Log):0,    shape=[None]    &quot;Log_1:0&quot;
|  |  |  Tensor(AddV2):0,   shape=[None]    &quot;AddV2:0&quot;
|  |  |  |  Tensor(Mul):0,  shape=[None]    &quot;Mul:0&quot;
|  |  |  |  |  Tensor(Placeholder):0,   shape=[None]    &quot;tau:0&quot;
|  |  |  |  |  Tensor(Placeholder):0,   shape=[None]    &quot;value_y:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[None]    &quot;value_x:0&quot;
|  |  Tensor(Sub):0,    shape=[None]    &quot;Y_1/log_prob/sub_1:0&quot;
|  |  |  Tensor(Mul):0, shape=[None]    &quot;Y_1/log_prob/mul_1:0&quot;
|  |  |  |  Tensor(SquaredDifference):0,    shape=[None]    &quot;Y_1/log_prob/SquaredDifference_1:0&quot;
|  |  |  |  |  Tensor(RealDiv):0,   shape=[None]    &quot;Y_1/log_prob/truediv_1:0&quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &quot;value_x:0&quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &quot;tau:0&quot;
|  |  |  |  |  Tensor(RealDiv):0,   shape=[None]    &quot;Y_1/log_prob/truediv_2:0&quot;
|  |  |  |  |  |  Tensor(Reshape):0,    shape=[]    &quot;Reshape_1:0&quot;
|  |  |  |  |  |  |  Tensor(AddV2):0,   shape=[None]    &quot;AddV2:0&quot;
|  |  |  |  |  |  |  |  ...
|  |  |  |  |  |  |  Tensor(Const):0,   shape=[0]   &quot;Reshape/shape:0&quot;
|  |  |  |  |  |  |  |  []
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[None]    &quot;tau:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[]    &quot;Y_1/log_prob/mul/x:0&quot;
|  |  |  |  |  -0.5
|  |  |  Tensor(Const):0,   shape=[]    &quot;Y_1/log_prob/add/x:0&quot;
|  |  |  |  0.9189385

</code></pre>
</figure>
</section>
<section id="missing-graph-simplifications" class="level2">
<h2>Missing Graph Simplifications</h2>
<p>From Listing <a href="#orga761bbe">33</a> we can see that <code>grappler</code> is not applying enough algebraic simplifications (e.g. it doesn’t remove multiplications with 1 or reduce the <span class="math inline">\(\left(\mu + x - \mu \right)^2\)</span> term in <code>SquaredDifference</code>).</p>
<p>Does missing this simplification amount to anything practical? Listing <a href="#orga71aafb">35</a> demonstrates the difference between our model without the simplification and a manually constructed model without the redundancy in <code>SquaredDifference</code>.</p>
<figure id="orga71aafb">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb35-1" data-line-number="1"><span class="kw">def</span> compute_point_diff():</a>
<a class="sourceLine" id="cb35-2" data-line-number="2">    <span class="cf">with</span> graph_mode(), demo_graph.as_default():</a>
<a class="sourceLine" id="cb35-3" data-line-number="3"></a>
<a class="sourceLine" id="cb35-4" data-line-number="4">        Y_trans_tfp <span class="op">=</span> tfp.distributions.normal.Normal(<span class="fl">0.0</span>, <span class="fl">1.0</span>, name<span class="op">=</span><span class="st">&#39;Y_trans&#39;</span>)</a>
<a class="sourceLine" id="cb35-5" data-line-number="5"></a>
<a class="sourceLine" id="cb35-6" data-line-number="6">        y_shifted_tf <span class="op">=</span> x_tf <span class="op">+</span> tau_tf <span class="op">*</span> y_tf</a>
<a class="sourceLine" id="cb35-7" data-line-number="7"></a>
<a class="sourceLine" id="cb35-8" data-line-number="8">        hier_norm_trans_lik <span class="op">=</span> tf.math.log(y_shifted_tf) <span class="op">+</span> Y_trans_tfp.log_prob(y_T_reshaped) <span class="op">+</span> X_tfp.log_prob(x_tf)</a>
<a class="sourceLine" id="cb35-9" data-line-number="9">        hier_norm_trans_lik <span class="op">=</span> normalize_tf_graph(hier_norm_trans_lik)</a>
<a class="sourceLine" id="cb35-10" data-line-number="10"></a>
<a class="sourceLine" id="cb35-11" data-line-number="11"></a>
<a class="sourceLine" id="cb35-12" data-line-number="12">    test_point <span class="op">=</span> {x_tf.name: np.r_[<span class="fl">1.0</span>],</a>
<a class="sourceLine" id="cb35-13" data-line-number="13">                  tau_tf.name: np.r_[<span class="fl">1e-20</span>],</a>
<a class="sourceLine" id="cb35-14" data-line-number="14">                  y_tf.name: np.r_[<span class="fl">1000.1</span>]}</a>
<a class="sourceLine" id="cb35-15" data-line-number="15"></a>
<a class="sourceLine" id="cb35-16" data-line-number="16">    <span class="cf">with</span> tf.compat.v1.Session(graph<span class="op">=</span>test_output_res.graph).as_default():</a>
<a class="sourceLine" id="cb35-17" data-line-number="17">        val <span class="op">=</span> test_output_res.<span class="bu">eval</span>(test_point)</a>
<a class="sourceLine" id="cb35-18" data-line-number="18"></a>
<a class="sourceLine" id="cb35-19" data-line-number="19">    <span class="cf">with</span> tf.compat.v1.Session(graph<span class="op">=</span>hier_norm_trans_lik.graph).as_default():</a>
<a class="sourceLine" id="cb35-20" data-line-number="20">        val_2 <span class="op">=</span> hier_norm_trans_lik.<span class="bu">eval</span>(test_point)</a>
<a class="sourceLine" id="cb35-21" data-line-number="21"></a>
<a class="sourceLine" id="cb35-22" data-line-number="22">    <span class="cf">return</span> val, val_2</a></code></pre></div>
<figcaption>
Listing 35
</figcaption>
</figure>
<figure id="org7e4367b">
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb36-1" data-line-number="1">_ <span class="op">=</span> np.subtract(<span class="op">*</span>compute_point_diff())</a></code></pre></div>
<figcaption>
Listing 36
</figcaption>
</figure>
<figure>
<pre class="text"><code>[500099.94]</code></pre>
</figure>
<p>The output of Listing <a href="#org7e4367b">36</a> shows exactly how large the discrepancy can be for carefully chosen parameter values. More specifically, as <code>tau_tf</code> gets smaller and the magnitude of the difference <code>x_tf - y_tf</code> gets larger, the discrepancy can increase. Since such parameter values are likely to be visited during sampling, we should address this missing simplification.</p>
<p>In Listing <a href="#orge313efe">39</a> we create a goal that performs that aforementioned simplification for <code>SquaredDifference</code>.</p>
<figure>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb38-1" data-line-number="1"><span class="kw">def</span> recenter_sqrdiffo(in_g, out_g):</a>
<a class="sourceLine" id="cb38-2" data-line-number="2">    <span class="co">&quot;&quot;&quot;Create a goal that reduces `(a/d - (a + c)/d)**2` to `()`&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb38-3" data-line-number="3">    a_sqd_lv, b_sqd_lv, d_sqd_lv <span class="op">=</span> var(), var(), var()</a>
<a class="sourceLine" id="cb38-4" data-line-number="4">    target_sqrdiff_lv <span class="op">=</span> mt.SquaredDifference(</a>
<a class="sourceLine" id="cb38-5" data-line-number="5">        mt.realdiv(a_sqd_lv, d_sqd_lv, name<span class="op">=</span>var()),</a>
<a class="sourceLine" id="cb38-6" data-line-number="6">        mt.realdiv(b_sqd_lv, d_sqd_lv, name<span class="op">=</span>var()),</a>
<a class="sourceLine" id="cb38-7" data-line-number="7">        name<span class="op">=</span>var()</a>
<a class="sourceLine" id="cb38-8" data-line-number="8">    )</a>
<a class="sourceLine" id="cb38-9" data-line-number="9"></a>
<a class="sourceLine" id="cb38-10" data-line-number="10">    c_sqd_lv <span class="op">=</span> var()</a>
<a class="sourceLine" id="cb38-11" data-line-number="11">    b_part_lv <span class="op">=</span> mt.addv2(mt.mul(d_sqd_lv, c_sqd_lv, name<span class="op">=</span>var()), a_sqd_lv, name<span class="op">=</span>var())</a>
<a class="sourceLine" id="cb38-12" data-line-number="12"></a>
<a class="sourceLine" id="cb38-13" data-line-number="13">    simplified_sqrdiff_lv <span class="op">=</span> mt.SquaredDifference(</a>
<a class="sourceLine" id="cb38-14" data-line-number="14">        c_sqd_lv,</a>
<a class="sourceLine" id="cb38-15" data-line-number="15">        <span class="fl">0.0</span></a>
<a class="sourceLine" id="cb38-16" data-line-number="16">    )</a>
<a class="sourceLine" id="cb38-17" data-line-number="17"></a>
<a class="sourceLine" id="cb38-18" data-line-number="18">    reshape_lv <span class="op">=</span> var()</a>
<a class="sourceLine" id="cb38-19" data-line-number="19">    simplified_sqrdiff_reshaped_lv <span class="op">=</span> mt.SquaredDifference(</a>
<a class="sourceLine" id="cb38-20" data-line-number="20">        mt.reshape(c_sqd_lv, reshape_lv),</a>
<a class="sourceLine" id="cb38-21" data-line-number="21">        <span class="fl">0.0</span></a>
<a class="sourceLine" id="cb38-22" data-line-number="22">    )</a>
<a class="sourceLine" id="cb38-23" data-line-number="23"></a>
<a class="sourceLine" id="cb38-24" data-line-number="24">    res <span class="op">=</span> lall(eq(in_g, target_sqrdiff_lv),</a>
<a class="sourceLine" id="cb38-25" data-line-number="25">               conde([eq(b_sqd_lv, b_part_lv),</a>
<a class="sourceLine" id="cb38-26" data-line-number="26">                      eq(out_g, simplified_sqrdiff_lv)],</a>
<a class="sourceLine" id="cb38-27" data-line-number="27">                     <span class="co"># Maybe it&#39;s been reshaped</span></a>
<a class="sourceLine" id="cb38-28" data-line-number="28">                     [eq(b_sqd_lv, mt.reshape(b_part_lv, reshape_lv, name<span class="op">=</span>var())),</a>
<a class="sourceLine" id="cb38-29" data-line-number="29">                      eq(out_g, simplified_sqrdiff_reshaped_lv)]))</a>
<a class="sourceLine" id="cb38-30" data-line-number="30">    <span class="cf">return</span> res</a></code></pre></div>
</figure>
<p>We apply the simplification in Listing <a href="#orge313efe">39</a> and print the results in <a href="#orga55e147">40</a>.</p>
<figure id="orge313efe">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb39-1" data-line-number="1"><span class="cf">with</span> graph_mode(), test_output_res.graph.as_default():</a>
<a class="sourceLine" id="cb39-2" data-line-number="2"></a>
<a class="sourceLine" id="cb39-3" data-line-number="3">    res <span class="op">=</span> run(<span class="dv">1</span>, var(<span class="st">&#39;q&#39;</span>),</a>
<a class="sourceLine" id="cb39-4" data-line-number="4">              reduceo(<span class="kw">lambda</span> x, y: tf_graph_applyo(recenter_sqrdiffo, x, y),</a>
<a class="sourceLine" id="cb39-5" data-line-number="5">                      test_output_res, var(<span class="st">&#39;q&#39;</span>)))</a>
<a class="sourceLine" id="cb39-6" data-line-number="6"></a>
<a class="sourceLine" id="cb39-7" data-line-number="7">    test_output_res <span class="op">=</span> normalize_tf_graph(res[<span class="dv">0</span>].eval_obj.reify())</a></code></pre></div>
<figcaption>
Listing 39
</figcaption>
</figure>
<figure id="orga55e147">
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb40-1" data-line-number="1">tf_dprint(test_output_res.graph.get_tensor_by_name(<span class="st">&#39;SquaredDifference:0&#39;</span>))</a></code></pre></div>
<figcaption>
Listing 40
</figcaption>
</figure>
<figure>
<pre class="text"><code>Tensor(SquaredDifference):0,    shape=[None]    &quot;SquaredDifference:0&quot;
|  Tensor(Const):0, shape=[]    &quot;X_1/log_prob/truediv_1:0&quot;
|  |  0.
|  Tensor(Placeholder):0,   shape=[None]    &quot;value_y:0&quot;

</code></pre>
</figure>
<p>After simplification, the difference is now gone.</p>
<figure>
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb42-1" data-line-number="1">_ <span class="op">=</span> np.subtract(<span class="op">*</span>compute_point_diff())</a></code></pre></div>
</figure>
<figure>
<pre class="text"><code>[0.]</code></pre>
</figure>
</section>
</section>
<section id="transforming-the-log-likelihood-graph" class="level1">
<h1>Transforming the Log-likelihood Graph</h1>
<p>Now, we’re ready to apply the transform to the radon model log-likelihood graph.</p>
<figure>
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="cf">with</span> graph_mode(), tf.Graph().as_default() <span class="im">as</span> trans_graph:</a>
<a class="sourceLine" id="cb44-2" data-line-number="2"></a>
<a class="sourceLine" id="cb44-3" data-line-number="3">    graph_inputs <span class="op">=</span> [logpfn_fg.get_operation_by_name(i.name).outputs[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb44-4" data-line-number="4">                    <span class="cf">for</span> i <span class="kw">in</span> logpfn_cf.structured_input_signature[<span class="dv">0</span>]]</a>
<a class="sourceLine" id="cb44-5" data-line-number="5"></a>
<a class="sourceLine" id="cb44-6" data-line-number="6">    logpfn_trans_tf, logpfn_remaps <span class="op">=</span> shift_squared_terms(logpfn_fg.outputs[<span class="dv">0</span>], graph_inputs<span class="op">=</span>graph_inputs)</a>
<a class="sourceLine" id="cb44-7" data-line-number="7"></a>
<a class="sourceLine" id="cb44-8" data-line-number="8"><span class="cf">with</span> graph_mode(), logpfn_trans_tf.graph.as_default():</a>
<a class="sourceLine" id="cb44-9" data-line-number="9"></a>
<a class="sourceLine" id="cb44-10" data-line-number="10">    res <span class="op">=</span> run(<span class="dv">1</span>, var(<span class="st">&#39;q&#39;</span>),</a>
<a class="sourceLine" id="cb44-11" data-line-number="11">              reduceo(<span class="kw">lambda</span> x, y: tf_graph_applyo(recenter_sqrdiffo, x, y),</a>
<a class="sourceLine" id="cb44-12" data-line-number="12">                      logpfn_trans_tf, var(<span class="st">&#39;q&#39;</span>)))</a>
<a class="sourceLine" id="cb44-13" data-line-number="13"></a>
<a class="sourceLine" id="cb44-14" data-line-number="14">    logpfn_trans_tf <span class="op">=</span> normalize_tf_graph(res[<span class="dv">0</span>].eval_obj.reify())</a></code></pre></div>
</figure>
<p>Listing <a href="#org73bcbee">45</a> shows the replacements that were made throughout the graph. Two replacements were found and they appear to correspond to the un-centered normal distribution terms <code>a</code> and <code>b</code> in our model–as intended.</p>
<figure id="org73bcbee">
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb45-1" data-line-number="1"><span class="cf">for</span> rm <span class="kw">in</span> logpfn_remaps:</a>
<a class="sourceLine" id="cb45-2" data-line-number="2">    <span class="cf">for</span> r <span class="kw">in</span> rm:</a>
<a class="sourceLine" id="cb45-3" data-line-number="3">      tf_dprint(r[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb45-4" data-line-number="4">      <span class="bu">print</span>(<span class="st">&quot;-&gt;&quot;</span>)</a>
<a class="sourceLine" id="cb45-5" data-line-number="5">      tf_dprint(r[<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb45-6" data-line-number="6">      <span class="bu">print</span>(<span class="st">&quot;------&quot;</span>)</a></code></pre></div>
<figcaption>
Listing 45
</figcaption>
</figure>
<figure>
<pre class="text"><code>Tensor(Placeholder):0,  shape=[85]  &quot;values_2:0&quot;
-&gt;
Tensor(AddV2):0,    shape=[85]  &quot;AddV2:0&quot;
|  Tensor(Placeholder):0,   shape=[]    &quot;values_4:0&quot;
|  Tensor(Mul):0,   shape=[85]  &quot;Mul_4:0&quot;
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &quot;values_5:0&quot;
|  |  Tensor(Placeholder):0,    shape=[85]  &quot;values_2:0&quot;
------
Tensor(Log):0,  shape=~_175065  &quot;SampleNormal_3_1/log_prob/Normal_3/log_prob/Log:0&quot;
|  Tensor(Exp):0,   shape=[]    &quot;exp_2_1/forward/Exp:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_5:0&quot;
-&gt;
0.0
------

</code></pre>
</figure>
<p>Likewise, Listing <a href="#org0ce0bba">47</a> shows <code>SquaredDifference</code> subgraphs that appear in the transformed log-likelihood.</p>
<figure id="org0ce0bba">
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb47-1" data-line-number="1">square_diff_outs <span class="op">=</span> [o.outputs[<span class="dv">0</span>] <span class="cf">for</span> o <span class="kw">in</span> logpfn_trans_tf.graph.get_operations()</a>
<a class="sourceLine" id="cb47-2" data-line-number="2">                    <span class="cf">if</span> o.<span class="bu">type</span> <span class="op">==</span> <span class="st">&#39;SquaredDifference&#39;</span> <span class="kw">or</span></a>
<a class="sourceLine" id="cb47-3" data-line-number="3">                    o.<span class="bu">type</span>.startswith(<span class="st">&#39;Gather&#39;</span>) <span class="kw">or</span> o.<span class="bu">type</span> <span class="op">==</span> <span class="st">&#39;Log&#39;</span>]</a>
<a class="sourceLine" id="cb47-4" data-line-number="4"></a>
<a class="sourceLine" id="cb47-5" data-line-number="5"><span class="cf">for</span> t <span class="kw">in</span> square_diff_outs:</a>
<a class="sourceLine" id="cb47-6" data-line-number="6">    tf_dprint(t)</a></code></pre></div>
<figcaption>
Listing 47
</figcaption>
</figure>
<figure>
<pre class="text"><code>Tensor(GatherV2):0, shape=[919] &quot;GatherV2:0&quot;
|  Tensor(Placeholder):0,   shape=[85]  &quot;values_3:0&quot;
|  Tensor(Const):0, shape=[919] &quot;GatherV2/indices:0&quot;
|  |  [ 0  0  0 ... 83 84 84]
|  Tensor(Const):0, shape=[]    &quot;GatherV2/axis:0&quot;
|  |  0
Tensor(Log):0,  shape=[]    &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/Log:0&quot;
|  Tensor(Exp):0,   shape=[]    &quot;exp_1/forward/Exp:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_0:0&quot;
Tensor(SquaredDifference):0,    shape=[]    &quot;Normal_5/log_prob/SquaredDifference:0&quot;
|  Tensor(Const):0, shape=[]    &quot;Const_723:0&quot;
|  |  0.
|  Tensor(Mul):0,   shape=[]    &quot;Normal_5/log_prob/truediv:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&quot;
|  |  |  1.
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_1:0&quot;
Tensor(SquaredDifference):0,    shape=[85]  &quot;SquaredDifference:0&quot;
|  Tensor(Const):0, shape=[]    &quot;Const_723:0&quot;
|  |  0.
|  Tensor(Reshape):0,   shape=[85]  &quot;Reshape:0&quot;
|  |  Tensor(Placeholder):0,    shape=[85]  &quot;values_2:0&quot;
|  |  Tensor(Const):0,  shape=[1]   &quot;SampleNormal_2_1/log_prob/Reshape/shape:0&quot;
|  |  |  [85]
Tensor(SquaredDifference):0,    shape=[]    &quot;Normal_1_1/log_prob/SquaredDifference:0&quot;
|  Tensor(Const):0, shape=[]    &quot;Const_723:0&quot;
|  |  0.
|  Tensor(Mul):0,   shape=[]    &quot;Normal_1_1/log_prob/truediv:0&quot;
|  |  Tensor(Const):0,  shape=[]    &quot;exp_3_2/inverse_log_det_jacobian/mul_1:0&quot;
|  |  |  1.
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_4:0&quot;
Tensor(Log):0,  shape=[]    &quot;Normal_4_1/log_prob/Log:0&quot;
|  Tensor(Exp):0,   shape=[]    &quot;exp_3_1/forward/Exp:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_6:0&quot;
Tensor(SquaredDifference):0,    shape=[85]  &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/SquaredDifference:0&quot;
|  Tensor(RealDiv):0,   shape=[85]  &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv:0&quot;
|  |  Tensor(Reshape):0,    shape=[85]  &quot;SampleNormal_2_1/log_prob/Reshape:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[85]  &quot;values_3:0&quot;
|  |  |  Tensor(Const):0,   shape=[1]   &quot;SampleNormal_2_1/log_prob/Reshape/shape:0&quot;
|  |  |  |  [85]
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &quot;values_0:0&quot;
|  Tensor(RealDiv):0,   shape=[]    &quot;SampleNormal_2_1/log_prob/Normal_2/log_prob/truediv_1:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_1:0&quot;
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_1/forward/Exp:0&quot;
|  |  |  ...
Tensor(GatherV2):0, shape=[919] &quot;GatherV2_1_1:0&quot;
|  Tensor(AddV2):0, shape=[85]  &quot;AddV2:0&quot;
|  |  Tensor(Mul):0,    shape=[85]  &quot;Mul_4:0&quot;
|  |  |  Tensor(Exp):0, shape=[]    &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[]    &quot;values_5:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[85]  &quot;values_2:0&quot;
|  |  Tensor(Placeholder):0,    shape=[]    &quot;values_4:0&quot;
|  Tensor(Const):0, shape=[919] &quot;GatherV2/indices:0&quot;
|  |  [ 0  0  0 ... 83 84 84]
|  Tensor(Const):0, shape=[]    &quot;GatherV2/axis:0&quot;
|  |  0
Tensor(SquaredDifference):0,    shape=[919] &quot;Normal_4_1/log_prob/SquaredDifference_1:0&quot;
|  Tensor(RealDiv):0,   shape=[919] &quot;Normal_4_1/log_prob/truediv:0&quot;
|  |  Tensor(Const):0,  shape=[919] &quot;Normal_4_1/log_prob/value:0&quot;
|  |  |  [0.8329091 0.8329091 1.0986123 ... 1.6292405 1.3350011 1.0986123]
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_3_1/forward/Exp:0&quot;
|  |  |  Tensor(Placeholder):0, shape=[]    &quot;values_6:0&quot;
|  Tensor(RealDiv):0,   shape=[919] &quot;Normal_4_1/log_prob/truediv_1_1:0&quot;
|  |  Tensor(AddV2):0,  shape=[919] &quot;add_12:0&quot;
|  |  |  Tensor(GatherV2):0,    shape=[919] &quot;GatherV2:0&quot;
|  |  |  |  Tensor(Placeholder):0,  shape=[85]  &quot;values_3:0&quot;
|  |  |  |  Tensor(Const):0,    shape=[919] &quot;GatherV2/indices:0&quot;
|  |  |  |  |  [ 0  0  0 ... 83 84 84]
|  |  |  |  Tensor(Const):0,    shape=[]    &quot;GatherV2/axis:0&quot;
|  |  |  |  |  0
|  |  |  Tensor(Mul):0, shape=[919] &quot;mul_5:0&quot;
|  |  |  |  Tensor(GatherV2):0, shape=[919] &quot;GatherV2_1_1:0&quot;
|  |  |  |  |  Tensor(AddV2):0, shape=[85]  &quot;AddV2:0&quot;
|  |  |  |  |  |  Tensor(Mul):0,    shape=[85]  &quot;Mul_4:0&quot;
|  |  |  |  |  |  |  Tensor(Exp):0, shape=[]    &quot;exp_2_1/forward/Exp:0&quot;
|  |  |  |  |  |  |  |  Tensor(Placeholder):0,  shape=[]    &quot;values_5:0&quot;
|  |  |  |  |  |  |  Tensor(Placeholder):0, shape=[85]  &quot;values_2:0&quot;
|  |  |  |  |  |  Tensor(Placeholder):0,    shape=[]    &quot;values_4:0&quot;
|  |  |  |  |  Tensor(Const):0, shape=[919] &quot;GatherV2/indices:0&quot;
|  |  |  |  |  |  [ 0  0  0 ... 83 84 84]
|  |  |  |  |  Tensor(Const):0, shape=[]    &quot;GatherV2/axis:0&quot;
|  |  |  |  |  |  0
|  |  |  |  Tensor(Const):0,    shape=[919] &quot;mul/y:0&quot;
|  |  |  |  |  [1. 0. 0. ... 0. 0. 0.]
|  |  Tensor(Exp):0,    shape=[]    &quot;exp_3_1/forward/Exp:0&quot;
|  |  |  ...

</code></pre>
</figure>
</section>
<section id="creating-a-new-log-likelihood-function" class="level1">
<h1>Creating a new Log-likelihood Function</h1>
<p>Now that we have a transformed version of the original log-likelihood graph (i.e. <code>logpfn_trans_tf</code>), we need to create a new <code>FuncGraph</code> from it. Listing <a href="#org87b4c38">49</a> provides a simple function that creates a new <code>ConcreteFunction</code> from an updated output node.</p>
<figure id="org87b4c38">
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb49-1" data-line-number="1"><span class="im">from</span> tensorflow.python.framework.func_graph <span class="im">import</span> FuncGraph</a>
<a class="sourceLine" id="cb49-2" data-line-number="2"><span class="im">from</span> tensorflow.python.eager.function <span class="im">import</span> ConcreteFunction</a>
<a class="sourceLine" id="cb49-3" data-line-number="3"><span class="im">from</span> tensorflow.python.eager.lift_to_graph <span class="im">import</span> lift_to_graph</a>
<a class="sourceLine" id="cb49-4" data-line-number="4"></a>
<a class="sourceLine" id="cb49-5" data-line-number="5"></a>
<a class="sourceLine" id="cb49-6" data-line-number="6"><span class="kw">def</span> new_tf_function(output, orig_cf):</a>
<a class="sourceLine" id="cb49-7" data-line-number="7">    <span class="co">&quot;&quot;&quot;Create a new ConcreteFunction by replacing a single output in an existing FuncGraph.</span></a>
<a class="sourceLine" id="cb49-8" data-line-number="8"></a>
<a class="sourceLine" id="cb49-9" data-line-number="9"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb49-10" data-line-number="10">    orig_fg <span class="op">=</span> orig_cf.graph</a>
<a class="sourceLine" id="cb49-11" data-line-number="11">    <span class="co"># with trans_graph.as_default(): #orig_fg.as_default():</span></a>
<a class="sourceLine" id="cb49-12" data-line-number="12"></a>
<a class="sourceLine" id="cb49-13" data-line-number="13">    logpfn_fg_new <span class="op">=</span> FuncGraph(<span class="st">&#39;logpfn_new&#39;</span>, orig_fg.collections, orig_fg.capture_by_value)</a>
<a class="sourceLine" id="cb49-14" data-line-number="14"></a>
<a class="sourceLine" id="cb49-15" data-line-number="15">    old_to_new_ops <span class="op">=</span> lift_to_graph([output],</a>
<a class="sourceLine" id="cb49-16" data-line-number="16">                                    logpfn_fg_new,</a>
<a class="sourceLine" id="cb49-17" data-line-number="17">                                    add_sources<span class="op">=</span><span class="va">True</span>,</a>
<a class="sourceLine" id="cb49-18" data-line-number="18">                                    handle_captures<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb49-19" data-line-number="19"></a>
<a class="sourceLine" id="cb49-20" data-line-number="20">    logpfn_fg_new.structured_input_signature <span class="op">=</span> orig_fg.structured_input_signature</a>
<a class="sourceLine" id="cb49-21" data-line-number="21"></a>
<a class="sourceLine" id="cb49-22" data-line-number="22">    new_inputs <span class="op">=</span> [old_to_new_ops.get(output.graph.get_operation_by_name(i.name).outputs[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb49-23" data-line-number="23">                  <span class="cf">for</span> i <span class="kw">in</span> orig_cf.structured_input_signature[<span class="dv">0</span>]]</a>
<a class="sourceLine" id="cb49-24" data-line-number="24"></a>
<a class="sourceLine" id="cb49-25" data-line-number="25">    logpfn_fg_new.inputs <span class="op">=</span> new_inputs</a>
<a class="sourceLine" id="cb49-26" data-line-number="26"></a>
<a class="sourceLine" id="cb49-27" data-line-number="27">    <span class="cf">assert</span> <span class="bu">all</span>(i <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">for</span> i <span class="kw">in</span> logpfn_fg_new.inputs)</a>
<a class="sourceLine" id="cb49-28" data-line-number="28"></a>
<a class="sourceLine" id="cb49-29" data-line-number="29">    logpfn_fg_new.outputs <span class="op">=</span> [old_to_new_ops[output]]</a>
<a class="sourceLine" id="cb49-30" data-line-number="30">    logpfn_fg_new.structured_outputs <span class="op">=</span> logpfn_fg_new.outputs[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb49-31" data-line-number="31"></a>
<a class="sourceLine" id="cb49-32" data-line-number="32">    <span class="cf">assert</span> logpfn_fg_new.as_graph_element(logpfn_fg_new.outputs[<span class="dv">0</span>]) <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb49-33" data-line-number="33"></a>
<a class="sourceLine" id="cb49-34" data-line-number="34">    logpfn_new_cf <span class="op">=</span> ConcreteFunction(logpfn_fg_new)</a>
<a class="sourceLine" id="cb49-35" data-line-number="35">    logpfn_new_cf._arg_keywords <span class="op">=</span> orig_cf._arg_keywords</a>
<a class="sourceLine" id="cb49-36" data-line-number="36">    logpfn_new_cf._num_positional_args <span class="op">=</span> <span class="bu">len</span>(logpfn_fg_new.inputs)</a>
<a class="sourceLine" id="cb49-37" data-line-number="37"></a>
<a class="sourceLine" id="cb49-38" data-line-number="38">    <span class="cf">return</span> logpfn_new_cf</a></code></pre></div>
<figcaption>
Listing 49
</figcaption>
</figure>
<figure id="orgd3e28de">
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb50-1" data-line-number="1">logpfn_new_cf <span class="op">=</span> new_tf_function(logpfn_trans_tf, logpfn_cf)</a></code></pre></div>
<figcaption>
Listing 50
</figcaption>
</figure>
<p>The new TF function, <code>logpfn_new_cf</code>, in Listing <a href="#org87b4c38">49</a> is the function we are going to use for sampling from the new log-likelihood.</p>
<figure id="org7bec3c9">
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb51-1" data-line-number="1">_ <span class="op">=</span> logpfn_cf(<span class="op">*</span>init.values()) <span class="op">-</span> logpfn_new_cf(<span class="op">*</span>init.values())</a></code></pre></div>
<figcaption>
Listing 51
</figcaption>
</figure>
<figure>
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb52-1" data-line-number="1">tf.Tensor(<span class="fl">153.41016</span>, shape<span class="op">=</span>(), dtype<span class="op">=</span>float32)</a></code></pre></div>
</figure>
<p>Listing <a href="#org7bec3c9">51</a> shows the difference between a transformed and non-transformed log-likelihood value given the same inputs.</p>
</section>
<section id="sampling-from-the-new-log-likelihood" class="level1">
<h1>Sampling from the new Log-likelihood</h1>
<p>In Listing <a href="#org4a79807">54</a>, we reproduce the remaining steps of <code>pm.inference.sampling.sample</code> and–unnaturally–force the PyMC4 machinery to draw samples from our new transformed log-likelihood function.</p>
<figure>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb53-1" data-line-number="1"><span class="im">from</span> contextlib <span class="im">import</span> contextmanager</a>
<a class="sourceLine" id="cb53-2" data-line-number="2"></a>
<a class="sourceLine" id="cb53-3" data-line-number="3"></a>
<a class="sourceLine" id="cb53-4" data-line-number="4"><span class="co"># We need to create new initial values for our transformed variables.</span></a>
<a class="sourceLine" id="cb53-5" data-line-number="5">new_val_map <span class="op">=</span> {}</a>
<a class="sourceLine" id="cb53-6" data-line-number="6"><span class="cf">for</span> logpfn_remap <span class="kw">in</span> logpfn_remaps:</a>
<a class="sourceLine" id="cb53-7" data-line-number="7">    transed_var <span class="op">=</span> logpfn_remap[<span class="dv">0</span>][<span class="dv">0</span>].reify()</a>
<a class="sourceLine" id="cb53-8" data-line-number="8">    transed_var_pymc_name <span class="op">=</span> tfp_names_to_pymc[transed_var.op.name]</a>
<a class="sourceLine" id="cb53-9" data-line-number="9">    old_val_np <span class="op">=</span> init[transed_var_pymc_name].numpy()</a>
<a class="sourceLine" id="cb53-10" data-line-number="10">    new_val_np <span class="op">=</span> np.random.standard_normal(old_val_np.shape).astype(old_val_np.dtype)</a>
<a class="sourceLine" id="cb53-11" data-line-number="11">    new_val_map[transed_var_pymc_name] <span class="op">=</span> tf.convert_to_tensor(new_val_np)</a>
<a class="sourceLine" id="cb53-12" data-line-number="12"></a>
<a class="sourceLine" id="cb53-13" data-line-number="13">new_init <span class="op">=</span> init.copy()</a>
<a class="sourceLine" id="cb53-14" data-line-number="14">new_init.update(new_val_map)</a>
<a class="sourceLine" id="cb53-15" data-line-number="15"></a>
<a class="sourceLine" id="cb53-16" data-line-number="16"></a>
<a class="sourceLine" id="cb53-17" data-line-number="17"><span class="at">@contextmanager</span></a>
<a class="sourceLine" id="cb53-18" data-line-number="18"><span class="kw">def</span> pymc4_force_logp(logpfn_new_cf, new_init):</a>
<a class="sourceLine" id="cb53-19" data-line-number="19">    <span class="co">&quot;&quot;&quot;Temporarily fix the logp function and init values used by PyMC4&#39;s sampler.&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb53-20" data-line-number="20"></a>
<a class="sourceLine" id="cb53-21" data-line-number="21">    <span class="kw">def</span> _new_build_logp_function(<span class="op">*</span>args, <span class="op">**</span>kwargs):</a>
<a class="sourceLine" id="cb53-22" data-line-number="22">        <span class="kw">nonlocal</span> logpfn_new_cf, new_init</a>
<a class="sourceLine" id="cb53-23" data-line-number="23">        <span class="cf">return</span> logpfn_new_cf, new_init</a>
<a class="sourceLine" id="cb53-24" data-line-number="24"></a>
<a class="sourceLine" id="cb53-25" data-line-number="25">    _old_fn <span class="op">=</span> pm.inference.sampling.build_logp_function</a>
<a class="sourceLine" id="cb53-26" data-line-number="26">    pm.inference.sampling.build_logp_function <span class="op">=</span> _new_build_logp_function</a>
<a class="sourceLine" id="cb53-27" data-line-number="27"></a>
<a class="sourceLine" id="cb53-28" data-line-number="28">    <span class="cf">try</span>:</a>
<a class="sourceLine" id="cb53-29" data-line-number="29">        <span class="cf">yield</span></a>
<a class="sourceLine" id="cb53-30" data-line-number="30">    <span class="cf">finally</span>:</a>
<a class="sourceLine" id="cb53-31" data-line-number="31">        pm.inference.sampling.build_logp_function <span class="op">=</span> _old_fn</a></code></pre></div>
</figure>
<figure id="org4a79807">
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb54-1" data-line-number="1"><span class="cf">with</span> pymc4_force_logp(logpfn_new_cf, new_init):</a>
<a class="sourceLine" id="cb54-2" data-line-number="2">    az_trace <span class="op">=</span> sample(model)</a></code></pre></div>
<figcaption>
Listing 54
</figcaption>
</figure>
<figure id="fig:transformed-model-plot-energy" class="plot">
<img src="https://brandonwillard.github.io/figures/transformed-model-plot-energy.png" alt="" />
<figcaption>
</figcaption>
</figure>
<figure id="fig:transformed-model-plot-trace" class="plot">
<img src="https://brandonwillard.github.io/figures/transformed-model-plot-trace.png" alt="" />
<figcaption>
</figcaption>
</figure>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p>The goals in the two separate <code>run</code> calls we used in Listing <a href="#org0ad3a96">24</a> could have been combined into a single <code>run</code>. This could’ve been accomplished using some “meta” steps (e.g. construct and evaluate a goal on-the-fly within a miniKanren) or special goals for reading from a miniKanren-generated <code>dict</code>s or association lists. Goals of this nature are not uncommon (e.g. type inference and inhabitation exmaples), and serve to demonstrate the great breadth of activity possible within relational context of miniKanren.</p>
<p>However, the point we want to make doesn’t require much sophistication. Instead, we wanted to demonstrate how a non-trivial “pattern” can be specified and matched using <code>symbolic-pymc</code>, and how easily those results could be used to transform a graph.</p>
<p>More specifically, our goal <code>shift_squared_subso</code> in <a href="#org0ad3a96">24</a> demonstrates <strong>the way in which we were able to specify desired structure(s) within a graph</strong>. We defined one pattern, <code>Y_sqrdiffo</code>, to match anywhere in the graph then another pattern, <code>X_sqrdiffo</code>, that relied on matched terms from <code>Y_sqrdiffo</code> and could also be matched/found anywhere else in the same graph.</p>
<p>Furthermore, our substitutions needed information from both “matched” subgraphs. Specifically, substitution pairs similar to <code>(x, z + x)</code>. Within this framework, we could just as easily have included <code>y</code>–or any terms from either successfully matched subgraph–in the substitution expressions.</p>
<p>In sample-space, the search patterns and substitutions are much easier to specify exactly because they’re single-subgraph patterns that themselves are the subgraphs to be replaced (i.e. if we find a non-standard normal, replace it with a shifted/scaled standard normal). In log-space, we chose to find distinct subgraph “chains”, i.e. all <code>(y - x)**2</code> and <code>(x - z)**2</code> pairs (i.e. “connected” by an “unknown” term <code>x</code>), since these are produced by the log-likelihood form of hierarchical normal distributions.</p>
<p>As a result, we had a non-trivial structure/“pattern” to express–and execute. Using conventional graph search-and-replace functionality would’ve required much more orchestration and resulted considerably less flexible code with little-to-no reusability. In our case, the goals <code>onceo</code> and <code>tf_graph_applyo</code> are universal and the forms in <code>shift_squared_subso</code> can be easily changed to account for more sophisticated (or entirely distinct) patterns and substitutions.</p>
<p>Most related graph manipulation offerings make it easy to find a single subgraph that matches a pattern, but not potentially “co-dependent” and/or distinct subgraphs. In the end, the developer will often have to manually implement a “global” state and orchestrate multiple single-subgraph searches and their results.</p>
<p>For single search-and-replace objectives, this amount of manual developer intervention/orchestration might be excusable; however, for objectives requiring the evaluation of multiple graph transformation, this approach is mostly unmaintainable and extremely difficult to compartmentalize.</p>
<p>This demonstration barely even scratches the surface of what’s possible using miniKanren and relational programming for graph manipulation and symbolic statistical model optimization. As the <code>symbolic-pymc</code> project advances, we’ll cover examples in which miniKanren’s more distinct offerings are demonstrated.</p>
</section>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  CommonHTML: { linebreaks: { automatic: true } },
  "HTML-CSS": { linebreaks: { automatic: true } },
  SVG: { linebreaks: { automatic: true } },
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
</body>
</html>

            </div>
            <!-- /.entry-content -->
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'brandonwillard-github-io'; // required: replace example with your forum shortname

                    var disqus_identifier = 'symbolic-pymc-radon-example-in-pymc4';
                var disqus_url = 'https://brandonwillard.github.io/symbolic-pymc-radon-example-in-pymc4.html';

            var disqus_config = function () {
                this.language = "en";
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<div id="aboutme">
        <p>
            <img width="100%" class="img-thumbnail" src="https://brandonwillard.github.io//images/profile-pic.png"/>
        </p>
    <p>
      <strong>About Brandon T. Willard</strong><br/>
        applied math/stats person
    </p>
</div><!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://linkedin.com/pub/brandon-willard/10/bb4/468/"><i class="fa fa-linkedin fa-lg"></i> linkedin</a></li>
    <li class="list-group-item"><a href="https://scholar.google.com/citations?user=g0oUxG4AAAAJ&hl=en"><i class="ai ai-google-scholar ai-lg"></i> google scholar</a></li>
    <li class="list-group-item"><a href="https://plus.google.com/+brandonwillard"><i class="fa fa-google-plus fa-lg"></i> google+</a></li>
    <li class="list-group-item"><a href="https://bitbucket.io/brandonwillard"><i class="fa fa-bitbucket-square fa-lg"></i> bitbucket</a></li>
    <li class="list-group-item"><a href="https://github.com/brandonwillard"><i class="fa fa-github-square fa-lg"></i> github</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<!-- End Content Container -->

<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2019 Brandon T. Willard
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>                <p><small>  <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/deed.en"><img alt="Creative Commons License" style="border-width:0" src="//i.creativecommons.org/l/by-nc/4.0/80x15.png" /></a>
    Content
  licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/deed.en">Creative Commons Attribution-NonCommercial 4.0 International License</a>, except where indicated otherwise.
</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="https://brandonwillard.github.io/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="https://brandonwillard.github.io/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="https://brandonwillard.github.io/theme/js/respond.min.js"></script>


    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'brandonwillard-github-io'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->
    <!-- Google Analytics Universal -->
    <script type="text/javascript">
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-91585967-1', '');
        ga('send', 'pageview');
    </script>
    <!-- End Google Analytics Universal Code -->


</body>
</html>