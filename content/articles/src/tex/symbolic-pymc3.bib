
@book{sympydevelopmentteam_sympy_2014,
  title = {{{SymPy}}: {{Python}} Library for Symbolic Mathematics},
  url = {http://www.sympy.org},
  author = {{SymPy Development Team}},
  year = {2014}
}

@article{srivastava_dropout_2014,
  title = {Dropout: {{A}} Simple Way to Prevent Neural Networks from Overfitting},
  volume = {15},
  shorttitle = {Dropout},
  number = {1},
  urldate = {2015-08-06},
  journal = {The Journal of Machine Learning Research},
  url = {http://dl.acm.org/citation.cfm?id=2670313},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  year = {2014},
  pages = {1929--1958}
}

@article{bauschke_symbolic_2006,
  title = {Symbolic Computation of {{Fenchel}} Conjugates},
  volume = {40},
  issn = {19322240},
  doi = {10.1145/1151446.1151453},
  number = {1},
  journal = {ACM Communications in Computer Algebra},
  author = {Bauschke, Heinz H. and Mohrenschildt, Martin V.},
  year = {2006},
  pages = {18}
}

@inproceedings{KucukelbirAutomaticvariationalinference2015,
  title = {Automatic Variational Inference in {{Stan}}},
  urldate = {2016-09-03},
  booktitle = {Advances in Neural Information Processing Systems},
  url = {http://papers.nips.cc/paper/5758-automatic-variational-inference-in-stan},
  author = {Kucukelbir, Alp and Ranganath, Rajesh and Gelman, Andrew and Blei, David},
  year = {2015},
  pages = {568--576}
}

@article{Wangmechanicalmathematics1960,
  title = {Toward Mechanical Mathematics},
  volume = {4},
  number = {1},
  urldate = {2016-10-18},
  journal = {IBM Journal of research and development},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5392526},
  author = {Wang, Hao},
  year = {1960},
  pages = {2--22}
}

@article{TranDeepProbabilisticProgramming2016,
  title = {Deep {{Probabilistic Programming}}},
  urldate = {2017-01-17},
  url = {http://bayesiandeeplearning.org/papers/BDL_43.pdf},
  author = {Tran, Dustin and Hoffman, Matt and Murphy, Kevin and Brevdo, Eugene and Saurous, Rif A. and Blei, David M.},
  year = {2016}
}

@article{parikh_proximal_2014,
  title = {Proximal {{Algorithms}}},
  volume = {1},
  issn = {2167-3888},
  doi = {10.1561/2400000003},
  number = {3},
  journal = {Foundations and Trends in Optimization},
  author = {Parikh, Neal and Boyd, Stephen},
  year = {2014},
  keywords = {shrinkage,sparsity},
  pages = {123-231}
}

@article{PedregosaScikitlearnMachineLearning2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  volume = {12},
  journal = {Journal of Machine Learning Research},
  author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  year = {2011},
  pages = {2825-2830}
}

@inproceedings{WoodNewApproachProbabilistic2014,
  title = {A {{New Approach}} to {{Probabilistic Programming Inference}}.},
  urldate = {2016-09-03},
  booktitle = {{{AISTATS}}},
  url = {http://www.jmlr.org/proceedings/papers/v33/wood14.pdf},
  author = {Wood, Frank and {van de Meent}, Jan-Willem and Mansinghka, Vikash},
  year = {2014},
  pages = {1024--1032}
}

@inproceedings{PaigeCompilationTargetProbabilistic2014,
  title = {A {{Compilation Target}} for {{Probabilistic Programming Languages}}.},
  urldate = {2016-09-03},
  booktitle = {{{ICML}}},
  url = {http://www.jmlr.org/proceedings/papers/v32/paige14.pdf},
  author = {Paige, Brooks and Wood, Frank},
  year = {2014},
  pages = {1935--1943}
}

@article{PolsonStatisticalTheoryDeep2015,
  title = {A {{Statistical Theory}} of {{Deep Learning}} via {{Proximal Splitting}}},
  urldate = {2016-09-06},
  journal = {arXiv preprint arXiv:1509.06061},
  url = {http://arxiv.org/abs/1509.06061},
  author = {Polson, Nicholas G. and Willard, Brandon T. and Heidari, Massoud},
  year = {2015}
}

@article{LucetWhatshapeyour2010,
  title = {What Shape Is Your Conjugate? {{A}} Survey of Computational Convex Analysis and Its Applications},
  volume = {52},
  shorttitle = {What Shape Is Your Conjugate?},
  number = {3},
  urldate = {2017-02-25},
  journal = {SIAM review},
  url = {http://epubs.siam.org/doi/abs/10.1137/100788458},
  author = {Lucet, Yves},
  year = {2010},
  pages = {505--542}
}

@article{scott_parameter_2010,
  title = {Parameter expansion in local-shrinkage models},
  urldate = {2015-06-13},
  journal = {arXiv preprint arXiv:1010.5265},
  url = {http://arxiv.org/abs/1010.5265},
  author = {Scott, James G.},
  year = {2010},
  keywords = {MCMC,Normal scale mixtures,parameter expansion,sparsity}
}

@article{MohaselAfsharProbabilisticInferencePiecewise2016,
  title = {Probabilistic {{Inference}} in {{Piecewise Graphical Models}}},
  copyright = {http://legaloffice.weblogs.anu.edu.au/content/copyright/},
  abstract = {In many applications of probabilistic inference the models
    contain piecewise densities that are differentiable except at
    partition boundaries. For instance, (1) some models may
    intrinsically have finite support, being constrained to some
    regions; (2) arbitrary density functions may be approximated by
    mixtures of piecewise functions such as piecewise polynomials or
    piecewise exponentials; (3) distributions derived from other
    distributions (via random variable transformations) may be highly
    piecewise; (4) in applications of Bayesian inference such as
    Bayesian discrete classification and preference learning, the
    likelihood functions may be piecewise; (5) context-specific
    conditional probability density functions (tree-CPDs) are
    intrinsically piecewise; (6) influence diagrams (generalizations
    of Bayesian networks in which along with probabilistic inference,
    decision making problems are modeled) are in many applications
    piecewise; (7) in probabilistic programming, conditional
    statements lead to piecewise models. As we will show, exact
    inference on piecewise models is not often scalable (if
    applicable) and the performance of the existing approximate
    inference techniques on such models is usually quite poor.
    This thesis fills this gap by presenting scalable and accurate
    algorithms for inference in piecewise probabilistic graphical
    models. Our first contribution is to present a variation of Gibbs
    sampling algorithm that achieves an exponential sampling speedup
    on a large class of models (including Bayesian models with
    piecewise likelihood functions). As a second contribution, we
    show that for a large range of models, the time-consuming Gibbs
    sampling computations that are traditionally carried out per
    sample, can be computed symbolically, once and prior to the
    sampling process. Among many potential applications, the
    resulting symbolic Gibbs sampler can be used for fully automated
    reasoning in the presence of deterministic constraints among
    random variables. As a third contribution, we are motivated by
    the behavior of Hamiltonian dynamics in optics \textemdash{}in particular,
    the reflection and refraction of light on the refractive
    surfaces\textemdash{} to present a new Hamiltonian Monte Carlo method that
    demonstrates a significantly improved performance on piecewise
    models.
    Hopefully, the present work represents a step towards scalable
    and accurate inference in an important class of probabilistic
    models that has largely been overlooked in the literature.},
  language = {en},
  urldate = {2016-09-03},
  url = {https://digitalcollections.anu.edu.au/handle/1885/107386},
  author = {Mohasel Afshar, Hadi},
  year = {2016},
  keywords = {binary trees,gibbs sampling}
}

@phdthesis{RocklinMathematicallyinformedlinear2013,
  title = {Mathematically Informed Linear Algebra Codes through Term Rewriting},
  urldate = {2016-09-20},
  school = {PhD Thesis, August},
  url = {http://people.cs.uchicago.edu/~mrocklin/storage/dissertation.pdf},
  author = {Rocklin, Matthew},
  year = {2013}
}

@article{peasgood_method_2009,
  title = {A {{Method}} to {{Symbolically Compute Convolution Integrals}}},
  urldate = {2016-01-20},
  url = {https://uwspace.uwaterloo.ca/handle/10012/4884},
  author = {Peasgood, Richard},
  year = {2009}
}

@article{SalvatierProbabilisticprogrammingPython2016,
  title = {Probabilistic Programming in {{Python}} Using {{PyMC3}}},
  volume = {2},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.55},
  language = {en},
  urldate = {2016-04-28},
  journal = {PeerJ Computer Science},
  url = {https://peerj.com/articles/cs-55},
  author = {Salvatier, John and Wiecki, Thomas V. and Fonnesbeck, Christopher},
  month = apr,
  year = {2016},
  pages = {e55}
}

@phdthesis{RoyComputabilityinferencemodeling2011,
  title = {Computability, Inference and Modeling in Probabilistic Programming},
  urldate = {2017-01-17},
  school = {Massachusetts Institute of Technology},
  url = {https://pdfs.semanticscholar.org/2ace/2f8090cb5dcb5a629937771dfb7a312adb33.pdf},
  author = {Roy, Daniel M.},
  year = {2011}
}

@article{LukasiewiczProbabilisticlogicprogramming2001,
  title = {Probabilistic Logic Programming with Conditional Constraints},
  volume = {2},
  number = {3},
  urldate = {2017-01-17},
  journal = {ACM Transactions on Computational Logic (TOCL)},
  url = {http://dl.acm.org/citation.cfm?id=377983},
  author = {Lukasiewicz, Thomas},
  year = {2001},
  pages = {289--339}
}

@article{carvalho_horseshoe_2010,
  title = {The Horseshoe Estimator for Sparse Signals},
  volume = {97},
  issn = {00063444},
  doi = {10.1093/biomet/asq017},
  number = {2},
  journal = {Biometrika},
  author = {Carvalho, Carlos M. and Polson, Nicholas G. and Scott, James G.},
  year = {2010},
  keywords = {Normal scale mixture,Ridge regression,Robustness,Thresholding,shrinkage,sparsity},
  pages = {465-480},
  pmid = {20882103}
}

@inproceedings{ScibiorPracticalprobabilisticprogramming2015,
  title = {Practical Probabilistic Programming with Monads},
  volume = {50},
  urldate = {2016-09-03},
  booktitle = {{{ACM SIGPLAN Notices}}},
  publisher = {{ACM}},
  url = {http://dl.acm.org/citation.cfm?id=2804317},
  author = {\'Scibior, Adam and Ghahramani, Zoubin and Gordon, Andrew D.},
  year = {2015},
  pages = {165--176}
}

@article{polson_proximal_2015,
  title = {Proximal Algorithms in Statistics and Machine Learning},
  volume = {30},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/15-STS530},
  abstract = {Proximal algorithms are useful for obtaining solutions to difficult optimization problems, especially those involving nonsmooth or composite objective functions. A proximal algorithm is one whose basic iterations involve the proximal operator of some function, whose evaluation requires solving a specific optimization problem that is typically easier than the original problem. Many familiar algorithms can be cast in this form, and this “proximal view” turns out to provide a set of broad organizing principles for many algorithms useful in statistics and machine learning. In this paper, we show how a number of recent advances in this area can inform modern statistical practice. We focus on several main themes: (1) variable splitting strategies and the augmented Lagrangian; (2) the broad utility of envelope (or variational) representations of objective functions; (3) proximal algorithms for composite objective functions; and (4) the surprisingly large number of functions for which there are closed-form solutions of proximal operators. We illustrate our methodology with regularized Logistic and Poisson regression incorporating a nonconvex bridge penalty and a fused lasso penalty. We also discuss several related issues, including the convergence of nondescent algorithms, acceleration and optimization for nonconvex functions. Finally, we provide directions for future research in this exciting area at the intersection of statistics and optimization.},
  language = {EN},
  number = {4},
  urldate = {2015-12-14},
  journal = {Statistical Science},
  url = {http://projecteuclid.org/euclid.ss/1449670858},
  author = {Polson, Nicholas G. and Scott, James G. and Willard, Brandon T.},
  month = nov,
  year = {2015},
  keywords = {\#duplicates,ADMM,bayes MAP,Bayes MAP,divide and concur,Divide and Concur,envelopes,fused lasso,KL,Kurdyka–Łojasiewicz,non-convex optimisation,nonconvex,optimization,Optimization,proximal,proximal operators,regularization,Regularization,shrinkage,sparsity,splitting},
  pages = {559-581}
}

@article{combettes_proximal_2011,
  title = {Proximal Splitting Methods in Signal Processing},
  journal = {Fixed-point algorithms for inverse problems in science and engineering},
  author = {Combettes, Patrick L and Pesquet, Jean-Christophe},
  year = {2011},
  keywords = {Iterative thresholding,alternating-direction method of multipliers,backward-backward algorithm,convex optimization,denoising,douglas-rachford algorithm,forward-backward algorithm,landweber method,parallel computing,proximal algorithm,restoration and reconstruction,sparsity,splitting},
  pages = {185--212}
}

@misc{Willardbrandonwillardtheanosympy,
  title = {Brandonwillard/Theano\_sympy},
  abstract = {theano\_sympy - Function to transform theano graph {$<$}-{$>$} sympy graph.},
  urldate = {2017-01-20},
  journal = {GitHub},
  url = {https://github.com/brandonwillard/theano_sympy},
  author = {Willard, Brandon}
}

@article{Parkbayesianlasso2008,
  title = {The bayesian lasso},
  volume = {103},
  number = {482},
  urldate = {2017-01-17},
  journal = {Journal of the American Statistical Association},
  url = {http://amstat.tandfonline.com/doi/abs/10.1198/016214508000000337},
  author = {Park, Trevor and Casella, George},
  year = {2008},
  pages = {681–686}
}

@misc{WillardRoleSymbolicComputation2017,
  title = {A {{Role}} for {{Symbolic Computation}} in the {{General Estimation}} of {{Statistical Models}}},
  abstract = {A Role for Symbolic Computation in the General Estimation of Statistical Models code\{white-space: pre;\} div.sourceCode \{ overflow-x: auto; \} table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode \{ margin: 0; padding: 0; vertical-align: baseline; border: none; \} table.sourceCode \{ width: 100\%; line-height: 100\%; \} td.lineNumbers \{ text-align: right; padding-right: 4px; padding-left: 4px; background-color ...\vphantom\}},
  urldate = {2017-02-11},
  journal = {Brandon T. Willard},
  url = {https://brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html},
  author = {Willard, Brandon T.},
  month = jan,
  year = {2017}
}

@phdthesis{HamiltonSymbolicconvexanalysis2005,
  title = {Symbolic Convex Analysis},
  urldate = {2017-02-25},
  school = {Simon Fraser University},
  url = {http://docserver.carma.newcastle.edu.au/id/eprint/296},
  author = {Hamilton, Chris H.},
  year = {2005}
}

@article{donoho2006compressed,
  title = {Compressed Sensing},
  volume = {52},
  number = {4},
  journal = {IEEE Transactions on information theory},
  author = {Donoho, David L},
  year = {2006},
  pages = {1289-1306}
}

@misc{RocklinlogpyLogicProgramming2018,
  title = {Logpy: {{Logic Programming}} in {{Python}}},
  copyright = {BSD-3-Clause},
  shorttitle = {Logpy},
  urldate = {2018-01-07},
  url = {https://github.com/logpy/logpy},
  author = {Rocklin, Matthew},
  month = jan,
  year = {2018}
}

@misc{ByrdminiKanrenorg2019,
  title = {{{miniKanren}}.Org},
  urldate = {2018-01-08},
  url = {http://minikanren.org/},
  author = {Byrd, William},
  year = {2019}
}

@article{ByrdaKanrenFreshName2007,
  title = {{{$\alpha$Kanren A Fresh Name}} in {{Nominal Logic Programming}}},
  author = {Byrd, William E. and Friedman, Daniel P.},
  year = {2007}
}

@phdthesis{ByrdRelationalProgrammingminiKanren2009,
  title = {Relational {{Programming}} in {{miniKanren}}: {{Techniques}}, {{Applications}}, and {{Implementations}}},
  shorttitle = {Relational {{Programming}} in {{miniKanren}}},
  school = {faculty of the University Graduate School in partial fulfillment of the requirements for the degree Doctor of Philosophy in the Department of Computer Science, Indiana University},
  author = {Byrd, William E.},
  year = {2009}
}

@techreport{CaretteSimplifyingProbabilisticPrograms2016,
  title = {Simplifying {{Probabilistic Programs Using Computer Algebra}}},
  number = {TR719},
  urldate = {2018-01-16},
  institution = {{Indiana University}},
  url = {https://www.cs.indiana.edu/cgi-bin/techreports/TRNNN.cgi?trnum=TR719},
  author = {Carette, Jacques and Shan, Chung-chieh},
  year = {2016},
  keywords = {Holonomic functions,Probability Theory,Symbolic and Algebraic Manipulation,integral transforms,measure theory}
}

@misc{WillardSymbolicMathPyMC32018,
  title = {Symbolic {{Math}} in {{PyMC3}}},
  urldate = {2018-12-27},
  url = {https://brandonwillard.github.io/symbolic-math-in-pymc3.html},
  author = {Willard, Brandon T.},
  month = dec,
  year = {2018}
}

@misc{WillardRandomVariablesTheano2018,
  title = {Random {{Variables}} in {{Theano}}},
  language = {en},
  urldate = {2019-01-16},
  url = {https://brandonwillard.github.io/random-variables-in-theano.html},
  author = {Willard, Brandon T.},
  month = dec,
  year = {2018}
}

@misc{WillardReadableStringsRelational2018a,
  title = {Readable {{Strings}} and {{Relational Programming}} in {{Hy}}},
  language = {en},
  urldate = {2019-01-22},
  journal = {Brandon T. Willard},
  url = {https://brandonwillard.github.io/readable-strings-and-relational-programming-in-hy.html},
  author = {Willard, Brandon T. and Willard, Brandon T.},
  month = dec,
  year = {2018}
}

@misc{RocklinMultipledispatchContribute2019,
  title = {Multiple Dispatch. {{Contribute}} to Mrocklin/Multipledispatch Development by Creating an Account on {{GitHub}}},
  copyright = {View license},
  urldate = {2019-01-22},
  url = {https://github.com/mrocklin/multipledispatch},
  author = {Rocklin, Matthew},
  month = jan,
  year = {2019}
}

@article{ZhangTraceclassMarkov2019,
  title = {Trace Class {{Markov}} Chains for the {{Normal}}-{{Gamma Bayesian}} Shrinkage Model},
  volume = {13},
  issn = {1935-7524},
  doi = {10.1214/18-EJS1491},
  abstract = {High-dimensional data, where the number of variables exceeds or is comparable to the sample size, is now pervasive in many scientific applications. In recent years, Bayesian shrinkage models have been developed as effective and computationally feasible tools to analyze such data, especially in the context of linear regression. In this paper, we focus on the Normal-Gamma shrinkage model developed by Griffin and Brown [7]. This model subsumes the popular Bayesian lasso model, and a three-block Gibbs sampling algorithm to sample from the resulting intractable posterior distribution has been developed in [7]. We consider an alternative two-block Gibbs sampling algorithm, and rigorously demonstrate its advantage over the three-block sampler by comparing specific spectral properties. In particular, we show that the Markov operator corresponding to the two-block sampler is trace class (and hence Hilbert-Schmidt), whereas the operator corresponding to the three-block sampler is not even Hilbert-Schmidt. The trace class property for the two-block sampler implies geometric convergence for the associated Markov chain, which justifies the use of Markov chain CLT's to obtain practical error bounds for MCMC based estimates. Additionally, it facilitates theoretical comparisons of the two-block sampler with sandwich algorithms which aim to improve performance by inserting inexpensive extra steps in between the two conditional draws of the two-block sampler.},
  language = {EN},
  number = {1},
  urldate = {2019-01-22},
  journal = {Electronic Journal of Statistics},
  url = {https://projecteuclid.org/euclid.ejs/1547607848},
  author = {Zhang, Liyuan and Khare, Kshitij and Xing, Zeren},
  year = {2019},
  keywords = {Markov chain Monte Carlo,Bayesian shrinakge,Data Augmentation,normal-Gamma model,trace class operators},
  pages = {166-207}
}

@misc{GelmanTransformingparameterssimple2019,
  title = {Transforming Parameters in a Simple Time-Series Model; Debugging the {{Jacobian}} \guillemotleft{} {{Statistical Modeling}}, {{Causal Inference}}, and {{Social Science}}},
  urldate = {2019-01-28},
  url = {https://statmodeling.stat.columbia.edu/2019/01/25/transforming-parameters-in-a-simple-time-series-model-debugging-the-jacobian/},
  author = {Gelman, Andrew},
  month = jan,
  year = {2019}
}


