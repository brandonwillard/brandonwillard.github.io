\documentclass[12pt]{article}
\usepackage{setspace}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{suffix}
\usepackage{color}

% Sadly, can't use this because it breaks greek letters.
%\usepackage[slantedGreek]{mathpazo}
\usepackage{breqn}

\usepackage{todonotes}
\usepackage{draftwatermark}
\SetWatermarkScale{1}
\SetWatermarkLightness{0.90}

% used by Pweave
\usepackage{graphicx}

\definecolor{bg}{rgb}{0.95,0.95,0.95}
\usepackage[backgroundcolor=bg, topline=false, bottomline=false, leftline=false, rightline=false]{mdframed}

<<pweave_code, echo=False, evaluate=False>>=
from pynoweb_tools.editor_utils import nvim_weave

input_file_base = nvim_weave(rel_figdir='../figures',
                             rel_outdir="./",
                             format_opts={'width': r'\textwidth',
                                          'figfmt': '.png',
                                          'savedformats': ['.png', '.pdf']})

# Compile document to markdown
assert os.system('make {}.pdf'.format(input_file_base)) == 0
assert os.system('make {}.md'.format(input_file_base)) == 0
@

\usepackage{minted}
\setminted{fontsize=\footnotesize, breaklines=true, breakanywhere=true,
breakautoindent=true}

% this order is important
%\PassOptionsToPackage{hyphens}{url}
\RequirePackage[hyphens]{url}
\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage[authoryear]{natbib}

% Apparently cleveref must always be last.
\usepackage{cleveref}

\allowdisplaybreaks

\include{math-commands}

\graphicspath{{../../figures/}{../figures/}{./figures/}{./}}

\title{A Role for Symbolic Computation in the General Estimation of Statistical Models}

\author{Brandon T. Willard}

\date{2017-01-18}

\begin{document}

\maketitle

\section{Introduction}

In this document we describe how symbolic computation can be used to provide
generalizable statistical estimation through a combination of existing open source
frameworks.  Specifically, we will show how symbolic tools can be used to
address the estimation of non-smooth functions that appear in models with parameter
regularization, shrinkage and sparsity.  We employ a mathematical framework
that makes extensive use of \emph{proximal operators}
\citep{parikh_proximal_2014, combettes_proximal_2011} and their properties for
maximum a posteriori (MAP) estimation: i.e. the \emph{proximal framework}.
This framework produces what we'll call \emph{proximal methods} and their
implementations as \emph{proximal algorithms}.

In \citet{polson_proximal_2015} we outlined a set of seemingly
disparate optimization techniques within the fields of statistics, computer
vision, and machine learning (e.g. gradient descent, ADMM, EM,
Douglas-Rachford) that are unified by their various applications of proximal
methods.  These methods--and the concepts behind them--have found much success
in recent times and admit quite a few interesting paths for research.  In other
words, there are many reasons to alone discuss the implementation of proximal
methods.

Proximal operators also enjoy a breadth of closed-form solutions and useful
properties that are amenable to symbolic computation.
In more than a few cases, the work required to produce a proximal algorithm
overlaps with well-established features of computer algebra systems and
symbolic mathematics, such as symbolic differentiation and
algebraic equation solving.

Symbolic integration provides an excellent example of how proximal operators
could be implemented in a symbolic system.  In these systems, mappings between
functions (as canonicalized graphs) and their generalized hypergeometric
equivalents are used to exploit the latter's relevant convolution identities.
In the same vein, it is possible to use tables of closed-form proximal
operators and their properties to produce a wide array of estimation algorithms
for many non-smooth functions.  We outline how this might be done in the
following sections.

Otherwise, the ideas discussed here are part of a never-ending attempt to
answer a question that arises naturally in both mathematics and programming--at
all levels: \emph{How does one provide a means of generating robust solutions
to as many problems as possible?}
Instead of the common attempt to independently implement each model, method
and/or combination of the two--followed by their placement in an API or
collection of functions--implementations can be encoded in and organized by the
very mathematics from which they were derived.  This close coupling between
mathematical principles and their implementations is possibly the most
reasonable way to remove barriers between theory, research and practice.

% Also, it is one of the few practical means of including the higher and lower level
% considerations made by professionals at all stages of statistical modeling: mathematical,
% numerical, computational (e.g. distributed environments, concurrency, etc.)
% Some steps toward these broader goals are within reach and worth taking now.

\subsection{A Context}

Much recent work in statistical modeling and estimation has revolved around the
desire for sparsity, regularization and efficient [automatic] model selection.
This is, in some sense, an objective shared with the more specialized areas of
Deep Learning and Compressed Sensing.  In the former case, we can point to
Dropout \citep{srivastava_dropout_2014} and, in the latter, $\ell_p$
regularization \citep{donoho_compressed_2006}.

Without delving into those topics here, we'll simply assume that a practitioner
intends to produce a sparse estimate for a model that results in LASSO.
First, some setup:
<<evaluate=True, echo=True>>=
import numpy as np
import scipy as sc

import pymc3 as pm
import theano
import theano.tensor as tt

theano.config.mode = 'FAST_COMPILE'
@

Using PyMC3, the Bayes version of the LASSO \citep{park_bayesian_2008} model is
easily specified.
<<evaluate=True, echo=True>>=
from theano import shared as tt_shared

mu_true = np.zeros(100)
mu_true[:20] = np.exp(-np.arange(20)) * 100

X = np.random.randn(int(np.alen(mu_true) * 0.7), np.alen(mu_true))
y = sc.stats.norm.rvs(loc=X.dot(mu_true), scale=10)

X_tt = tt_shared(X, name='X', borrow=True)
y_tt = tt_shared(y, name='y', borrow=True)

with pm.Model() as lasso_model:
    # Would be nice if we could pass the symbolic y_tt.shape, so
    # that our model would automatically conform to changes in
    # the shared variables X_tt.
    # See https://github.com/pymc-devs/pymc3/pull/1125
    beta_rv = pm.Laplace('beta', mu=0, b=1, shape=X.shape[1])
    y_rv = pm.Normal('y', mu=X_tt.dot(beta_rv), sd=1,
                     shape=y.shape[0], observed=y_tt)
@

The negative total log likelihood in our example problem has a non-smooth
$\ell_1$ term.  The standard means of estimating a [MAP] solution to this problem
usually involves the soft-thresholding operator, which is a type of proximal
operator.  This operator is cheap to compute, so that--among other things--makes
the proximal approaches that use it quite appealing.

% Let's illustrate exactly how a symbolic context, like the one
% provided by PyMC3 and Theano, provides a means of adding an otherwise inaccessible
% automatic ``awareness'' to a function like \texttt{find\_MAP}.

Moving on, let's say we wanted to produce a MAP estimate in this PyMC3 context.
A function is already provided for this generic task: \texttt{find\_MAP}.
<<echo=True, evaluate=False>>=
with lasso_model:
    params_0 = pm.find_MAP(vars=[beta_rv])
@
In our run of the above, an exception is thrown due to the \texttt{nan} values
that arise within the gradient evaluation.

More directly, we can inspect the gradient at $\beta = 0, 1$ to demonstrate the
same.
<<find_MAP_gradient, echo=True, evaluate=True>>=
start = pm.Point({'beta': np.zeros(X.shape[1])}, model=lasso_model)
bij = pm.DictToArrayBijection(pm.ArrayOrdering(lasso_model.vars), start)
logp = bij.mapf(lasso_model.fastlogp)
dlogp = bij.mapf(lasso_model.fastdlogp(lasso_model.vars))

# Could also inspect the log likelihood of the prior:
# beta_rv.dlogp().f(np.zeros_like(start['beta']))

grad_at_0 = dlogp(np.zeros_like(start['beta']))
grad_at_1 = dlogp(np.ones_like(start['beta']))
@
<<term=True>>=
print(np.sum(np.isnan(grad_at_0)))
print(np.sum(np.isnan(grad_at_1)))
@

\section{The Proximal Context}

We start with the essential ingredient: the proximal operator.
\begin{Def}[Proximal Operator]
  \begin{equation}
    \prox_{\phi}(x) =
    \argmin_{z} \left\{
    \frac{1}{2} \left(z - x\right)^2 + \phi(z)
    \right\}
    \;.
  \end{equation}
\end{Def}

As we mentioned earlier, the proximal operator is the main tool of proximal
algorithms.  Exact solutions to proximal operators exist for many $\phi$.
These are the elements that could exist in a table, many entries of which could
be generated automatically, in analogy to symbolic integration.

Consider the MAP estimation of a penalized likelihood, i.e.
\begin{equation}
  \beta^* = \argmin_\beta \left\{ l(\beta) + \gamma \phi(\beta) \right\}
  \;,
  \label{eq:prox_problem}
\end{equation}
where functions $l$ and $\phi$ are commonly referred to as likelihood and prior terms
(or loss and penalty), respectively.
The proximal framework usually assumes $l$ and $\phi$ are at least lower
semi-continuous and convex--although quite a few useful results still hold for
non-convex functions.

Notice that \Cref{eq:prox_problem} takes the form of a proximal operator when
$l(\beta) = \frac{1}{2} (y - \beta)^2$.  In regression problems, we
have $l(\beta) = \frac{1}{2} \|y - X \beta\|^2$.  Properties of the proximal
operator are then used to produce a independent proximal operators in each
component of $\beta$.  Since more than one property of the proximal operator can
accomplish this, we can see one reason for their breadth.


The proximal operator relevant to our example, $\prox_{|\cdot|}$, is
equivalent to the soft-thresholding operator.
We can implement it in Theano with something like the following:
<<soft_thresholding, echo=True, evaluate=True>>=
beta_tt = tt.vector('beta', dtype=tt.config.floatX)
beta_tt.tag.test_value = np.r_[-10, -1, -0.2, 0, 0.2, 1, 10].astype(tt.config.floatX)

lambda_tt = tt.scalar('lambda', dtype=tt.config.floatX)
lambda_tt.tag.test_value = np.array(0.5).astype(tt.config.floatX)

def soft_threshold(beta_, lambda_):
    return tt.sgn(beta_) * tt.maximum(tt.abs_(beta_) - lambda_, 0)
@
<<term=True>>=
print(soft_threshold(beta_tt, lambda_tt).tag.test_value)
@
Operators like these can be composed with a gradient step to produce a
\emph{proximal gradient} algorithm:
\begin{equation}
  \beta = \prox_{\alpha \lambda \phi}(\beta - \alpha \nabla l(\beta))
  \;.
  \label{eq:forward-backward}
\end{equation}


Besides the proximal operator for $\phi$, the steps in a proximal gradient
algorithm are very straightforward and rely primarily on the gradient of
$l(\beta)$.  When considering this quantity, a tangible benefit of symbolic
computation becomes apparent; complicated gradients can be computed
automatically and efficiently.  With [backtracking] line search to handle
unknown step sizes, the proximal gradient alone provides a surprisingly general
means of sparse estimation.

Here is an implementation of a proximal gradient step:
<<prox_gradient_setup, echo=True, evaluate=True>>=
from theano import function as tt_function

def prox_grad_step(logl, beta_tt, lambda_1_tt, gamma_prox_tt,
                   prox_func=soft_threshold):
    # Negative log-likelihood without non-smooth (\ell_1) term:
    logl_grad = tt.grad(logl, wrt=beta_tt)
    logl_grad.name = "logl_grad"

    from theano.compile.nanguardmode import NanGuardMode
    tt_func_mode = NanGuardMode(nan_is_error=True,
                                inf_is_error=False,
                                big_is_error=False)

    beta_var_tt = tt.vector(name='beta', dtype=beta_tt.dtype)
    beta_var_tt.tag.test_value = beta_tt.get_value()
    grad_step = tt_function([beta_var_tt], logl_grad,
                            mode=tt_func_mode,
                            givens={beta_tt: beta_var_tt})

    beta_quad_step = beta_tt - lambda_1_tt * logl_grad
    beta_quad_step.name = "beta_quad_step"

    beta_prox = prox_func(beta_quad_step, gamma_prox_tt * lambda_1_tt)
    beta_prox.name = "beta_prox"

    r_tt = y_tt - X_tt.dot(beta_tt)

    prox_step = tt_function([],
                            [beta_prox, logl, logl_grad, tt.mean(r_tt**2)],
                            updates=[(beta_tt, beta_prox)],
                            mode=tt_func_mode)

    return (prox_step, grad_step)
@

\section{The Symbolic Operations}

In order to employ a lookup table, or to even identify a proximal problem and
check that its conditions (e.g. convexity) are satisfied, we need to obtain the
exact forms of each component: $l$, $\phi$ and $\gamma$.
We start with the determination of $l$ and $\phi$.

In some cases, we're able to tease apart our $l(\beta)$ and $\phi(\beta)$ using
the symbolic log likelihoods for the organizational designations of
\emph{observed} and unobserved PyMC3 random variables.
<<evaluate=False, echo=True>>=
from theano import clone as tt_clone

logl = tt_clone(lasso_model.observed_RVs[0].logpt,
                {beta_rv: beta_tt})
logl.name = "logl"
@
Instead, let's assume we're extending \texttt{find\_MAP} with some generality,
so that distinguishing $l$ and $\phi$ in \Cref{eq:prox_problem} using these
designations isn't reliable.  This is necessary for cases in which a user
specifies custom distributions or a potential function.  In either case, to
achieve our desired functionality we need to operate at a more symbolic level.

\begin{remark}
  At this point, it is extremely worthwhile to browse the
  \href{http://deeplearning.net/software/theano/extending/graphstructures.html}{Theano documentation}
  regarding graphs and their constituent objects.
\end{remark}

The total log likelihood is a good place to start.  Let's
look at symbolic graphs produced by ours.
<<evaluate=True, echo=True>>=
from theano import pp as tt_pp
from theano import pprint as tt_pprint
@
<<term=True>>=
print(tt_pp(lasso_model.logpt))
@
The \href{http://deeplearning.net/software/theano/tutorial/printing_drawing.html#pretty-printing}{pretty printed}
Theano graph tells us, among other things, that we have the anticipated sum of
$\ell_2$ and $\ell_1$ terms.

As with most graphs produced by symbolic algebra systems, we need to consider
exactly how its operations are arranged, so that we can develop a means of
matching general structures.
The \href{http://deeplearning.net/software/theano/tutorial/printing_drawing.html#debug-print}{debug printout}
is better for this.
<<evaluate=True, echo=True, term=True>>=
tt.printing.debugprint(lasso_model.logpt)
@
We see that the top-most operator is an \texttt{Elemwise} that applies
the scalar \texttt{add} operation.  This is the $+$ in $l(\beta) + \phi(\beta)$.
If we were to consider the inputs to this operator as our candidates for
$l$ and $\phi$, then we might find this pair with the following:
<<evaluate=True, echo=True, term=True>>=
print(lasso_model.logpt.owner.inputs)
@
Using these two terms, we might simply search for an absolute value operator.
<<evaluate=True, echo=True>>=
def get_abs_between(input_node):
    # Get all the operations in the sub-tree between our input and the
    # log likelihood output node.
    term_ops = list(tt.gof.graph.ops([input_node], [lasso_model.logpt]))

    # Is there an absolute value in there?
    return filter(lambda x: x.op is tt.abs_, term_ops)

abs_res = [(get_abs_between(in_), in_)
           for in_ in lasso_model.logpt.owner.inputs]

for r_ in abs_res:
    if len(r_[0]) == 0:
        phi = r_[1]
    else:
        logp = r_[1]
@
<<term=True>>=
tt.printing.debugprint(logp)
tt.printing.debugprint(phi)
@
From these terms one can similarly attempt to determine multiplicative constants, or
parts thereof (e.g. $\gamma$).

The above approach is too limiting; we need something more robust.  The above
logic will fail on
graphs that are constructed differently (e.g. producing equivalent, but different,
representations via associativity) or when our naive use of \texttt{theano.gof.graph.ops} is
compromised by certain types of intermediate operations (e.g. non-distributed,
non-affine).  These are only a few of the many weaknesses inherent to the naive
approach above.  Furthermore, sufficient coverage of all the necessary conditions--using
the same approach--is likely to result in complicated, less approachable code.

What we need to identify the more general patterns suitable for our
goal is mostly covered within the areas of graph unification and logic programming.
Luckily, Theano has some basic unification capabilities that we're able to deploy
immediately via \texttt{PatternSub}.

\texttt{PatternSub} works within the context of Theano
\href{http://deeplearning.net/software/theano/optimizations.html}{graph
optimization}.  Graph optimizations essentially perform the common symbolic
operations of simplification, reduction and rewriting.  Consider the
\texttt{phi} variable; the printouts show an unnecessary subtraction (with
$0$).  Clearly this step is unnecessary, so--in a basic way--we can see
that the graph hasn't been simplified, yet.

Many standard algebraic simplifications are already present in Theano, and, by
creating graph optimizations, we can provide ones that assist with
our identification of $l$ and $\phi$, or closed-form solutions to proximal
operators.

\begin{Exa}[Algebraic Graph Optimization]

To demonstrate the kind of operations that could be used to pre-condition a
graph and robustly determine a set of supported $l$ and $\phi$, we'll make
replacement patterns for multiplicative distribution across two forms of
addition: \texttt{sum} and \texttt{add}.
<<evaluate=True, echo=True>>=
test_a_tt = tt.as_tensor_variable(5, name='a')
test_b_tt = tt.as_tensor_variable(2, name='b')
test_c_tt = tt.as_tensor_variable(np.r_[1, 2], name='c')

test_exprs_tt = (test_a_tt * test_b_tt,)
test_exprs_tt += (test_a_tt * (test_b_tt + test_a_tt),)
test_exprs_tt += (test_a_tt * (test_c_tt + test_a_tt),)
test_exprs_tt += (test_a_tt * (test_c_tt + test_c_tt),)

mul_dist_pat_tt = (tt.gof.opt.PatternSub(
    (tt.mul, 'x', (tt.sum, 'y', 'z')),
    (tt.sum, (tt.mul, 'x', 'y'), (tt.mul, 'x', 'z'))
),)
mul_dist_pat_tt += (tt.gof.opt.PatternSub(
    (tt.mul, 'x', (tt.add, 'y', 'z')),
    (tt.add, (tt.mul, 'x', 'y'), (tt.mul, 'x', 'z'))
),)
@

These searches and replacements can be applied to an objective function until
it is in a sufficiently reduced form.  \texttt{EquilibriumOptimizer} provides
this functionality.
<<evaluate=True, echo=True>>=
test_sub_eqz_opt_tt = tt.gof.opt.EquilibriumOptimizer(
    mul_dist_pat_tt, max_use_ratio=10)

test_fgraph_tt = tt.gof.fg.FunctionGraph(
    tt.gof.graph.inputs(test_exprs_tt), test_exprs_tt)
@
<<term=True>>=
tt.printing.debugprint(test_fgraph_tt)
@

Now, when we apply the optimization, the \texttt{FunctionGraph} should
contain the replacements.
<<evaluate=True, echo=True>>=
test_fgraph_opt = test_sub_eqz_opt_tt.optimize(test_fgraph_tt)
@
<<term=True>>=
tt.printing.debugprint(test_fgraph_tt)
@
\end{Exa}

More symbolic capabilities might be needed to [efficiently] achieve the
functionality we desire.  Standalone libraries like SymPy and
\href{https://github.com/logpy/logpy/}{LogPy} can be adapted to Theano graph
objects to provide these capabilities--although direct implementation in Theano
may be better.

% Could also mention the nice compartmentalization provided by independent
% logic programming.  These provide many features foundational to symbolic
% algebra, without the extra baggage--so to say.
%
%Matrix algebra using LogPy and SymPy
%\href{https://github.com/mrocklin/sympy/blob/matrix-cookbook-logpy/sympy/matrices/expressions/simplifydata.py}{here}
%and
%\href{https://github.com/mrocklin/sympy/blob/matrix-cookbook-logpy/sympy/matrices/expressions/simplify.py}{here}.
%Tests/examples are
%\href{https://github.com/mrocklin/sympy/blob/matrix-cookbook-logpy/sympy/matrices/expressions/tests/test_simplify.py}{here}.

% Nice use cases:
% \href{https://github.com/mrocklin/Theano/blob/logpy-unify/theano/gof/match.py}{match.py},
% \href{https://github.com/mrocklin/Theano/blob/logpy-unify/theano/gof/tests/test_match.py}{test\_match.py}.

Finally, let's briefly imagine how convexity could be determined
symbolically.  For differentiable terms, we could start with a simple
second derivative test.  Within Theano, a ``second derivative'' can be
obtained using the \texttt{hessian} function, and within \texttt{theano.sandbox.linalg}
are \texttt{Optimizer} hints for matrix positivity and other properties relevant
to determining convexity using this simple idea.

\begin{remark}
  Other great examples of linear algebra themed optimizations are in
  \texttt{theano.sandbox.linalg}: for instance, \texttt{no\_transpose\_symmetric}.
  Some of these demonstrate exactly how straight-forward it can be to
  add algebraic considerations.
\end{remark}

Although our convexity testing idea is far too simple for many $l$, the point we want to
make is that the basic code necessary for simple tests like this may already be in place.
However, with the logic programming mentioned earlier in this section,
comes the possibility of implementing aspects of the convex function calculus, by
which one can determine convexity for many more classes of functions.

\section{Discussion}

We've sketched out the concepts and mechanism with which one can develop a robust
estimation platform that can be transparently guided by the more abstract
mathematics frameworks from which new, efficient methods are produced.

Some key steps in the process will most likely require the integration of a
symbolic algebra system, so that a much wider array of algebraic machinery can
be leveraged to assess--say--convexity of the terms or to solve the proximal
operators themselves.  Connections between Theano, SymPy and LogPy have already
been explored in \citet{rocklin_mathematically_2013}, as well as many other
important aspects of the topics discussed here.

Additionally, more advanced proximal algorithms exist to improve upon the convergence and
stability of the most basic proximal gradient given here.  These algorithms often involve
operator splitting, which requires careful consideration regarding the exact type of splitting
and on which terms it is performed.  Within this area are the familiar convex-conjugate approaches;
these too could be approached by symbolic solvers, or simply addressed by [partially] generated
tables.

Overall, there appear to be many avenues to explore just within the space of proximal
algorithms and modern symbolic systems.  Not all of this work necessitates the inclusion of
fully featured symbolic algebra systems; much can be done with the symbolic tools of Theano alone.
Furthermore, there are specialized, lightweight logic programming systems--like
LogPy--that can serve as a step before full symbolic algebra integration.

Besides the automation of proximal algorithms themselves, there are areas of application involving
very large and complicated models or graphs--such as the ones arising in Deep Learning.
How might we consider the operator splitting of ADMM within deeply layered or hierarchical
models \citep{polson_statistical_2015}?  At which levels and on which terms
should the splitting be performed?  Beyond simply trying to solve the
potentially intractable mathematics arising from related questions, with the
symbolic capabilities described here, we can at least begin to experiment with
the questions.


Before closing, a very related--and at least as interesting--set of ideas is
worth mentioning: the possibility of encoding more symbolic knowledge into
probabilistic programming platforms like PyMC3.  Using the same optimization
mechanisms as the examples here, simple distributional
relationships can be encoded.
For instance, the convolution of normally distributed random variables:
<<norm_conv_setup>>=
mu_X = tt.vector('mu_X')
mu_X.tag.test_value = np.array([1.], dtype=tt.config.floatX)
sd_X = tt.vector('sd_X')
sd_X.tag.test_value = np.array([2.], dtype=tt.config.floatX)

mu_Y = tt.vector('mu_Y')
mu_Y.tag.test_value = np.array([1.], dtype=tt.config.floatX)
sd_Y = tt.vector('sd_Y')
sd_Y.tag.test_value = np.array([0.5], dtype=tt.config.floatX)

with pm.Model() as conv_model:
    X_rv = pm.Normal('X', mu_X, sd=sd_X, shape=(1,))
    Y_rv = pm.Normal('Y', mu_Y, sd=sd_Y, shape=(1,))
    Z_rv = X_rv + Y_rv
@
We create a Theano \texttt{Op} to handle the convolution.
<<norm_conv_op_setup>>=
class NormConvOp(tt.Op):
    __props__ = ()

    def make_node(self, *inputs):
        name_new = str.join('+', [getattr(in_, 'name', '') for in_ in inputs])
        mu_new = tt.add(*[in_.distribution.mu for in_ in inputs])
        sd_new = tt.sqrt(tt.add(*[in_.distribution.sd**2 for in_ in inputs]))
        conv_rv = pm.Normal(name_new, mu=mu_new, sd=sd_new,
                            # Is this another place where automatically/Theano managed
                            # shapes are really needed.  For now, we hack it.
                            shape=(1,))

        return tt.Apply(self, inputs, [conv_rv])

    def perform(self, node, inputs, output_storage):
        z = output_storage[0]
        z[0] = np.add(*inputs)
@
Now, all that's needed is a \texttt{PatternSub} like before.
<<norm_conv_opt_pattern>>=
def is_normal_dist(x):
    return hasattr(x, 'distribution') and isinstance(x.distribution, pm.Normal)

norm_conv_pat_tt = (tt.gof.opt.PatternSub(
    (tt.add,
     {'pattern': 'x',
      'constraint': lambda x: is_normal_dist(x)},
     {'pattern': 'y',
      'constraint': lambda x: is_normal_dist(x)}
     ),
    (NormConvOp(), 'x', 'y')),)

norm_conv_opt_tt = tt.gof.opt.EquilibriumOptimizer(norm_conv_pat_tt,
                                                   max_use_ratio=10)

Z_fgraph_tt = tt.gof.fg.FunctionGraph([X_rv, Y_rv], [Z_rv])

# We lose the `FreeRV.distribution` attribute when cloning the graph
# with `theano.gof.graph.clone_get_equiv` in `FunctionGraph`, so this
# hackishly reattaches that information:
_ = [setattr(g_in, 'distribution', s_in.distribution)
     for s_in, g_in in zip([X_rv, Y_rv], Z_fgraph_tt.inputs)]
@
<<norm_conv_opt_run>>=
with conv_model:
    _ = norm_conv_opt_tt.optimize(Z_fgraph_tt)

norm_conv_var_dist = Z_fgraph_tt.outputs[0].distribution
@
The resulting graph:
<<term=True>>=
tt.printing.debugprint(Z_fgraph_tt)
@
and the convolution's parameters (for the test values):
<<term=True>>=
print(norm_conv_var_dist.mu.tag.test_value)
print(norm_conv_var_dist.sd.tag.test_value)
@

More sophisticated routines--like the example above--could implement parameter
expansions, efficient re-parameterizations and equivalent scale mixture forms
in an effort to optimize a graph for sampling or point evaluation.  Objectives
for these optimizations could be straightforward and computationally based
(e.g. reducing the number of operations in computations of the log likelihood
and other quantities) or more statistically focused (e.g. highly efficient
sampling, improve mixing).  These ideas are most definitely not new--one
example is given by \citet{mohasel_afshar_probabilistic_2016} for symbolic Gibbs
sampling, but we hope the examples given here make the point that the tools are
readily available and quite accessible.

We'll end on a much more spacey consideration.  Namely, that this is a context
in which we can start experimenting rapidly with objectives over the space of
estimation routines.  This space is generated by--but not limited to--the
variety of symbolic representations, re-parameterizations, etc., mentioned
above.  It does not necessarily require the complete estimation of a model at
each step, nor even the numeric value of quantities like the gradient or
Hessian.  It may involve them, but not their evaluation; perhaps, instead,
symbolic comparisons of competing gradients and Hessians arising from different
representations.  What we're describing lies somewhere between the completely
numeric assessments common today, and the entirely symbolic work found within
the theorems and manipulations of the mathematics we use to derive methods.

\bibliographystyle{plainnat}
\bibliography{symbolic}


\end{document}
